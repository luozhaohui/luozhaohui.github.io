<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人工智能 on 飘飘白云：所读，所观，所思</title>
    <link>https://luozhaohui.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on 飘飘白云：所读，所观，所思</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 15 Mar 2025 22:14:00 +0800</lastBuildDate>
    
        <atom:link href="https://luozhaohui.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>人工智能发展之潮起潮落</title>
      <link>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</link>
      <pubDate>Sat, 15 Mar 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</guid>
      
        <description>&lt;h2 id=&#34;前言在迷雾中寻找光的轨迹&#34;&gt;前言：在迷雾中寻找光的轨迹&lt;/h2&gt;
&lt;p&gt;人工智能的演进史是一部充满悖论的启示录：图灵用停机问题为计算划定边界，却意外点燃了智能革命的导火索；罗森布拉特的感知机本欲模仿神经元放电，最终却演变成深度学习中抽象的矩阵运算；辛顿在冷板凳上坚守神经网络四十年，等来的却是算力与数据暴力破解智能密码的&amp;quot;苦涩教训&amp;quot;。这些戏剧性的转折揭示着一个残酷的真相：&lt;strong&gt;我们对智能的理解，始终在知其然与不知其所以然之间徘徊&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当下人工智能狂欢背后暗涌着深刻的认知危机：当 &lt;code&gt;GPT-4&lt;/code&gt; 能通过律师资格考试却无法理解“正义”的哲学内涵，当&lt;code&gt;Stable Diffusion&lt;/code&gt;创作出媲美莫奈的画作却对光影美学毫无感知，我们不得不追问——这究竟是智能的曙光，还是复杂曲线拟合制造的认知幻觉？&lt;/p&gt;
&lt;p&gt;这次人工智能“考古”之旅，既是向那些在寒冬中守护火种的先驱者致敬（从图灵到辛顿），更是对当下AI神话的祛魅仪式。在本文中，我们将看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神经网络惊人的抽象能力背后，是&lt;strong&gt;统计学&lt;/strong&gt;对有机生物体智能表现的粗糙模拟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Transformer&lt;/code&gt;架构的革命性突破，本质是利用&lt;strong&gt;预训练机制&lt;/strong&gt;对大规模数据的概率特征的&lt;strong&gt;高效建模&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;强化学习的&lt;strong&gt;试错进化&lt;/strong&gt;，也不过是达尔文主义在数字世界的投影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这个深度学习主导的“暴力美学”时代，重访人工智能发展的潮起潮落，不仅是为了理解技术演进的内在逻辑，更是为了在算法黑箱与人类认知的裂隙中，寻找智能本质的蛛丝马迹。本文将系统地&lt;strong&gt;梳理人工智能发展的三次高潮与两次低谷，剖析符号主义、连接主义、行为主义三大流派的哲学分野&lt;/strong&gt;，并探讨哥德尔不完备定理对强人工智能的理论约束。通过跨学科的视角，试图在数学的严谨、神经科学的实证与哲学的思辨之间，勾勒人工智能演进的探索过程以及可能图景。&lt;/p&gt;
&lt;h2 id=&#34;理论开端&#34;&gt;理论开端&lt;/h2&gt;
&lt;h3 id=&#34;可形式化与可计算&#34;&gt;可形式化与可计算&lt;/h3&gt;
&lt;p&gt;1900年，数学家&lt;strong&gt;大卫·希尔伯特&lt;/strong&gt;于向国际数学界提出了著名的“&lt;strong&gt;二十三个数学问题&lt;/strong&gt;”，其中第二个和第十个问题与人工智能的&lt;strong&gt;理论可能性&lt;/strong&gt;和&lt;strong&gt;实现可能性&lt;/strong&gt;紧密相关：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;问题二：&lt;strong&gt;算术公理的一致性证明&lt;/strong&gt;：证明在算术系统中，基于该系统内的公理规则，不存在能够同时成立又相互矛盾的定理。&lt;/li&gt;
&lt;li&gt;问题十：&lt;strong&gt;丢番图方程的可解性判定&lt;/strong&gt;：是否存在一种算法，可以通过有限步骤判断任意给定的丢番图方程（Diophantine equation）是否有整数解。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1931年&lt;strong&gt;库尔特·哥德尔&lt;/strong&gt;提出了著名的&lt;strong&gt;哥德尔不完备定理&lt;/strong&gt;证否问题二。哥德尔不完备定理表明，在任何一致的形式系统中，&lt;strong&gt;总存在一些命题无法在这个系统内部被证明或证伪，即该系统是不完备的，一定存在逻辑矛盾的表述&lt;/strong&gt;。典型示例如语言符号系统中的&lt;strong&gt;说谎者悖论&lt;/strong&gt;：“这句话是假的”。&lt;/p&gt;
&lt;p&gt;1970年&lt;strong&gt;尤里·马季亚谢维奇&lt;/strong&gt;证明了无法通过固定的算法步骤来判断所有丢番图方程是否具有整数解，从而证否了问题十。问题十和图灵停机问题是等价的。&lt;strong&gt;图灵停机问题&lt;/strong&gt;（Halting Problem）是图灵于1936年提出的，该问题是说：是否存在一个算法对于任意给定的程序和输入，可以判定程序最终会停止运行（停机）还是会无限期地运行下去。图灵自己通过反证法证明图灵停机问题是不可判定的。&lt;/p&gt;
&lt;p&gt;这两个问题都在理论上被证否了，也就是说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不是所有问题都可以被形式系统所表征。也就是说&lt;strong&gt;形式系统不能抽象所有现实问题&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;不能所有被形式系统表征的问题都可以通过计算来解决。也就是说&lt;strong&gt;计算不能解决所有可形式化的问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于问题的范围大于可形式化的范围，而可形式化的范围又大于可计算的范围，所以&lt;strong&gt;可形式化和可计算理论就限定了机器计算的边界&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;皇帝的新脑&#34;&gt;皇帝的新脑&lt;/h3&gt;
&lt;p&gt;罗杰·彭罗斯在《皇帝的新脑》中论证，基于哥德尔不完备定理，人类心智具有超越算法的能力。这就引出一个根本问题：如果人类智能确实超越了算法计算，那么模拟人脑的努力是否有内在的理论限制？或者说，&lt;strong&gt;我们是否需要开发出本质上不同于现有计算范式的新型智能系统？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此外罗杰·彭罗斯提出的&amp;quot;意识的量子理论&amp;quot;暗示大脑可能利用了量子效应。虽然这一观点仍有争议，但它启发我们思考：未来的人工智能是否会利用量子叠加、纠缠甚至意识的量子基础，创造出全新的智能形式？这种&amp;quot;量子计算&amp;quot;可能比现有的基于经典计算的人工智能拥有本质上不同的能力边界。&lt;/p&gt;
&lt;p&gt;由于目前理论上对机器计算能力的这种约束，有人认为机器模拟智能是不可能的。但图灵反驳说：“尽管已经证明任何一台特定的机器能力都是有限的，但&lt;strong&gt;并没有任何证据说，人类智能就没有这种局限性。&lt;/strong&gt;”&lt;/p&gt;
&lt;h3 id=&#34;图灵机&#34;&gt;图灵机&lt;/h3&gt;
&lt;p&gt;图灵机计算模型为现代计算机科学奠定了理论基础。但图灵机的提出可能是计算机科学史上最大的讽刺之一，因为图灵本来是为证明有些事情（停机问题）是计算机永远也做不了的，而设计的一种定义机械计算过程的抽象计算模型。图灵机的基本思想是模拟人类日常的“计算”行为，通过一根&lt;strong&gt;无限长&lt;/strong&gt;的纸带、一个&lt;strong&gt;读写头&lt;/strong&gt;以及一组状态转换&lt;strong&gt;规则&lt;/strong&gt;来模拟任何算法的“机械”计算过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;纸带&lt;/strong&gt;（带行草稿纸）：被划分为一个个单元格，每个单元格可以存储一个符号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;读写头&lt;/strong&gt;（笔头）：可以在纸带上左右移动，读取当前单元格的内容或向其中写入新符号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态寄存器&lt;/strong&gt;（短期记忆）：存储机器当前的状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态转换规则集&lt;/strong&gt;（运算法则）：根据当前状态和读写头下的符号决定下一步操作，包括更改状态、写入新符号及移动读写头的方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在每个动作完成后，根据当前所关注的纸带某个&lt;strong&gt;位置上的符号&lt;/strong&gt;以及寄存器中存储的&lt;strong&gt;状态&lt;/strong&gt;（类似人短期记忆中的状态），来决定下一步的动作是什么。&lt;/p&gt;
&lt;h4 id=&#34;图灵完备&#34;&gt;图灵完备&lt;/h4&gt;
&lt;p&gt;设计图灵机的初衷是为了探讨机器计算的边界，即机器计算不可以（反面即可以）实现哪些算法。由于图灵机计算模型非常直观、易于理解，而且很容易通过机械或者电子技术来实现。因此，它迅速&lt;strong&gt;成为机器解决“如何计算”问题的基础，在计算理论上也成为了可计算性的对标物&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这就引出了“&lt;strong&gt;图灵完备&lt;/strong&gt;”这一概念，如果一台设备实现了图灵机计算模型定义的行为，则称该设备是图灵完备的，理论上它可以解决所有可计算问题。当一个新的计算模型出现时，人们通过它是否能够解决所有可计算问题来判定它是否是图灵等价或者图灵完备的。今天，如果称一门程序设计语言是图灵完备的，意思是所有可计算的算法都能够用这种语言来实现 。&lt;/p&gt;
&lt;p&gt;图灵给出了用机械操作来模拟人类用纸笔运算过程这一解决可计算问题的计算模型“图灵机”，而冯·诺依曼则给出了实现这一计算模型的物理架构“冯·诺依曼架构”，于是通用计算机的“灵魂”与“躯体”就都有了。虽然通用计算机不能解决所有问题，但它至少可以解决可计算问题，也就是说可以解决现实世界中可被符号化中的可计算的那一部分问题。&lt;/p&gt;
&lt;h3 id=&#34;np-问题&#34;&gt;NP 问题&lt;/h3&gt;
&lt;p&gt;前面提到图灵机在理论上可以解决所有可计算问题，但这个“理论上”是在“&lt;strong&gt;无限纸带&lt;/strong&gt;”的前提下才可能实现的，换句话说就是&lt;strong&gt;在计算资源无限供应的情况下可解&lt;/strong&gt;。而在现实中，这个约束条件对于求解那些计算规模超级大的算法是很不现实的。由 &lt;em&gt;Steve Cook&lt;/em&gt; 于 1971 年提出的 NP 问题就是这样一类问题，用计算机来求解它们是非常低效的，甚至因计算规模随输入规模呈指数级增长而变得完全不可行。P vs NP 问题猜想被列为计算机科学和数学领域的核心难题，是克雷数学研究所列出的七大千禧年难题之一，该所为这七大世纪难题的每一个都悬赏一百万美元的奖金。&lt;/p&gt;
&lt;h4 id=&#34;p-问题&#34;&gt;P 问题&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：所有可以在&lt;strong&gt;多项式时间&lt;/strong&gt;内被确定性图灵机&lt;strong&gt;解决&lt;/strong&gt;的问题的集合。换句话说，对于某个确定性的图灵机（即算法），如果一个问题能够在输入大小的多项式时间内得到解答，则该问题属于 P 类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：排序算法、最短路径问题、最小生成树问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;np-问题-1&#34;&gt;NP 问题&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：所有可以在&lt;strong&gt;多项式时间&lt;/strong&gt;内被非确定性图灵机&lt;strong&gt;验证解&lt;/strong&gt;的问题的集合。这意味着如果你有一个候选解，你可以快速检查这个解是否满足条件，即使找到这个解可能很困难。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;P ⊆ NP&lt;/strong&gt;：所有 P 问题都属于 NP 问题，因为&lt;strong&gt;能高效求解的问题必然能高效验证解&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：旅行商问题、背包问题、图着色问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;np-完全问题np-complete&#34;&gt;NP 完全问题（NP-Complete）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：NP 完全问题是 NP 问题中最难的一类，它同时满足两个条件：
&lt;ol&gt;
&lt;li&gt;属于 NP 类；&lt;/li&gt;
&lt;li&gt;所有 NP 问题可归约到它（即存在多项式时间归约）。规约的意思是：若问题 A 可归约为问题 B，则 B 至少和 A 一样难，即若有算法能解决 B，那么 A 也可以用同样复杂度的算法解决。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：如果任何一个 NP 完全问题可以在多项式时间内解决，那么所有的 NP 问题都可以在多项式时间内解决，这意味着 P=NP。相反，如果能证明任何一个 NPC 问题是无法在多项式时间内解决的，则 P≠NP。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;p--np-猜想&#34;&gt;P ≠ NP 猜想&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;含义&lt;/strong&gt;：是否所有 NP 问题都能高效求解，大多数科学家认为不能，即 &lt;strong&gt;P类 ≠ NP类&lt;/strong&gt;，这就意味着&lt;strong&gt;有些问题找解很难，但验证解很容易&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;如果 &lt;strong&gt;P=NP&lt;/strong&gt; 被证明是真的，这将打破目前的“计算不可逆”假设，从而对加密学（RSA等协议依赖NP问题的困难性假设）、人工智能（对抗样本防御）、算法优化等领域产生革命性影响，因为许多目前认为难以解决的问题都将变得易于处理。&lt;/li&gt;
&lt;li&gt;如果 &lt;strong&gt;P≠NP&lt;/strong&gt; 被证明是真的，虽然不会改变当前的技术实践，但它会正式确认许多重要问题确实没有高效的解决方案，从而指导研究人员更加专注于开发有效的&lt;strong&gt;近似算法&lt;/strong&gt;和&lt;strong&gt;启发式方法&lt;/strong&gt;来应对这些难题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自 NP 问题提出起，人工智能领域的研究人员就利用 NP 完全问题理论来研究他们的课题，结果发现不管哪个领域：问题解决、玩游戏、规划、学习、推理等，似乎任何关键性的问题都是 NP 完全问题。这种现象使得业界流传着一个笑话：所谓的“AI完全问题”意味着“一个和AI本身一样难的问题”，如果你能解决一个AI完全问题，你就能解决所有AI问题。&lt;/p&gt;
&lt;p&gt;当前人工智能中的最关键的神经网络算法虽然不属于&lt;strong&gt;NP完全问题（NPC）&lt;/strong&gt;，但其训练过程与NP问题的求解在&lt;strong&gt;计算复杂度&lt;/strong&gt;和&lt;strong&gt;近似解策略&lt;/strong&gt;上高度关联。神经网络训练属于&lt;strong&gt;非凸优化问题&lt;/strong&gt;（通常为NP难问题），二者虽不属于同一复杂性类别，但均面临“搜索空间庞大”和“缺乏确定性高效算法”的共性挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;参数空间的维度爆炸与计算复杂度&lt;/strong&gt;：神经网络训练的优化问题本质上是非凸的，其参数规模通常达到百万甚至千亿级别（如GPT-4的参数规模达到了1.8万亿）。随着参数量的增加，搜索空间的维度呈指数级增长，这与NP问题（如旅行商问题）的输入规模扩大时计算量爆炸的特性相似。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;近似解策略&lt;/strong&gt;：神经网络的优化算法不保证找到全局最优解，但根据梯度下降的局部最优性，往往能发现足够好的局部最优解。这类似于NP问题中启发式算法（如模拟退火、遗传算法）的近似求解思路。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;图灵测试&#34;&gt;图灵测试&lt;/h3&gt;
&lt;p&gt;关于何为智能，图灵和香农观点不一样。香农倾向于强人工智能（通用人工智能），认为应该包括艺术、情感、音乐等。而图灵则不这么认为，他在反驳香农时是这么说的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“不！我对如何建造一颗无所不能的大脑完全不感兴趣，我只要一颗并不太聪明的大脑，和美国电报电话公司董事长的脑袋那样差不多就行了！”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;图灵用一向的“逆向思维”（前面他就用反证法证明了图灵停机问题的不可判定），不从正面给智能下定义，而是根据外部行为来判定机器是否拥有智能，这就是论文《计算机器和智能》中给出的“图灵测试”：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“如果人类由于无法分辨一台机器是否具备与人类相似的智能，导致无法分辨与之对话的到底是人类还是机器，那即可认定机器存在智能。”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;“&lt;strong&gt;图灵测试&lt;/strong&gt;”为衡量机器是否具备智能提供了一种标准。常见的图形验证码就是图灵测试的一种典型应用，验证码的英文单词“&lt;strong&gt;Captcha&lt;/strong&gt;”就是“通过图灵测试来完全自动地分辨出计算机和人类”这句话的首字母缩写（Completely Automated Public Turing test to tell Computers and Humans Apart）。后来著名的“中文屋”实验也采用了这个思路。&lt;/p&gt;
&lt;p&gt;彼时，图灵对智能的关注点在于&lt;strong&gt;思考&lt;/strong&gt;，这里的思考不是从内部的结构模式出发考察的，而是从外部可观察到的行为着手，即机器通过学习而获得某项技能，并通过将这项技能表现出来的智能行为。所以图灵在论文中重点论证了建造“学习机器”（Learning Machines）的可行性，更具体地说，是论证机器依靠学习进化而最终通过图灵测试的可能性。&lt;/p&gt;
&lt;h3 id=&#34;通用人工智能智能能被模拟么&#34;&gt;通用人工智能：智能能被模拟么&lt;/h3&gt;
&lt;p&gt;由于形式系统的不完备性以及存在不可判定的计算问题，因此世界上总有些问题是无法被机器模拟的。那回到图灵与香农最初探讨的问题：&lt;strong&gt;人类的智能是否能够被某种模型所模拟（抽象）？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果是，那必将存在着人类智能绝对无法解决的问题；&lt;/li&gt;
&lt;li&gt;如果不是，那人类就很难制造出能够拥有人类思维的机械智能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;像说谎者悖论“这句话是假的”、罗素的理发师悖论“理发师只给那些不给自己刮胡子的人刮胡子”这样涉及自指的问题，一般都要上升一个层面或维度才能解决。这有点像自我意识套娃：&lt;strong&gt;我在思考我在思考&lt;/strong&gt;。对这个问题，图灵的回答是“&lt;strong&gt;人也不是完备的&lt;/strong&gt;”。对于机器是否必须具备和人类一样的思维意识才能算人工智能，语言和认知学家诺姆·乔姆斯基的回答是“&lt;strong&gt;潜艇能够游泳吗？&lt;/strong&gt;”&lt;/p&gt;
&lt;p&gt;而澳大利亚哲学家&lt;strong&gt;大卫·查尔默斯&lt;/strong&gt;提出&amp;quot;意识难题&amp;quot;质疑：即使我们完全理解了大脑的物理机制，仍无法解释为何会产生&lt;strong&gt;主观体验的感受性&lt;/strong&gt;。这对人工智能提出了根本挑战：即使人工智能系统表现出与人类相似的行为，我们有理由相信它拥有类似人类的主观体验吗？&lt;strong&gt;托马斯·内格尔&lt;/strong&gt;也在其著作《成为一只蝙蝠是什么感受》中提出，&lt;strong&gt;主观体验是无法通过客观描述来完全理解的&lt;/strong&gt;。他认为，即使我们能够完全了解蝙蝠的大脑结构和功能，也无法真正知道“成为一只蝙蝠是什么感受”。&lt;strong&gt;意识产生于有主观体验的智能体：拥有主观上的内在感受性&lt;/strong&gt;，重点就在于对内在心理现象的感知。 这暗示&lt;strong&gt;我们可能需要超越计算理论的框架来理解意识本质，而这正是强人工智能与弱人工智能之争的核心&lt;/strong&gt;。（非确定性 VS 确定性，可以用量子物理 VS 经典物理来类比思考）&lt;/p&gt;
&lt;p&gt;智能的本质究竟是计算、理解、模拟、创造还是感受？从计算的角度看，图灵机模型暗示了智能的可计算性；从现象学角度看，智能与体验、意图不可分割；从演化角度看，智能本质上是适应性解决问题的能力。这些不同视角暗示我们可能需要一个多元、立体的智能观，而非单一的理解框架。未来人工智能的重大突破很可能来自跨学科交叉融合。特别是将数学理论、神经科学的大脑工作机制、心理学的人类认知模式、哲学的本体论思考与计算机科学的实现方法相结合，可能是走向通用人工智能的必由之路。&lt;/p&gt;
&lt;h2 id=&#34;发展历程三次高潮与两次低谷&#34;&gt;发展历程：三次高潮与两次低谷&lt;/h2&gt;
&lt;p&gt;在强大的军事需求的刺激下，二战后不久，&lt;strong&gt;系统论（1945）、信息论（1948）、控制论（1948）&lt;/strong&gt; 这“信息学三论”的开创性著作相继发表，使之前零散研究摸索的信息科学得以系统有序起来。从此信息计算、人工智能、控制自动化相关领域飞速发展，当然发展的过程也是跌宕起伏。人工智能的发展是一部充满希望与挫折的探索史，凝聚了无数科学家的智慧与坚持。从图灵机的理论奠基到深度学习的爆发，人工智能历经三次高潮与两次低谷，展现了人类对智能本质的不懈追求。&lt;/p&gt;
&lt;h3 id=&#34;第一次高潮1950s-1970s符号主义崛起与逻辑推理的黄金时代&#34;&gt;第一次高潮（1950s-1970s）：符号主义崛起与逻辑推理的黄金时代&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1950年&lt;/strong&gt;：图灵提出“图灵测试”，奠定智能机器的哲学基础。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1956年&lt;/strong&gt;：达特茅斯会议召开，麦卡锡首次提出“人工智能”概念，符号主义成为主流。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1960年代&lt;/strong&gt;：LISP 语言诞生，逻辑推理与专家系统初现雏形。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1960年代&lt;/strong&gt;：M-P神经元模型和单层神经网络感知机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低谷原因&lt;/strong&gt;：
符号主义依赖人工规则和逻辑推理，但规则难以穷尽，因而难以应对复杂现实问题。连接主义的单层神经网络感知机无法处理异或问题。再加上当时计算机的计算能力非常薄弱。1973年《莱特希尔报告》批评 AI 研究缺乏实际成果，经费锐减，进入第一次寒冬。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第二次高潮1980s-1990s知识工程与专家系统的兴衰&#34;&gt;第二次高潮（1980s-1990s）：知识工程与专家系统的兴衰&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1980年代&lt;/strong&gt;：专家系统（如MYCIN）在医疗、金融领域崭露头角，知识工程成为研究热点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1986年&lt;/strong&gt;：辛顿提出误差反向传播算法（BP算法），使神经网络重获关注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低谷原因&lt;/strong&gt;：
专家系统依赖人工知识输入，但静态知识难以同步动态世界，因而难以穷尽、扩展和维护。全面常识知识工程CYC的幻灭。布鲁克斯（iRobot扫地机器人创始人）基于行为主义思想对知识系统进行了猛烈批判，认为不可能预装一切知识，而应该通过环境互动试错演进。1990年代统计学习方法（如支持向量机）兴起，连接主义暂未突破，AI再次遇冷。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第三次高潮2006年至今深度学习革命与ai的全面爆发&#34;&gt;第三次高潮（2006年至今）：深度学习革命与AI的全面爆发&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2006年&lt;/strong&gt;：辛顿发表深度信念网络论文，开启深度学习时代。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2012年&lt;/strong&gt;：AlexNet 在 ImageNet 竞赛中碾压传统方法，深度学习引爆产业热潮。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2016年&lt;/strong&gt;：在围棋比赛中，AlphaGo 击败世界冠军李世石，这是深度强化学习与蒙特卡洛树搜索结合的突破性成果，标志着AI首次在高度复杂的&lt;strong&gt;完全信息&lt;/strong&gt;博弈中超越人类顶尖水平。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2017年&lt;/strong&gt;：Transformer架构，由 Vaswani 等人在论文《Attention is All You Need》中首次提出，通过&lt;strong&gt;自注意力机制&lt;/strong&gt;彻底革新了NLP领域。Transformer摒弃了传统的RNN结构，采用纯注意力机制实现并行计算，解决了长序列依赖问题。这一架构不仅成为BERT、GPT等所有现代大型语言模型的基础，还因其设计上的灵活性被广泛应用于计算机视觉等领域，成为跨模态AI发展的关键基石。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2020&lt;/strong&gt;：GPT-3 发布，参数量达到1750亿，标志着AI的重大突破，能够在广泛的任务中生成类人文本，显示了强大的少样本学习能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2022年&lt;/strong&gt;：ChatGPT 发布，专为对话交互设计，结合了人类反馈强化学习(RLHF)，引发大众对 AI 热潮。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2024年&lt;/strong&gt;：Deepseek系列模型发布，它通过优化模型结构和训练方法，在保持强大性能的同时大幅降低了成本。Deepseek不仅成本低，还是完全免费开源的，这就为AI应用落地打开了无限的可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当前挑战&lt;/strong&gt;：
深度学习依赖大数据与算力、可解释性不足、理论根基薄弱、伦理与安全问题亟待解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三大流派&#34;&gt;三大流派&lt;/h2&gt;
&lt;p&gt;根据不同的理念，人工智能的发展过程中出现了三种流派：符号主义演绎着人类心智的逻辑架构（&lt;strong&gt;人心&lt;/strong&gt;），连接主义编织着神经元网络的结构密码（&lt;strong&gt;人脑&lt;/strong&gt;），行为主义则捕捉着机体与环境互动的反馈奥秘（&lt;strong&gt;人身&lt;/strong&gt;）。如果说心智派在研究模拟智能的&lt;strong&gt;软件&lt;/strong&gt;，结构派在研究模拟智能的&lt;strong&gt;硬件&lt;/strong&gt;，那行为派就是在模拟智能生物的&lt;strong&gt;身体&lt;/strong&gt;了。&lt;/p&gt;
&lt;p&gt;用神经元模型的发明者、数理逻辑学家&lt;strong&gt;沃尔特·皮茨&lt;/strong&gt;（Walter Pitts，1923—1969）话来总结：“在我们面前有两条通向智能的路径，一条是模拟人脑的结构，一条是模拟人类心智，但我相信这两条路最终是殊途同归的。”从人工智能的发展历程上看，皮茨的总结非常有预见性，人工智能的探索历程就是结构派和“心智派交替提出新理论和新发现，交替占据主流地位的发展史，而具身智能的发展又离不开行为派的贡献。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;流派&lt;/th&gt;
          &lt;th&gt;时间段&lt;/th&gt;
          &lt;th&gt;理念&lt;/th&gt;
          &lt;th&gt;范式&lt;/th&gt;
          &lt;th&gt;核心人物&lt;/th&gt;
          &lt;th&gt;关键事件&lt;/th&gt;
          &lt;th&gt;优缺点&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;符号主义&lt;/strong&gt;，心智派&lt;/td&gt;
          &lt;td&gt;1950s-1980s&lt;/td&gt;
          &lt;td&gt;智能源于符号计算与逻辑推理&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;演绎&lt;/strong&gt;：逻辑推理、知识表示&lt;/td&gt;
          &lt;td&gt;麦卡锡、明斯基、纽厄尔、司马贺&lt;/td&gt;
          &lt;td&gt;达特茅斯会议、LISP语言发明、专家系统、知识系统&lt;/td&gt;
          &lt;td&gt;强可解释性、弱抽象、弱学习&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;连接主义&lt;/strong&gt;，结构派，&lt;/td&gt;
          &lt;td&gt;1980s-至今&lt;/td&gt;
          &lt;td&gt;仿生大脑神经网络结构&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;归纳&lt;/strong&gt;：神经网络、深度学习&lt;/td&gt;
          &lt;td&gt;麦卡洛克、皮茨、罗森布拉特、辛顿、杨立昆、本希奥&lt;/td&gt;
          &lt;td&gt;M-P神经元模型、蛙眼实验、感知机、ImageNet竞赛、ChatGPT&lt;/td&gt;
          &lt;td&gt;强泛化、强学习、弱可解释性、强规模依赖&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;行为主义&lt;/strong&gt;：行为派&lt;/td&gt;
          &lt;td&gt;1940s-至今&lt;/td&gt;
          &lt;td&gt;在环境中行为反馈试错演化、组件化&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;反馈&lt;/strong&gt;：感知-动作闭环、强化学习&lt;/td&gt;
          &lt;td&gt;维纳、布鲁克斯&lt;/td&gt;
          &lt;td&gt;控制论提出、机器人学发展&lt;/td&gt;
          &lt;td&gt;强学习、弱抽象、弱可解释性、组件数量规模限制&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;值得注意的是，当代人工智能发展实际上正逐步融合这三大流派的优势。符号主义的可解释性、连接主义的抽象能力与行为主义的环境互动，正通过类似于神经符号系统(Neurosymbolic AI)等新范式相互补充。理想的人工智能系统可能需要既能从数据中抽象学习（连接主义），又能进行逻辑推理（符号主义），同时能在环境互动通过反馈强化学习（行为主义）。&lt;/p&gt;
&lt;h3 id=&#34;符号主义&#34;&gt;符号主义&lt;/h3&gt;
&lt;p&gt;在人工智能的发展历程中，基于符号的智能研究曾经是大多数学者努力的方向，甚至在长达30年的时间里，符号主义的学说在人工智能这个学科里是占统治地位的。&lt;/p&gt;
&lt;p&gt;符号主义学派的思想和观点直接继承自图灵，提倡直接从功能的角度来理解智能，简而言之就是把智能视为一个黑盒，只关心这个黑盒的输入和输出，而不关心黑盒的内部结构。为了实现智能，符号主义学派利用“符号”（Symbolic）来抽象表征现实世界，利用逻辑推理和搜索来替代人类大脑的思考、认知过程，而不去关注现实中大脑的神经网络结构，也不关注大脑是不是通过逻辑运算来完成思考和认知的。概括来说，符号主义的理念是：“&lt;strong&gt;认知即计算&lt;/strong&gt;”，符号主义的思路是：“&lt;strong&gt;描述已知，推理未知&lt;/strong&gt;”。&lt;/p&gt;
&lt;p&gt;对于符号主义学派长达数十年的探索研究过程，根据研究问题的不同，可以将其划分为三个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;推理期&lt;/strong&gt;：最初这派的学者并未过多考虑知识的来源问题，而是假设知识是先验地存储于黑盒之中的，重点解决的问题是&lt;strong&gt;利用现有的知识去做复杂的推理、规划、逻辑运算和判断&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;知识期&lt;/strong&gt;：由于大家发现智能的体现并不能仅依靠推理来解决，先验的知识是更重要的一环，研究重点就转变为&lt;strong&gt;如何获取知识、表示知识和利用知识&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习期&lt;/strong&gt;：由于知识仅依靠人类专家总结、提炼然后输入计算机的方式无法应对世界上几乎无穷无尽的知识，研究的重点又转为如何&lt;strong&gt;让机器自己学习知识、发现知识&lt;/strong&gt;这个方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而根据研究思路的不同，可以分为两个支派：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;认知派&lt;/strong&gt;：以&lt;strong&gt;纽厄尔&lt;/strong&gt;和&lt;strong&gt;司马贺&lt;/strong&gt;领导的&lt;strong&gt;卡内基梅隆大学&lt;/strong&gt;为主，他们是从人类问题解决的思维活动出发，尝试将这种&lt;strong&gt;思维过程模型化&lt;/strong&gt;后，应用于计算机之上。他们经常基于心理学实验的结果来开发模拟人类解决问题方法的程序，这种研究方法一度成为人工智能和符号主义的主流。他们提出物理符号系统来尝试解释智能来源机制的理论，它试图模拟人类如何获取、储存、传播和处理信息的，并提供了一种将这个过程中各种现象模型化，迁移到计算机中实现的途径。该理论主要由两个假说构成，分别是&lt;strong&gt;物理符号系统假说&lt;/strong&gt;（智能行为的抽象模型，符号即模式特征）和&lt;strong&gt;启发式搜索假说&lt;/strong&gt;（解决问题或做出决策的抽象模型）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;逻辑派&lt;/strong&gt;：以&lt;strong&gt;麦卡锡&lt;/strong&gt;领导的斯坦福大学为主，他们认为直接找出抽象推理和解决问题的本质，只要通过&lt;strong&gt;逻辑推理&lt;/strong&gt;能展现出智能行为即可，大可不必去管人类是否使用同样的方式思考。在麦卡锡看来，对于特定问题的解决方法是“知识”，对于普适智能行为则需要“常识”才行，因此他关注“如何才能令机器拥有常识”这样的问题。他提出了 LISP（LISt Processing的缩写）语言的构想，而他的学生则实现了该语言，这使得他在计算机程序语言领域获得了可媲美“人工智能之父”头衔的荣誉与地位。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;启发式搜索的概念就是使用“经验法则”来指导搜索的重点&lt;/strong&gt;。通常我们也无法寻找到直指正确搜索路径的方法，但我们往往可以在感兴趣的问题上找到启发式搜索方向，从而大大减少搜索量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;连接主义&#34;&gt;连接主义&lt;/h3&gt;
&lt;h4 id=&#34;m-p神经元模型&#34;&gt;M-P神经元模型&lt;/h4&gt;
&lt;p&gt;连接主义这一派主要是研究&lt;strong&gt;人类大脑神经网络结构&lt;/strong&gt;的学者，他们主张从生物结构角度出发，让机器先去模拟人脑构造，再在“大脑是如何处理信息”的过程中获得智能。他们用神经元细胞要么发射信号、要么不发射信号的离散、二元的特征，比拟“与”、“或”、“非”这些最基础的逻辑门的性质。因此，神经元网络就像由逻辑门构成的网络。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;麦卡洛克&lt;/strong&gt;和&lt;strong&gt;皮茨&lt;/strong&gt;的《神经活动中内在思想的逻辑演算》一文被认为是连接主义研究的开端，首次提出了“神经网络”（Neural Network）这个概念，提出了被后人以两人首字母命名的机械式的思维模型：“&lt;strong&gt;M-P神经元模型&lt;/strong&gt;”。但在一次探索眼神经功能的蛙眼实验之后，皮茨对大脑是唯一的神经信号处理中心的信念破灭了，他意识到纯粹的逻辑、纯粹以大脑为中心的思想观是有局限性的。再加上维纳的支持纳粹的妻子作梗，皮茨、麦卡洛克与维纳交恶，皮茨在情感上、学术方向上都备受打击，一颗巨星就此陨落。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神经网络学习的基本原理就是从训练数据集中提取出分类特征，这些特征应该能够适用于相同分布的测试数据集&lt;/strong&gt;，所以经已知数据学习训练（即预训练）后的神经网络可以对同类的未知数据有效。&lt;strong&gt;神经网络学习是基于特征匹配的概率，它不是基于逻辑推理，因为它能做分类识别，但无法理解&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;感知机&#34;&gt;感知机&lt;/h4&gt;
&lt;p&gt;康奈尔大学的实验心理学家&lt;strong&gt;罗森布拉特&lt;/strong&gt;在“&lt;strong&gt;M-P神经元模型&lt;/strong&gt;”的基础上实现了一种称为“感知机”（Perceptron）的单层神经网络模型。 皮茨和麦卡洛克曾向人们展示了M-P神经元可以通过不同的连接方式和权重来实现逻辑与、或、非运算，罗森布拉特的感知机基本原理，就是利用了神经元可以进行逻辑运算的特点，通过“&lt;strong&gt;赫布法则&lt;/strong&gt;”（Hebb&amp;rsquo;s Law）的学习机制，调整连接线上的权重和神经元上的阈值，做到不依靠人工编程，仅靠机器学习来完成一部分机器视觉和模式识别方面的任务，这就展现了一条独立于图灵机之外的，全新的实现机器模拟智能的道路&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1949年，赫布出版了《行为组织学》（Organization of Behavior）一书。在该书中，赫布总结提出了被后人称为“&lt;strong&gt;赫布法则&lt;/strong&gt;”（Hebb&amp;rsquo;s Law）的学习机制。他认为如果两个神经元细胞总是同时被激活的话，它们之间就会出现某种关联，同时激活的概率越高，这种关联程度也会越高。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;罗森布拉特因感知机获得巨大的成功，并获得美国军方的支持。但成也感知机，败也感知机。&lt;strong&gt;明斯基&lt;/strong&gt;对高调的罗森布拉特研究感知机存在的价值和前途发起了攻击，他在《感知机：计算几何学导论》一书中在数学上证明了基于单层神经网络的“感知机能解决线性可分的问题，但是它也仅仅能解决线性可分的问题。”更准确地说是&lt;strong&gt;单层的感知机只能处理在特定特征上线性可分的数据集，并不能处理非线性数据的分类问题，其中最典型的就是“异或问题”&lt;/strong&gt;，而多层神经网络的感知机需要巨大规模的计算与数据，受当时的算力与数据规模限制，根本不可能想象，就更别说实现了。明斯基在第一版中明确说“这里（指罗森布拉特的理论）的大部分内容都没有多少科学价值。”&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果把逻辑与、或、非运算输入数据，按照0、1值构成二维的坐标平面，并把逻辑运算结果为1的用红色方块表示，结果为0的用蓝色圆圈表示，就形成了二维的图表，这三种逻辑运算都能够很直观地通过一条直线将这个二维坐标平面中的数据划分开来。 而异或则不能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;由于明斯基在人工智能领域的特殊地位与影响（第四届图灵奖获得者），罗森布拉特被整个人工智能学术界声讨。1971年，43岁的罗森布拉特在一次划船事故中不幸遇难。也许出于愧疚心理，明斯基在《感知机》第二版中删除了攻击罗森布拉特的话，并在扉页上手写了“纪念弗兰克·罗森布拉特”。连接主义与神经网络也和罗森布拉特一样备受打击，这一场风波可以说至少延误神经网络研究十年以上的发展。&lt;/p&gt;
&lt;p&gt;不久，1973年受英国政府委托的数学家&lt;strong&gt;詹姆士·莱特希尔&lt;/strong&gt;发表了赫赫有名的《莱特希尔报告》，这篇公开的报告是一份具有广泛影响力的、直接刺破人工智能乐观思潮泡沫的调查文件，被视作人工智能寒冬的开启。&lt;/p&gt;
&lt;h3 id=&#34;行为主义&#34;&gt;行为主义&lt;/h3&gt;
&lt;p&gt;1948年，图灵在论文《智能机器》里把研究智能的方向划分成了“&lt;strong&gt;具身智能&lt;/strong&gt;”（Embodied Intelligence）和“&lt;strong&gt;非具身智能&lt;/strong&gt;”（Disembodied Intelligence）两类。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“非具身智能”的研究演进成我们今天传统的基于计算（Computationalism）的认知科学，符号主义学派所主张的观点便是追寻这类智能的具体表现。以非具身智能的角度来看，所谓智能就是符号操作，起始于大脑的输入，终止于大脑的输出，智能和认知只关注这个符号操作过程。&lt;/li&gt;
&lt;li&gt;“具身智能”的研究则认为智能、认知都是与具体的身体、环境密切相关的，它们之间存在内在的和本质的关联，智能和认知两者必须以一个在环境中的具体的身体结构和身体活动为基础。智能是基于身体和涉及身体的，智能始终是具体身体的智能，而不能仅仅存在于脑海之中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;行为主义学派是1948年以“&lt;strong&gt;控制论之父&lt;/strong&gt;”&lt;strong&gt;维纳&lt;/strong&gt;的《控制论》的出版发行为起源标志的，因此又常被称为“&lt;strong&gt;控制论学派&lt;/strong&gt;”，根据其学说特点，有时候也被称作“&lt;strong&gt;演化主义学派&lt;/strong&gt;”。 控制论是在二战中英国防空战争中因研制自动火控系统而发展起来的。在《控制论》一书中，维纳对“机器能不能拥有智能行为”这个问题给予了正面的回答，提出了“智能性原则”：&lt;strong&gt;由信息、通信、控制和反馈构成的感知（输入）-行动（输出）系统就是智能的&lt;/strong&gt;。只要能够对环境的外部输入给予预期中的输出，这就是智能的体现，而无须去纠结是这样的系统是机器还是生物体。&lt;/p&gt;
&lt;p&gt;后期的控制论是一种统计理论，它关心的不是系统根据单独一次输入后产生的动作，而是&lt;strong&gt;对全部输入整体上能够做出合乎统计概率预期的动作&lt;/strong&gt;。在这个系统中，因果联系不再是完全确定的，它&lt;strong&gt;同时具有统计上的确定性和个体上的不确定性&lt;/strong&gt;，因而是一种统计上的因果关系。在控制系统中引入统计属性，从根本上改进了机械式的因果观念。此外行为主义还认为人工智能是应该和人类智能一样，依靠&lt;strong&gt;演化&lt;/strong&gt;获得，通过遗传过程的随机变异和环境对个体物竞天择的自然选择，逐代筛选出更快速、更健壮、更聪明的个体。iRobot创始人布鲁克斯曾经这样批判知识系统：预装全部知识是不可能的，也不是实现智能的正确途径，应该通过在环境中交互，通过试错反馈演化，即&lt;strong&gt;强化学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;机器学习&#34;&gt;机器学习&lt;/h2&gt;
&lt;p&gt;图灵在《计算机器和智能》中首次提出了“学习机器”（Learning Machines）的概念，以极具预见性的眼光洞察到能否实现人工智能的关键，很可能就取决于能否或者说何时解决“&lt;strong&gt;如何让机器拥有学习能力&lt;/strong&gt;”这个问题。&lt;/p&gt;
&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;司马贺&lt;/strong&gt;是最早（1959年）在学术上给出符合今天机器学习思想的定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果某个系统可以从经验中改进自身的能力，那这便是学习的过程。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但司马贺没有具体限定经验、改进等要素。1998年卡内基梅隆大学的&lt;strong&gt;汤姆·米切尔&lt;/strong&gt;在他撰写的《机器学习》中额外增加了几个具有可操作性的辅助描述符号：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习就是一种可以让机器根据历史经验自动改进自身的学习算法。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;他们俩都是&lt;strong&gt;从机器学习的本质出发，即从“是什么”、“做什么”的角度来定义机器学习&lt;/strong&gt;这个概念。还有一种方式是&lt;strong&gt;从“怎么做”这个角度来定义&lt;/strong&gt;。在李航老师的《统计学习方法》一书中，就提出机器学习由“模型”、“策略”和“算法”三个要素构成：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习＝模型+策略+算法&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型：是指机器学习所要产出的内容，它以一个可被计算的决策函数或者条件概率分布函数的形式存在&lt;/strong&gt;。把未知的新数据代入到这个模型中计算，就会得到符合真实情况的输出结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;策略：是指要按照什么样的准则进行学习，具体一点是按照什么样的准则评估选择出最优的模型&lt;/strong&gt;。从宏观角度讲，一般我们都会&lt;strong&gt;以“减少模型的输出结果与真实情况差距”以及学习复杂度作为学习的准则&lt;/strong&gt;，这里的“差距”同样也是以一个可被计算函数的形式来描述的，被称为“&lt;strong&gt;损失函数&lt;/strong&gt;”或“成本函数”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;算法&lt;/strong&gt;：是指&lt;strong&gt;如何把最能拟合真实世界的参数系数都找出来&lt;/strong&gt;。在确定寻找最优模型的策略后，机器学习的问题便归结为寻找出最优参数的优化问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在大方向上，机器学习最初是从基于&lt;strong&gt;规则&lt;/strong&gt;的机器学习开始的，现在正在朝着基于&lt;strong&gt;数据&lt;/strong&gt;的机器学习在持续迈进。基于&lt;strong&gt;规则演绎&lt;/strong&gt;和基于&lt;strong&gt;数据归纳&lt;/strong&gt;两种思维，分别对应了人类对现象规律（&lt;strong&gt;可计算的&lt;/strong&gt;）和对现象表现（&lt;strong&gt;可统计的&lt;/strong&gt;）的研究，也反映了符号主义学派和连接主义学派各自对机器学习的看法。&lt;/p&gt;
&lt;p&gt;如果把一切都看成由输入变换到输出的函数，那么符号主义是试图&lt;strong&gt;通过数学建模逻辑推导&lt;/strong&gt;出这个函数，而基于神经网络的连接主义则是试图&lt;strong&gt;通过输入与输出来逆向拟合&lt;/strong&gt;出这个函数，高效拟合的手段大多采用&lt;strong&gt;反向传播&lt;/strong&gt;，这整个过程也称为模型训练。&lt;/p&gt;
&lt;h3 id=&#34;模型训练&#34;&gt;模型训练&lt;/h3&gt;
&lt;p&gt;机器学习中所说的模型训练，是指从真实世界的一系列历史经验中获得一个可以拟合真实世界的决策模型 。上节提到模型训练过程是通过输入与输出来逆向拟合出目标函数：&lt;strong&gt;Function(输入)  = 输出，而 Function 是由：参数+系数+操作符 构成的&lt;/strong&gt;，也就是&lt;strong&gt;确定参数、系数和操作符的过程&lt;/strong&gt;。对于模型训练来说，这可以通俗理解为确定特征参数、优化系数、选择策略方法，因此模型训练主要聚焦在如下问题上：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特征：挑选哪些数据的哪些特征属性来当作参数，涉及：数据清洗，特征选择&lt;/li&gt;
&lt;li&gt;策略：如何选择损失函数，涉及：策略选择&lt;/li&gt;
&lt;li&gt;优化：如何优化参数系数，涉及：算法优化&lt;/li&gt;
&lt;li&gt;测试：如何测试模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型评估&#34;&gt;模型评估&lt;/h4&gt;
&lt;p&gt;模型选择是采取一种适当的学习策略，在大量数据的支持下，从假设空间（可选的决策/损失函数的全集）中筛选出一个最佳的模型。如何确定最佳模型的标准、用何种方法来学习得到这个最佳的模型，就是选择损失函数、理解其含义、如何求解和优化损失函数，从而得到满足损失函数最小值的模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一个模型的性能（performance）是指其泛化能力，也就是对满足相同分布规律的、训练集以外的数据的适应能力&lt;/strong&gt;。 “适应能力高低”是指模型输出值与实际值之间的“误差”（Error）的大小。“误差”是一个在统计学中被精确定义的概念，它在机器学习这个语境更加强调泛化而不是在训练集中，因此这里它被称为“&lt;strong&gt;期望泛化误差&lt;/strong&gt;”。误差是偏差、方差和噪声的总和：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;误差（Error）＝偏差（Bias）+方差（Variance）+噪声（Noise）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;偏差的含义是描述模型输出结果与真实标注的样例之间的差距，即模型在训练集上的&lt;strong&gt;拟合能力&lt;/strong&gt;。如果模型越复杂，引入的参数越多，那偏差就会小，但可能陷入过拟合；反之因为欠拟合，偏差就可能大。&lt;/li&gt;
&lt;li&gt;方差的含义是描述数据变化对模型输出结果的扰动影响，即模型对数据的&lt;strong&gt;敏感程度&lt;/strong&gt;。模型的复杂度越低，方差就越小，但可能陷入欠拟合；反之因为过拟合，方差就可能大。&lt;/li&gt;
&lt;li&gt;噪声是&lt;strong&gt;训练数据自身的错误&lt;/strong&gt;，即训练集中的部分样例数据的标注值与真实结果有差别。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择最优模型复杂度的一个最基本的准则就是偏差和方差之和最小，即要同时警惕避免发生训练过少导致模型复杂度过低（参数少）而&lt;strong&gt;欠拟合&lt;/strong&gt;和训练过度导致模型复杂度太高（参数多）而&lt;strong&gt;过拟合&lt;/strong&gt;的情况发生。“&lt;strong&gt;控制模型复杂度&lt;/strong&gt;”可以视为机器学习中除了“&lt;strong&gt;让模型的输出结果与实际结果差异最小&lt;/strong&gt;”之外的第二重要的目标。&lt;/p&gt;
&lt;h2 id=&#34;深度学习&#34;&gt;深度学习&lt;/h2&gt;
&lt;p&gt;现代科学已经基本确定了人的视觉系统的信息处理是分级的，从最低级像素提取边缘特征，再到稍高层次的形状或者目标的部分等，再到更高层的整体目标，以及目标的行为和其他特征的联想等。换句话说，&lt;strong&gt;高层的特征是低层特征的组合提炼，从低层到高层的特征表示越来越抽象，越来越能表现出认知的意图。抽象层面越高，存在的可能猜测就越少，就越利于分类&lt;/strong&gt;。 深度学习通过多层神经网络结构模拟了人类处理外界信息的“&lt;strong&gt;分层迭代、逐级抽象&lt;/strong&gt;”过程。这里的关键词有两个，一个是“抽象”，一个是“迭代”，从原始信号输入开始，先做低级的抽象，逐渐向高级抽象迭代。&lt;/p&gt;
&lt;p&gt;深度学习属于神经网络的一个子集，而神经网络又是机器学习的一个分支。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机器学习&lt;/strong&gt;：是让计算机系统通过数据自动“学习”并改进其性能，而无需进行明确编程的能力。机器学习使用算法解析数据，从中学习，并对真实世界中的事件做出决策或预测。机器学习包括多种不同的学习方法和技术，如监督学习、非监督学习、强化学习等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;神经网络&lt;/strong&gt;：是机器学习领域中的一种模型或算法，它受到生物神经系统工作原理的启发，旨在模仿人类大脑处理信息的方式。神经网络由大量的节点（或称“神经元”）组成，这些节点被组织在多个层中，包括输入层、隐藏层和输出层。每个节点与相邻层的节点相连，通过连接权重传递信号。神经网络特别擅长识别复杂的数据模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习&lt;/strong&gt;：是神经网络的一个子集或者说是一种特定类型的神经网络架构。所谓“深度”，指的是网络中含有一个或多个隐藏层，使得网络能够学习数据的更高层抽象表示。深度学习利用了具有多层结构的神经网络，特别是深层神经网络（DNN）、卷积神经网络（CNN，特长：视觉识别）、循环神经网络（RNN，特长：时序依赖性的序列数据）及其变体等，以实现从大量未标注或半标注的数据中学习特征的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;深度学习历史&#34;&gt;深度学习历史&lt;/h3&gt;
&lt;p&gt;人工神经网络（Artificial Neural Network）这个概念最早是在皮茨与麦卡洛克合著的论文《神经活动中内在思想的逻辑演算》中首次提出，随后，由于罗森布拉特和他的感知机引起了全社会的广泛关注，促成了连接主义的第一波热潮。后来由于明斯基对单层神经网络的缺陷证明以及其个人的影响力，而多层神经网络受当时数据和算力规模限制而不可想象，神经网络跌落低谷，很多学术期刊拒绝接受标题中带神经网络字眼的论文。但在以多伦多大学&lt;strong&gt;杰弗里·辛顿&lt;/strong&gt;教授（“深度学习教父”，坐了40年冷板凳）为首的一批神经网络信仰者的共同努力下，神经网络最终以&lt;strong&gt;深度学习&lt;/strong&gt;的面目重返人工智能的舞台，并暂时占据主角地位。由于神经网络曾经在人工智能圈的坏“名声”，他们更愿意被称呼为机器学习下的深度学习，而非人工智能下的神经网络。&lt;/p&gt;
&lt;p&gt;2006年被认为是深度学习时代的元年，是以辛顿在这一年发表的两篇论文为标志的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一篇是《通过神经网络进行数据降维处理》的论文。这里“&lt;strong&gt;数据降维&lt;/strong&gt;”的方法就是用神经网络自动进行&lt;strong&gt;特征选择和提取&lt;/strong&gt;，此文实质性地开创了“深度学习”这个机器学习的新分支。&lt;/li&gt;
&lt;li&gt;第二篇文章《一种基于深度信念网络的快速学习算法》再次对“深度”这个词进行定义和包装，才变得火爆起来的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;辛顿在两篇文章中提出了以下两个主要的观点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多层神经网络具有优异的、自动化的&lt;strong&gt;特征学习&lt;/strong&gt;能力。&lt;/li&gt;
&lt;li&gt;提出&lt;strong&gt;逐层预训练&lt;/strong&gt;的方法来克服深度神经网络在训练上的难度。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;得益于大数据、GPU计算硬件的支持，在 2012 年的 ImageNet 挑战赛中，基于深度学习的 AlexNet 模型以巨大优势赢得了比赛，标志着深度学习时代的到来。可以说&lt;strong&gt;当今基于深度学习大模型的人工智能框架是：数据（人工） + 算力（GPU）+ 算法（模型）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;深度学习三巨头&#34;&gt;深度学习“三巨头”&lt;/h3&gt;
&lt;p&gt;2018年深度学习三巨头因为“在概念和工程方面使深度神经网络成为计算的关键组成部分”而获得图灵奖。辛顿的感言是&amp;quot;我们终于不用再假装在研究别的东西了&amp;quot;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;杰弗里·辛顿&lt;/strong&gt;：深度学习教父，多伦多大学，Google 大脑，误差反向传播算法。在2012年通过改进卷积神经网络（AlexNet）大幅提高了图像识别的准确率，引发了计算机视觉领域的一场革命。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;杨立昆&lt;/strong&gt;：纽约大学，Facebook人工智能研究院创建人，卷积神经网络（CNN）的主要发明者。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;书亚·本希奥&lt;/strong&gt;：蒙特利尔大学，微软研究院的人工智能战略顾问。提出长短期记忆神经网络、词向量，这对自然语言处理产生了重大影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;深度学习祛魅&#34;&gt;深度学习祛魅&lt;/h3&gt;
&lt;p&gt;随着 ChatGPT 和 Deepseek 的爆火，人工智能已经天下闻名，人人趋之若鹜。但深度学习达到了或者说能实现通用人工智能的目标么？我深表怀疑，理由如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;严重依赖大规模的数据&lt;/strong&gt;，“有多少人工就有多少智能”。不仅穷尽每个领域的所有数据既不现实也不是智能的体现，而且带有人类偏见的数据还会引起&lt;strong&gt;算法歧视&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;严重依赖高质量数据的预训练建模&lt;/strong&gt;：不具备迁移或多任务能力。通用人工智能必须能通过少量数据的学习来自发现规律。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不可解释和不可验证&lt;/strong&gt;：由于缺乏理论支持，神经网络算法是一个黑盒/暗箱，对其输出的结果没有可验证的手段，也不具备可解释性。其实现的内部复杂性也不符合奥卡姆剃刀的简约原则（主张选择假设最少的解释）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺少理论基础&lt;/strong&gt;：人类自己都没搞清楚人类大脑是如何思考和学习的。大脑皮质柱是否具有通用统一的基础结构，且这种结构的运作机制是否遵循某种通用算法？智能能否被建模？数学建模如何超越哥德尔不完备定理？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;还原方法论局限&lt;/strong&gt;：复杂系统科学揭示了&lt;strong&gt;涌现现象&lt;/strong&gt;：系统整体表现出的属性无法简单地从其组成部分推导出来。大脑和社会都是典型的复杂自适应系统，而&lt;strong&gt;还原方法论难以完全把握其整体运作机制&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而今的&lt;strong&gt;深度学习本质上是将特征直接映射到基于统计数据建立的模型中概率最大的输出，它更多的是一种计算框架，而非理论框架&lt;/strong&gt;。它不具备采集数据、过滤数据、反思与反馈更新模型、理解意义等能力。尽管深度学习存在上述局限性，它在特定领域已经展现出惊人的能力。在图像识别、自然语言处理和语音合成等方面，深度学习模型已经达到或超越人类水平。它也为医疗诊断、药物发现和气候模拟等领域带来了革命性突破。&lt;/p&gt;
&lt;h2 id=&#34;强化学习&#34;&gt;强化学习&lt;/h2&gt;
&lt;h3 id=&#34;苦涩的教训&#34;&gt;苦涩的教训&lt;/h3&gt;
&lt;p&gt;由于对基于统计的人工智能研究路线的不认同，强化学习之父&lt;strong&gt;理查德·萨顿&lt;/strong&gt;（Rich Sutton）于 2019年在《苦涩的教训》（The Bitter Lesson）一文中认为：&lt;strong&gt;AI研究历史告诉我们，长期来看，最有效的方法不是人为地加入特定知识，而是依靠更通用的方法与越来越强大的计算力&lt;/strong&gt;。他认为&lt;strong&gt;智能是不断根据环境反馈调整行为模式来实现目标的能力&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在该文，萨顿总结了如下经验教训：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过去的误区&lt;/strong&gt;： 人们习惯在人工智能中嵌入大量人类智慧，比如专家经验、规则和统计知识。这在短期内可能提高性能，给研究者带来满足感，但长期来看会限制进步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成功的关键&lt;/strong&gt;： 真正的突破往往是靠大规模的计算资源实现的，而非人工设计的复杂规则。
&lt;ul&gt;
&lt;li&gt;国际象棋的成功，靠的是暴力搜索（穷举搜索）。&lt;/li&gt;
&lt;li&gt;围棋的突破，靠的是大规模自我对弈学习。&lt;/li&gt;
&lt;li&gt;语音识别的进步，靠的是统计模型和循环神经网络（RNN）而非人为特征提取。&lt;/li&gt;
&lt;li&gt;图像识别和计算机视觉的飞跃，靠的是卷积神经网络（CNN）而非人为特征提取。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;萨顿认为应该打造能自主试错、学习世界模型的人工智能，而非直接教给它人类已经知道的东西。可以说，这是一条重新发明人类的过程。未来人工智能的发展方向，最具前途的是“&lt;strong&gt;记忆化搜索&lt;/strong&gt;”：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;记忆&lt;/strong&gt;（memory）：记住以往成功的经验或结果以便在未来的问题解决过程中加以利用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;搜索&lt;/strong&gt;（search）：试错法、生成与测试法、变异与选择法，利用大量计算资源搜索解空间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心特征&#34;&gt;核心特征&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;（Reinforcement Learning, RL）也是一种机器学习方法，它是让智能体（agent）在与环境的交互过程中通过试错来学习，不断优化策略以最大化累积奖励从而达成目标。不同于监督学习和非监督学习，强化学习强调的是智能体在没有明确指导的情况下自主探索环境，并从中学习最佳行为策略。这一过程直接体现了萨顿提到的智能三个核心特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目标导向&lt;/strong&gt;：智能体的终极目标是最大化长期奖励（如赢得游戏、完成复杂任务）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态调整&lt;/strong&gt;：通过试错（Trial-and-Error），智能体学习哪些行为能带来更高奖励，并调整策略（Policy）以趋近最优行为模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反馈驱动&lt;/strong&gt;：奖励信号（Reward）是智能体调整行为的唯一指导。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着计算能力的提升和大数据时代的到来，强化学习与深度学习的结合带来了革命性的变化，使得强化学习成为了当前AI研究和应用的一个重要方向。&lt;/p&gt;
&lt;h3 id=&#34;强化学习双杰&#34;&gt;强化学习双杰&lt;/h3&gt;
&lt;p&gt;2024年图灵奖授予了强化学习领域的两位奠基人：&lt;strong&gt;理查德·萨顿&lt;/strong&gt;和他的导师&lt;strong&gt;安德鲁·巴托&lt;/strong&gt;（Andrew Barto）。巴托和萨顿的研究成果不仅奠定了强化学习的理论基础，还促进了这一领域的实际应用。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在棋类竞赛中，AlphaZero 利用了强化学习技术击败了世界顶级围棋选手；&lt;/li&gt;
&lt;li&gt;在机器人控制方面，强化学习使机器人能够自主学习完成复杂任务；&lt;/li&gt;
&lt;li&gt;在自动驾驶领域，它也在路径规划和决策制定中发挥了重要作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;actor-critic-架构&#34;&gt;Actor Critic 架构&lt;/h4&gt;
&lt;p&gt;Actor Critic 架构是巴托和萨顿获奖的作品之一。它是一种&lt;strong&gt;结合了价值方法和策略梯度方法&lt;/strong&gt;优点的强化学习架构。它由两个主要组件组成：&lt;strong&gt;Actor&lt;/strong&gt; 和 &lt;strong&gt;Critic&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Actor&lt;/strong&gt;：负责学习采取何种行动（即&lt;strong&gt;策略&lt;/strong&gt;）。它决定了在给定状态下应该执行的动作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic&lt;/strong&gt;：&lt;strong&gt;评估&lt;/strong&gt;这个动作的好坏，也就是评估当前策略的好坏。具体来说，Critic 通过估计从当前状态开始遵循该策略所能获得的回报来评价 Actor 的选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在该框架下，模型与环境交互并观察，但不是用交互的直接结果当作激励，而是&lt;strong&gt;根据自己的价值函数（价值观）来评估直接结果与长期回报之间的差距，从而调整策略&lt;/strong&gt;。引入价值方法，就是要人工智能能关注长期回报而非短期奖励。用萨顿的话来说就是：&amp;ldquo;In reinforcement learning, rewards are sparse, but the returns can be rich.&amp;quot;（&lt;strong&gt;在强化学习中，奖励虽稀疏，然回报却可丰厚&lt;/strong&gt;）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;结语在火焰与镜子之间人工智能的认知革命&#34;&gt;结语：在火焰与镜子之间——人工智能的认知革命&lt;/h2&gt;
&lt;p&gt;物理学家马克斯·普朗克说，“&lt;strong&gt;科学每经历一次葬礼就前进一步&lt;/strong&gt;。”人工智能的发展历程是“&lt;strong&gt;瓶颈-探索-突破&lt;/strong&gt;”的循环：每一次低谷都催生了新的技术方向，而每一次高潮都离不开先驱者的坚持与跨学科的协作。无论是符号主义的严谨逻辑、连接主义的生物仿生，还是行为主义的互动反馈，三大流派的竞争与融合，共同勾勒出人类探索智能疆域的壮丽图景。&lt;/p&gt;
&lt;p&gt;人工智能七十载跌宕起伏的探索史，&lt;strong&gt;本质上是人类在数学约束与哲学迷思中寻找自我认知镜像的过程&lt;/strong&gt;，恰似普罗米修斯盗火与纳西索斯临镜的双重寓言：我们既在创造照亮未知疆域的技术之火，也在算法之境中不断重构对人类意识的认知。这场无止境的探索终将证明：每次试图定义人工智能的尝试，都是对人类认知边界的重新丈量。就像古希腊人在德尔斐神庙镌刻的箴言：&amp;ldquo;认识你自己&amp;rdquo;，人工智能时代的终极命题，依然是那些连人类自己都尚未弄明白的终极哲思：何为智能？、何为意识？、何为人类？&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>人工智能：对涌现与智能的再思考</title>
      <link>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</link>
      <pubDate>Sat, 15 Feb 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</guid>
      
        <description>&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;p&gt;一年前在粗略了解 Sora 之后发表了对通用人工智能（AGI） 的粗浅看法（见&lt;a href=&#34;https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/&#34;&gt;人工智能：Sora 随感&lt;/a&gt;)，经过对 AGI 知识的学习之后，再次刷新对 Scaling Law、Transformer 以及智能/涌现的理解，因此有了此文以更新对这个知识点的“模型参数”（一年前我对 AGI 能否达到涌现是存疑的，现在转变为肯定）。都说大道至简，但精准简化岂是常人所能，我只好在通俗与严谨之间，弃严谨而取通俗。下面就是用通俗的方式来讲述我对人工智能架构主要思想的新理解。&lt;/p&gt;
&lt;h3 id=&#34;scaling-law-与涌现&#34;&gt;Scaling Law 与涌现&lt;/h3&gt;
&lt;p&gt;Scaling Law 描述了数据规模、计算资源和模型参数对 AI 模型的影响。大模型之所要大，是因为只有当模型的训练（样本）数据和参数大到突破一定的临界值后，才可能涌现出一些不可预测、更复杂的能力和特性，而进行这样大规模的训练又依赖于大规模的计算资源。这等规模的模型能够从原始训练数据中自动学习并发现或发明新的、更高层次的特征和模式，这种能力被称为“&lt;strong&gt;涌现（Emergence）&lt;/strong&gt;”。随着科技的进步，曾经被认为难以突破的计算和数据限制，将来一定会是可控和可实现的。从本质上讲，Scaling Law 不是决定 AI 智能形态的根本因素，而是影响其发展的&lt;strong&gt;资源门槛&lt;/strong&gt;。但就像“巧妇难为无米之炊”，即使有再先进的模型架构，也需要规模足够大的数据和计算能力来达到涌现所需的阈值。此外，涌现现象的出现通常依赖于大规模个体之间的相互作用，只有在规模足够大的个体之间的&lt;strong&gt;非线性关系&lt;/strong&gt;才可能催生出&lt;strong&gt;整体大于部分之和&lt;/strong&gt;的智能表现。&lt;/p&gt;
&lt;h3 id=&#34;transformer-与智能&#34;&gt;Transformer 与智能&lt;/h3&gt;
&lt;p&gt;可以说&lt;strong&gt;世界是一个基于贝叶斯定理的概率（经验）大模型（推理在经验之上）&lt;/strong&gt;。关于贝叶斯定理，多年以前我写过一篇《从贝叶斯定理说开去》的文章，互联网应该还有这个记忆。通俗地讲，&lt;strong&gt;贝叶斯定理就是根据新的观察结果来调整由过去学习到的经验概率值&lt;/strong&gt;。比如：猎人在某片树林连续三天发现猎物群，于是猎人习得经验（逐天增加这片树林发现猎物的概率），当然猎物群也会调整自身的经验（逐步增加这片树林的危险性概率）。&lt;/p&gt;
&lt;p&gt;展开说说经验与推理，西方经典哲学分两派：英国经验主义与大陆唯理主义。这可以用来类比大模型的两种实现思路：经验概率和逻辑推理，经验概率不是绝对可靠的，需要逻辑推理来引导和试错，两相结合就完美了。&lt;/p&gt;
&lt;p&gt;因此&lt;strong&gt;智能可以简化理解为从环境中自主学习、调整和应用经验的能力（反思过去、改变现在、规划未来）&lt;/strong&gt;。如果说 Scaling Law 解决大模型之“大”的问题（大才可能有足够多的相关性概率参数来突破涌现所需的阈值），那么 Transformer 就是要解决基于贝叶斯定理的概率问题，通俗地说就是解决经验问题（表现为智能，表征为模型参数）：参数从哪来？参数怎么调整？参数怎么评估？参数怎么应用？参数怎么存储？Transformer 中的对这些问题的解决机制非常巧妙与精细，也非常专业，在此不展开细述（遇事不决，问 AI 啊）。&lt;/p&gt;
&lt;h3 id=&#34;通俗解读-transformer-架构&#34;&gt;通俗解读 Transformer 架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://opensource.niutrans.com/niutensor/Transformer/1.png&#34; alt=&#34;Transformer 架构图&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上图是 Transformer 架构图，下面我以一群红学爱好者研读和续写《红楼梦》为类比对这个架构图进行通俗的解读。&lt;/p&gt;
&lt;h4 id=&#34;1-自注意力机制--大观园诗社品评会&#34;&gt;1. 自注意力机制 → 大观园诗社品评会&lt;/h4&gt;
&lt;p&gt;想象一下大观园内一群红学爱好者组成品评社，将所有《红楼梦》词句都制作成考据卡片（词向量），同时对所有卡片进行研读解析。当解析&amp;quot;黛玉葬花&amp;quot;时：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分席研读&lt;/strong&gt;：品评社分设八张茶案（多头注意力），一席专研葬花词韵律，一席考据花锄形制，一席探讨谶语隐喻，终将各席见解汇成《葬花十论》。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局索引&lt;/strong&gt;：&amp;ldquo;葬花&amp;quot;自动关联第五回&amp;quot;花冢&amp;rdquo;、二十七回&amp;quot;泣残红&amp;quot;，如同全局雷达可以扫描全文查找互文线索（长程依赖）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-位置编码--脂批本页码钤印&#34;&gt;2. 位置编码 → 脂批本页码钤印&lt;/h4&gt;
&lt;p&gt;为防止混淆章回时序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位置编码&lt;/strong&gt;：每张考据卡片背后加注出处信息：本子+回数+段落，如&amp;quot;甲戌本第三回第十段&amp;quot;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;周期性特征编码&lt;/strong&gt;：不同版本（如甲戌本、程乙本、蒙府本）用青赤墨色区分（正弦波编码的周期性特征）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-前馈神经网络--金陵十二钗品藻堂&#34;&gt;3. 前馈神经网络 → 金陵十二钗品藻堂&lt;/h4&gt;
&lt;p&gt;每完成一轮研讨后，带着解读成果进入下一轮研读（&lt;strong&gt;分层迭代，逐层抽象&lt;/strong&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特质解经&lt;/strong&gt;：将&amp;quot;宝钗&amp;quot;拆解为&amp;quot;冷香丸药理&amp;quot;、&amp;ldquo;金锁谶语&amp;rdquo;、&amp;ldquo;蘅芜苑陈设&amp;quot;等维度（GeLU激活的&lt;strong&gt;特征提取&lt;/strong&gt;：特征放大镜），如同将&amp;quot;冷香丸&amp;quot;分解为白牡丹花蕊、白荷花蕊等十二味药材。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;芜杂筛除&lt;/strong&gt;：剔除如&amp;quot;黛玉用药中的人参是否产自辽东&amp;quot;等细枝末节，保留&amp;quot;疾病作为命运隐喻&amp;quot;的核心命题（&lt;strong&gt;特征蒸馏&lt;/strong&gt;：噪声过滤器）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-残差连接--程乙本朱丝栏夹批&#34;&gt;4. 残差连接 → 程乙本朱丝栏夹批&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;底本存真&lt;/strong&gt;：必须在原本上直接写批注（残差连接），不能另起新纸，防止偏离原文而导致过度阐释（语义漂移）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;体例规整&lt;/strong&gt;：在每一层研读完成后，按《校勘学通则》（层归一化公式）调整特征值分布，使&amp;quot;诗词鉴赏分&amp;quot;与&amp;quot;器物考据分&amp;quot;处于可比量纲。这确保不会因为某一席的研读过于精彩而剑走偏锋。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;5-自回归生成--芹溪草堂续书接龙&#34;&gt;5. 自回归生成 → 芹溪草堂续书接龙&lt;/h4&gt;
&lt;p&gt;仿高鹗续写后四十回：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;前文锁钥&lt;/strong&gt;：续写&amp;quot;黛玉之死&amp;quot;时后续稿页封存（掩码机制），仅可参看前八十回伏笔。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;笔削春秋&lt;/strong&gt;：若有人续&amp;quot;宝玉修仙&amp;rdquo;，系统自动改为&amp;quot;宝玉中举&amp;quot;，如同脂砚斋批&amp;quot;此回未成而芹逝矣&amp;quot;的遗憾修补。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;6-智能表现--脂砚斋大数据评点&#34;&gt;6. 智能表现 → 脂砚斋大数据评点&lt;/h4&gt;
&lt;p&gt;模型智慧源于红学百年积淀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;套路总结&lt;/strong&gt;：统计十万条脂批发现&amp;quot;凡&amp;rsquo;赤瑕宫&amp;rsquo;出现必关联&amp;rsquo;宝玉疯癫&amp;rsquo;&amp;quot;（注意力模式挖掘）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;笔补造化&lt;/strong&gt;：要求&amp;quot;描绘潇湘馆AI设计图&amp;quot;，系统融合&amp;quot;竹影纱窗+药炉棋枰+鹦鹉念诗&amp;quot;（跨模态生成），如同将大观园图样与《园冶》营造法式结合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么这套机制能成功&#34;&gt;为什么这套机制能成功？&lt;/h3&gt;
&lt;p&gt;这套机制能成功运作的关键在三组学术张力的平衡：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;索隐与实证&lt;/strong&gt;：注意力机制允许&amp;quot;索隐派&amp;quot;式发散联想（如将&amp;quot;甄士隐&amp;quot;解读为&amp;quot;真事隐&amp;quot;），残差连接确保不违&amp;quot;作者本意&amp;quot;（文本约束）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微观与宏观&lt;/strong&gt;：既见&amp;quot;晴雯病补雀金裘&amp;quot;（局部特征），又悟&amp;quot;千红一哭&amp;quot;悲剧基调（全局视野）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流派与共识&lt;/strong&gt;：各注意力头如不同红学流派（评点派、考证派、索引派），最终通过加权投票形成主流阐释&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Transformer 本质是&lt;strong&gt;大数据驱动的统计智能&lt;/strong&gt;。其运作机制就好比组建了一个超级红学研究团队：有考据达人（自注意力）、有版本比对家（位置编码）、有主题提炼师（前馈网络）、有体例规范官（层归一化），所有人都遵循《红楼梦校勘学》（Transformer架构），产出既承曹雪芹本真、又具当代精神的续书方案。这种智能，在总体效果上就是达成文献学与阐释学的动态平衡——既能考据&amp;quot;枫露茶事件&amp;quot;版本异文，又能提炼&amp;quot;悲金悼玉&amp;quot;的永恒母题。这在红学中体现为&amp;quot;大胆探佚，小心求证&amp;quot;；在数学上对应&amp;quot;既要发散（拓展阐释维度），又要收敛（遵循文本边界）&amp;quot;；工程上实现为&amp;quot;在多轮讨论迭代的梯度中寻求最优续写路径&amp;quot;。也就是说既要有足够的探索空间来发现新模式，又要有一定的约束来避免无意义的生成。用头脑风暴的过程来类比：第一阶段发散思维，探索尽可能多的可能性；第二阶段筛选和收敛，确保输出合理有用。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;gpt&#34;&gt;GPT&lt;/h3&gt;
&lt;p&gt;GPT 系列大语言模型是站在 Transformer 的肩膀上，且只用解码器部分。它本质上就是一个用来估计文本概率分布的数学模型，它通过大规模预训练足够多的文本序列统计得到 token 在自然语言中不同维度上的相关性概率的数据库（基础模型），因此就能够根据已生成的文本，预测下一个最可能（概率最大）出现的汉字或单词。因而它是&lt;strong&gt;一种基于统计的概率模型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;展望&#34;&gt;展望&lt;/h3&gt;
&lt;p&gt;当今的大模型的主要成就还集中在知识密集型领域，但多模态模型和基于思维链的推理模型都已初具规模。以 AI 的发展速度，不用多久人形（具身）智能体便可以落地。到那时，人形智能体能自动从世界环境中获取数据、交互作用、积累经验，并因独特的成长轨迹习得独特的个体经验。无数这样的个体相互作用再涌现出某种非凡能力，这种能力有可能都不属于人类知识范围了。人形智能体的出现，还能给人留下了什么地盘？或许如康德给理性划界从而为信仰留出地盘一样，有了这些替人代劳部分功能的人形智能体，&lt;strong&gt;人类能更纯粹地思考人之所以为人的独特之处&lt;/strong&gt;。所以，何以为人？康德式的道德律？意义信仰？亦或是欲望？&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>人工智能：Sora 随感</title>
      <link>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</link>
      <pubDate>Thu, 22 Feb 2024 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</guid>
      
        <description>&lt;h2 id=&#34;sora-做了什么&#34;&gt;Sora 做了什么&lt;/h2&gt;
&lt;p&gt;基于目前公开的信息 Sora 模型奠基于两大原理之上：Transformer 与 Scaling Law。前者本质就是换个角度看问题，使得跨领域建模及其处理更为一致、高效，一如：频率和概率，直角坐标系和极坐标系，大数据常用的矩阵变换等等；后者就是大力出奇迹的规模效应：模型大，数据多，算力强，那效果就更好（是否能达到涌现的程度存疑）。个人感觉前者使“通用”成为可能，后者使“智能”成为可能。Sora 强大之处是仅通过学习人类产生的视频（仅视觉、听觉、字幕），就能产生&lt;strong&gt;世界模拟器&lt;/strong&gt;的四维视频。但我不认为它从中推理出牛顿定律或能量守恒定律等，进而根据这些理论来构建四维世界视频，它仅仅是通过大数据分析在可能性空间中选择相关关系最大的情景。&lt;/p&gt;
&lt;h2 id=&#34;指数级速度&#34;&gt;指数级速度&lt;/h2&gt;
&lt;p&gt;通用人工智能（AGI）的演进速度将呈指数级增长。参照人类历史发展的时间间隔便可直观感受这惊人的速度：从以万年为单位的农业革命，到以千年为单位的工业革命，到以百年为单位的计算机革命，再到以十年为单位的互联网革命，以及以年为单位的智能革命。仅用了几年时间 AGI 就实现从文字（ChatGPT）、到图片（DALL·E ）、再到视频（Sora）的模拟生成。这还是在只具备基于相关的概率归纳能力，不具备基于因果的理解演绎能力的情况下发生的。可以预见，随着AGI自迭代能力（数据自采集、模型自编程）的发展，其演进速度将以天以秒为单位，这将极大地挑战人类社会的适应能力。随着实现途径变得越来越强大与便捷，未来，想法为王。以前因人类在生理与环境、文化的演化速度上不匹配而造成一些认知谬误，人们常会说：我们是生活在信息时代的原始人，不久人们将会说：我们是生活在智能时代的动物。&lt;/p&gt;
&lt;h2 id=&#34;风险与收益&#34;&gt;风险与收益&lt;/h2&gt;
&lt;p&gt;阴阳之道，祸福相依。效率与公平、收益与风险，前者常在明处、近处，后者常在隐处、远处。“遥遥领先”的 OpenAI 在激进的奥特曼的带领下对安全与非营利并没有那么看重，是福还是祸？随着通用人工智能以指数级的速度演进而来的很可能是认知差距、贫富差距等也以指数级的速度扩大，智能替代还可能造成大量的“无用”人。《新约·马太效应]》说：“凡有的，还要加倍给他叫他多余；没有的，连他所有的也要夺过来。”如果迷信激进的科学教，而缺少必要的人文关怀和宽容，二八定律变成一比九九九定律，在我们有生之年是很可能见到的。这将对人类社会的治理、道德文化、生存意义带来极大的挑战。到目前为止，人性阴阳之道（贪婪与恐惧）的转换是人类文明不被毁灭的保障（即便疯狂如希特勒，其同归于尽的毁灭计划也被抵制没有得到执行，他本人也至少两次被德国军官暗杀未遂）。但倘若出现了非人类新型智能文明，或人机智能合体文明呢？&lt;/p&gt;
&lt;h2 id=&#34;具备自我意识的智能机器人&#34;&gt;具备自我意识的智能机器人&lt;/h2&gt;
&lt;p&gt;具有自我意识或者情感的智能机器人是可能的。一个可以更新智能算法模型和基础数据包的具备五感的通用人形机器人就如一个新生儿，在生存与成长这两大框架下，在特定环境中去执行人类赋予的某些使命或职责。在这个特定环境中不断交互学习形成独一无二的本地数据包，且形成为不同数据赋有不同权重的信息网络，一如每个人独特的成长经历（记忆）。加权的信息网络对主题是有偏好的，且本地数据包的使用优先于内置的通用基础数据包，从而智能机器人可以具有偏好，形成情感，达成自我意识。&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
