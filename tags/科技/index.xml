<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>科技 on 飘飘白云：所读，所观，所思</title>
    <link>https://luozhaohui.github.io/tags/%E7%A7%91%E6%8A%80/</link>
    <description>Recent content in 科技 on 飘飘白云：所读，所观，所思</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 26 Apr 2025 14:14:00 +0800</lastBuildDate><atom:link href="https://luozhaohui.github.io/tags/%E7%A7%91%E6%8A%80/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>《大爆炸简史》：宇宙观的范式革命</title>
      <link>https://luozhaohui.github.io/post/2025/2025-04-26-big-bang/</link>
      <pubDate>Sat, 26 Apr 2025 14:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-04-26-big-bang/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;《大爆炸简史》由西蒙·辛格撰写，讲述了“大爆炸理论”从提出到被广泛接受的历史。大爆炸模型是集体智慧的历史结晶，凝聚了哥白尼、第谷、开普勒、伽利略、爱因斯坦、勒迈特、哈勃、伽莫夫、霍伊尔等科学家的贡献。这一理论揭示了宇宙的起源，是人类智慧的重大成就。书中通过科学家的探索与争论，展现了大爆炸理论如何从边缘假说成为现代宇宙学的核心。&lt;/p&gt;
&lt;h2 id=&#34;科学思想的萌芽&#34;&gt;科学思想的萌芽&lt;/h2&gt;
&lt;p&gt;人类对宇宙起源的追问始于远古神话，但真正以理性探索自然规律始于古希腊。古希腊哲学家如哲学家&lt;strong&gt;色诺芬&lt;/strong&gt;与&lt;strong&gt;阿那克西曼德&lt;/strong&gt;摒弃神创论，提出自然现象可通过观察与逻辑解释。亚历山大图书馆馆长&lt;strong&gt;埃拉托色尼&lt;/strong&gt;通过日影测量地球的周长和半径，进而通过月食测量出月球半径以及地月距离，进而根据半月相测量出日地距离，最后根据日全食测量出太阳半径，这充分证明了科学方法的威力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;阿里斯塔克斯&lt;/strong&gt;首次提出&lt;strong&gt;日心说&lt;/strong&gt;，却因缺乏实证沉寂千年。&lt;strong&gt;托勒密&lt;/strong&gt;的&lt;strong&gt;地心模型&lt;/strong&gt;凭借复杂但实用的预测能力，成为中世纪天文学圭臬。16世纪，哥白尼在《天球运行论》中复兴&lt;strong&gt;日心说&lt;/strong&gt;，但因预测精度不足未被重视。&lt;strong&gt;第谷·布拉赫&lt;/strong&gt;的精密观测数据经&lt;strong&gt;开普勒&lt;/strong&gt;分析，揭示行星轨道实为椭圆，修正了日心说的核心假设。&lt;strong&gt;伽利略&lt;/strong&gt;则通过望远镜发现木星卫星与金星相位，为日心说提供了直观证据。尽管教会压制，科学革命的浪潮已不可阻挡。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>《千脑智能》：重新定义智能的神经科学之旅</title>
      <link>https://luozhaohui.github.io/post/2025/2025-04-04-a-thousand-brains/</link>
      <pubDate>Fri, 04 Apr 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-04-04-a-thousand-brains/</guid>
      <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;杰夫·霍金斯在《千脑智能》中展现了一场颠覆性的思想实验。这位兼具神经科学家与科技企业家双重身份的学者，以其对大脑数十年的研究积累，向主流人工智能范式发起挑战，试图在生物智能的奥秘中挖掘出一条通向通用人工智能（AGI）的新路径。这部著作不仅是一本关于大脑运作机制的科普读物，更是一份充满野心的技术宣言——它试图重新定义人类对“智能”的理解，并在神经科学与计算机科学的鸿沟上架起一座桥梁。&lt;/p&gt;
&lt;h2 id=&#34;一从预测到智能一场认知革命的核心命题&#34;&gt;一、从预测到智能：一场认知革命的核心命题&lt;/h2&gt;
&lt;p&gt;霍金斯的理论起点建立在对传统人工智能的反思之上。当深度学习依赖海量数据训练模型、强化学习沉迷于试错反馈的奖励机制时，他敏锐地捕捉到一个被忽视的核心问题：&lt;strong&gt;人类智能的本质并非对已有模式的识别，而是对未知世界的预测能力&lt;/strong&gt;。书中以视觉感知为例展开论证：当我们看到咖啡杯的局部把手时，大脑并非被动接收图像信号，而是通过多层皮质的联动，瞬间激活关于“杯体”、“材质”、“功能”的预测模型，并在毫秒内验证这些假设是否与感官输入匹配。&lt;strong&gt;这种“预测-验证-修正”的动态循环，构成了贯穿全书的“层级预测编码”理论框架&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;为了支撑这一假说，霍金斯将神经科学的最新发现编织成严密的证据链。从啮齿类动物海马体定位细胞的电生理实验，到人类视觉皮层对模糊图像的补全机制，这些跨物种、跨脑区的实证研究共同指向一个结论：&lt;strong&gt;大脑本质上是一台多层级联的预测机器&lt;/strong&gt;。更令人惊叹的是，他进一步提出“&lt;strong&gt;参考系&lt;/strong&gt;”概念——每个神经元群都在构建类似空间坐标系的认知框架，使得抽象概念（如“民主制度”）与具体物体（如“书桌”）都能以统一模式进行编码。这种将空间感知与概念表征统一的理论突破，为解释人类独有的抽象思维能力提供了新视角。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>人工智能发展之潮起潮落</title>
      <link>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</link>
      <pubDate>Sat, 15 Mar 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</guid>
      <description>&lt;h2 id=&#34;前言在迷雾中寻找光的轨迹&#34;&gt;前言：在迷雾中寻找光的轨迹&lt;/h2&gt;
&lt;p&gt;人工智能的演进史是一部充满悖论的启示录：图灵用停机问题为计算划定边界，却意外点燃了智能革命的导火索；罗森布拉特的感知机本欲模仿神经元放电，最终却演变成深度学习中抽象的矩阵运算；辛顿在冷板凳上坚守神经网络四十年，等来的却是算力与数据暴力破解智能密码的&amp;quot;苦涩教训&amp;quot;。这些戏剧性的转折揭示着一个残酷的真相：&lt;strong&gt;我们对智能的理解，始终在知其然与不知其所以然之间徘徊&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当下人工智能狂欢背后暗涌着深刻的认知危机：当 &lt;code&gt;GPT-4&lt;/code&gt; 能通过律师资格考试却无法理解“正义”的哲学内涵，当&lt;code&gt;Stable Diffusion&lt;/code&gt;创作出媲美莫奈的画作却对光影美学毫无感知，我们不得不追问——这究竟是智能的曙光，还是复杂曲线拟合制造的认知幻觉？&lt;/p&gt;
&lt;p&gt;这次人工智能“考古”之旅，既是向那些在寒冬中守护火种的先驱者致敬（从图灵到辛顿），更是对当下AI神话的祛魅仪式。在本文中，我们将看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神经网络惊人的抽象能力背后，是&lt;strong&gt;统计学&lt;/strong&gt;对有机生物体智能表现的粗糙模拟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Transformer&lt;/code&gt;架构的革命性突破，本质是利用&lt;strong&gt;预训练机制&lt;/strong&gt;对大规模数据的概率特征的&lt;strong&gt;高效建模&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;强化学习的&lt;strong&gt;试错进化&lt;/strong&gt;，也不过是达尔文主义在数字世界的投影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这个深度学习主导的“暴力美学”时代，重访人工智能发展的潮起潮落，不仅是为了理解技术演进的内在逻辑，更是为了在算法黑箱与人类认知的裂隙中，寻找智能本质的蛛丝马迹。本文将系统地&lt;strong&gt;梳理人工智能发展的三次高潮与两次低谷，剖析符号主义、连接主义、行为主义三大流派的哲学分野&lt;/strong&gt;，并探讨哥德尔不完备定理对强人工智能的理论约束。通过跨学科的视角，试图在数学的严谨、神经科学的实证与哲学的思辨之间，勾勒人工智能演进的探索过程以及可能图景。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>人工智能：对涌现与智能的再思考</title>
      <link>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</link>
      <pubDate>Sat, 15 Feb 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</guid>
      <description>&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;p&gt;一年前在粗略了解 Sora 之后发表了对通用人工智能（AGI） 的粗浅看法（见&lt;a href=&#34;https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/&#34;&gt;人工智能：Sora 随感&lt;/a&gt;)，经过对 AGI 知识的学习之后，再次刷新对 Scaling Law、Transformer 以及智能/涌现的理解，因此有了此文以更新对这个知识点的“模型参数”（一年前我对 AGI 能否达到涌现是存疑的，现在转变为肯定）。都说大道至简，但精准简化岂是常人所能，我只好在通俗与严谨之间，弃严谨而取通俗。下面就是用通俗的方式来讲述我对人工智能架构主要思想的新理解。&lt;/p&gt;
&lt;h3 id=&#34;scaling-law-与涌现&#34;&gt;Scaling Law 与涌现&lt;/h3&gt;
&lt;p&gt;Scaling Law 描述了数据规模、计算资源和模型参数对 AI 模型的影响。大模型之所要大，是因为只有当模型的训练（样本）数据和参数大到突破一定的临界值后，才可能涌现出一些不可预测、更复杂的能力和特性，而进行这样大规模的训练又依赖于大规模的计算资源。这等规模的模型能够从原始训练数据中自动学习并发现或发明新的、更高层次的特征和模式，这种能力被称为“&lt;strong&gt;涌现（Emergence）&lt;/strong&gt;”。随着科技的进步，曾经被认为难以突破的计算和数据限制，将来一定会是可控和可实现的。从本质上讲，Scaling Law 不是决定 AI 智能形态的根本因素，而是影响其发展的&lt;strong&gt;资源门槛&lt;/strong&gt;。但就像“巧妇难为无米之炊”，即使有再先进的模型架构，也需要规模足够大的数据和计算能力来达到涌现所需的阈值。此外，涌现现象的出现通常依赖于大规模个体之间的相互作用，只有在规模足够大的个体之间的&lt;strong&gt;非线性关系&lt;/strong&gt;才可能催生出&lt;strong&gt;整体大于部分之和&lt;/strong&gt;的智能表现。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>人工智能：Sora 随感</title>
      <link>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</link>
      <pubDate>Thu, 22 Feb 2024 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</guid>
      <description>&lt;h2 id=&#34;sora-做了什么&#34;&gt;Sora 做了什么&lt;/h2&gt;
&lt;p&gt;基于目前公开的信息 Sora 模型奠基于两大原理之上：Transformer 与 Scaling Law。前者本质就是换个角度看问题，使得跨领域建模及其处理更为一致、高效，一如：频率和概率，直角坐标系和极坐标系，大数据常用的矩阵变换等等；后者就是大力出奇迹的规模效应：模型大，数据多，算力强，那效果就更好（是否能达到涌现的程度存疑）。个人感觉前者使“通用”成为可能，后者使“智能”成为可能。Sora 强大之处是仅通过学习人类产生的视频（仅视觉、听觉、字幕），就能产生&lt;strong&gt;世界模拟器&lt;/strong&gt;的四维视频。但我不认为它从中推理出牛顿定律或能量守恒定律等，进而根据这些理论来构建四维世界视频，它仅仅是通过大数据分析在可能性空间中选择相关关系最大的情景。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
