<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>科技 on 飘飘白云：所读，所观，所思</title>
    <link>https://luozhaohui.github.io/tags/%E7%A7%91%E6%8A%80/</link>
    <description>Recent content in 科技 on 飘飘白云：所读，所观，所思</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 07 Jun 2025 11:14:00 +0800</lastBuildDate>
    
        <atom:link href="https://luozhaohui.github.io/tags/%E7%A7%91%E6%8A%80/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>双缝实验——窥探量子世界的奇异之门</title>
      <link>https://luozhaohui.github.io/post/2025/2025-06-07-double-slit-experiment/</link>
      <pubDate>Sat, 07 Jun 2025 11:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-06-07-double-slit-experiment/</guid>
      
        <description>&lt;h2 id=&#34;双缝实验窥探量子世界的奇异之门&#34;&gt;双缝实验——窥探量子世界的奇异之门&lt;/h2&gt;
&lt;p&gt;“我不会用任何熟悉的事物做类比，只是单纯地描述。”物理学家理查德·费曼曾这样警告我们。他称双缝实验“将让你直面大自然的自相矛盾、神秘莫测和稀奇古怪”。《&lt;a href=&#34;https://book.douban.com/subject/36893049/&#34;&gt;双缝实验和量子力学&lt;/a&gt;》一书正是围绕“双缝实验”这个量子物理中最不可思议的实验及其不断演化的版本展开。本书并没有覆盖量子力学所有领域（如量子隧穿、超弦理论、量子宇宙、量子引力或量子计算），而是聚焦于通过双缝实验及其衍生实验揭示出来的那些最令人惊奇、彻底颠覆常规直觉的量子现象和核心理论发展。&lt;/p&gt;
&lt;h3 id=&#34;从光波到物质波量子思想的萌芽&#34;&gt;从光波到物质波：量子思想的萌芽&lt;/h3&gt;
&lt;p&gt;19世纪，麦克斯韦的统一理论证明了光是一种电磁波，它依赖遍布空间的“场”概念：粒子是局域的，场却能弥漫扩散，影响远方。然而，世纪初赫兹等人的“光电效应”实验却强烈暗示光也具有粒子的特性：光的能量似乎只能一包一包地被打出来。1905年，爱因斯坦基于此提出“光量子”（光子）假说，认为光以离散的能量包（量子）形式存在。正是这一开创性工作，而非相对论，使他在1921年荣获诺贝尔物理学奖。与此同时，玻尔的原子模型指出，围绕原子核运动的电子轨道也是量子化的，只能占据特定的能级。光的这种“既是波又是粒子”的波粒二象性，让德布罗意在1924年提出了一个惊人的推广：所有实体物质粒子（如电子）也应具有波动的性质！他给出了物质波波长与其动量的关系（德布罗意公式）。&lt;/p&gt;
&lt;h3 id=&#34;数学描述波函数与量子体系的演化&#34;&gt;数学描述：波函数与量子体系的演化&lt;/h3&gt;
&lt;p&gt;如何定量描述量子世界的奇特行为？以海森堡、波恩和约尔当为代表的物理学家创立了矩阵力学，侧重计算各种测量结果的出现概率。狄拉克对此做了重要提炼和统一。而偏好形象直观的薛定谔则基于“物质是波”的观念，在1926年创立了波动力学，写出了核心方程——薛定谔方程。这个方程是量子力学的动力学基础，用数学语言描述量子体系的状态（用希腊字母 ψ 表示，音普西，称为波函数）如何随时间演化。玻恩随即对波函数ψ做出了关键诠释：|ψ|²代表了在空间中某点发现粒子的概率。因此，ψ也被称为概率波。冯·诺伊曼不久后严格证明了波动力学与矩阵力学在数学上是完全等价的，殊途同归。&lt;/p&gt;
&lt;h3 id=&#34;核心诡异测量不确定与互补&#34;&gt;核心诡异：测量、不确定与互补&lt;/h3&gt;
&lt;p&gt;在探索薛定谔方程解和量子物理基础的过程中，海森堡于1927年提出了著名的不确定性原理（测不准原理）：不可能同时精确确定一个粒子的位置和动量。玻尔则更进一步，发展出互补原理，认为微观客体的波动性与粒子性并非矛盾，而是相互补充的描述，任何试图同时观测这两种属性的实验装置都是自相矛盾的。不确定性原理被玻尔视为互补原理的一个具体体现。在1927年的著名索尔维会议上，以玻尔、海森堡和泡利为核心所倡导的这一套观点，被总结为量子力学的哥本哈根诠释，成为早期最主流的解释。&lt;/p&gt;
&lt;h3 id=&#34;双缝实验的量子升级单粒子实验验证幽灵行为&#34;&gt;双缝实验的量子升级：单粒子实验验证幽灵行为&lt;/h3&gt;
&lt;p&gt;传统双缝实验用光照射两条狭缝，会在屏幕上出现明暗相间的干涉条纹，这被理解为光波通过双缝后相互叠加（干涉）的结果。但量子力学预言，即使把光（或电子、原子）减弱到一次只发射一个粒子，经过长时间积累，单个粒子仍然能在屏幕上展现出干涉条纹！仿佛每个粒子同时通过了两条缝，并与自身发生干涉！阿斯佩等人是成功实现高精度单光子双缝实验的先驱。在量子世界，干涉是单个粒子自身行为的体现。&lt;/p&gt;
&lt;h3 id=&#34;非定域性与量子纠缠幽灵般的超距作用&#34;&gt;非定域性与量子纠缠：幽灵般的超距作用&lt;/h3&gt;
&lt;p&gt;经典物理坚信局域性（影响最快只能以光速传播）。然而，量子力学预言了一种奇特现象：两个（或多个）粒子相互作用后，会形成一种量子关联态。无论它们相隔多远，对其中一个粒子进行测量，会瞬间决定另一个粒子的状态（或状态的可能性），这种关联仿佛超越了时空限制！爱因斯坦敏锐地察觉出这种“幽灵般的超距作用”违背局域性；薛定谔也独立地深入研究了这种关联态，并在1935年将其命名为纠缠态。同年，追求实在论（粒子具有独立于测量的属性）和定域性的爱因斯坦、波多尔斯基、罗森（EPR）在著名论文中以此纠缠现象为论据，认为量子力学不完备，可能存在隐藏的变量（隐变量）决定了粒子的真实状态。值得注意的是，早在1932年，冯·诺伊曼曾给出一个数学证明宣称隐变量不可能存在。但这个证明因其依赖的某些假设存在争议而被质疑。&lt;/p&gt;
&lt;p&gt;为了验证隐变量理论是否可行，1964年，物理学家贝尔基于EPR论文和玻姆提出的“自旋相关”思想实验版本，提出了划时代的贝尔定理。该定理表明，如果存在满足局域性和实在性的隐变量理论，其预测必须满足一个特定的数学不等式（贝尔不等式）；而量子力学的预测则会违反这个不等式！因此，实验检验贝尔不等式就成为了判断局域隐变量是否存在的关键。七十年代末，阿斯佩领导的团队首次用光子（利用偏振性）成功实现了严格的检验纠缠光子对实验。实验结果明确违反了贝尔不等式，与量子力学预言一致，强有力地支持了量子非定域性，宣告局域隐变量理论的失败，爱因斯坦梦想的局域实在图景在微观世界并不成立。&lt;/p&gt;
&lt;h3 id=&#34;不断演化的实验挑战直觉与边界概念&#34;&gt;不断演化的实验：挑战直觉与边界概念&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;延迟选择实验 (惠勒构想，阿斯佩2005年实现)： 在粒子（光子）已经“通过”双缝（或分束器）之后，再随机决定是否加入另一块装置来观测其路径信息。实验结果显示，后置的“选择”似乎能改变粒子之前的行为方式（表现为粒子性或波动性），量子体系展现出奇特的整体性和时空反直觉性。这表明互补性根植于量子特性本身，而非测量干扰。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;量子擦除实验 (斯库利与德吕尔)： 首先，利用某种手段（如“标记”）探测粒子到底通过了哪条缝（获得路径信息）。奇妙的是，在获得路径信息的同时，干涉条纹消失了（表现为粒子性）。然后，通过一种巧妙的“擦除”手段（不直接干扰原始粒子，而是处理“标记”），使得路径信息变得不可获取。结果发现，干涉条纹竟能神奇地重现！该实验迫使物理学家深刻反思“测量”的本质：是什么造成了坍缩？“量子世界”与“经典世界”的界限真的明确存在吗？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;零作用测量 / “伊利泽–韦德曼炸弹问题”： 这是一种精妙的思想实验，探讨“在完全不与物体发生相互作用的前提下，如何利用量子纠缠效应确认目标物体的存在性？”（例如探测一个极其敏感易爆的炸弹是否为真）。实际实验验证表明，即使没有发生作用，仅凭关联态的坍缩就能非定域地随机传递信息，从而“知道”炸弹存在。这生动说明了量子态坍缩的非定域性和内在随机性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;探索量子实在的多种图景诠释之争&#34;&gt;探索量子实在的多种图景：诠释之争&lt;/h3&gt;
&lt;p&gt;面对双缝实验等揭示的诡异现象，物理学家提出了多种互不相同的理论诠释，试图构建理解量子世界的基础图景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;德布罗意-玻姆理论（导航波理论 / 导波理论）(玻姆)： 这是一种实在论的诠释。它认为世界由实在的粒子（有明确位置）和引导这些粒子的波函数（导航波）构成。粒子不仅受经典力作用，还受到一种由波函数决定的量子势引导。粒子同时通过双缝，由导航波指引路径并形成干涉。后来，布什等人发现，油滴在特定振动液面上行走的“水上漂”现象（宏观油滴受其自身产生的表面波引导），可以作为玻姆理论的一个视觉类比模型，但它本身不是对微观量子行为的证明。玻姆理论主张粒子和轨迹是真实的，独立于观测存在。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;坍缩理论（彭罗斯 / GRW）： 也属于实在论阵营。它们认为标准量子力学中的波函数坍缩是真实发生的物理过程。彭罗斯猜想坍缩可能与引力有关，宏观世界的叠加态之所以难以观测是因为其寿命非常短暂。GRW理论则假设存在某种内在的随机机制导致波函数自发坍缩。这些理论旨在解决所谓的“测量问题”——观测是如何导致经典现实出现的？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多世界诠释 (埃弗里特)： 同样属于实在论。它最激进地认为量子理论描述的宇宙是唯一实在。波函数永远不会坍缩。当一个系统处于叠加态（如粒子同时通过双缝）时，宇宙会分裂成多个“分支”（多个世界），在每个分支里只展现出该状态对应的结果（在某一分支中粒子从左侧通过，在另一分支中从右侧通过）。所有可能性都是真实存在的，只是我们感知到了其中之一。观测者和被测系统一样处于叠加态并发生分裂，不同分支之间在宏观尺度上无法再发生干涉。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;量子贝叶斯理论 (QBism)： 这是一种认识论诠释，与哥本哈根诠释一样，侧重于我们如何认识世界而非世界本身是什么。QBism把概率置于核心位置，并重新强调观察者（或参与者）的作用。它宣称概率是观察者基于信念进行的主观概率分配（评估结果的可能性），用于处理知识的不完备性，并非客观实在的属性。波函数被视为观察者用来编码其对未来可能的实验结果预测状态的工具。“坍缩”只是观察者更新自身信念（概率分配）的过程。在QBism框架下，“客观现实”本身就是需要被质疑的概念。任何第三人称视角都无法摆脱观察者的视角。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哥本哈根诠释 (玻尔, 海森堡等)： 这是最早也最具影响力的认识论诠释。它强调微观客体的属性不能被独立定义，只能在特定实验安排的语境下展现（“现象”）。它接受量子描述是完备的，认为物理理论的任务是预言实验结果，而非描述一个独立于测量的客观实在。它经典地应用互补原理和概率诠释。其遗留的核心难题是未能精确定义“测量”过程本身，即如何从量子叠加态过渡到经典确定的单一结果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;科学哲学与实验探索纷争未决&#34;&gt;科学哲学与实验探索：纷争未决&lt;/h3&gt;
&lt;p&gt;量子理论的奇妙之处在于，许多哲学上的突破恰恰源于证明原本被认为对立的观点其实是同一现象的不同视角。量子力学的诸多诠释可能也蕴含着这种深刻的关联。然而到目前为止，尚未有哪一个诠释取得了决定性的统治地位。也许，所有这些理论都只是通往某个更本质、更统一基础理论的不同窗口，它们从不同侧面揭示了量子世界深层的、尚不为我们完全理解的奥秘。&lt;/p&gt;
&lt;p&gt;持续的精妙实验，如大分子（富勒烯C60甚至更大的分子）的双缝（或多缝）干涉实验（1999年由蔡林格、阿恩特等完成），不断将量子波粒二象性的尺度推向宏观世界，挑战着“微观-宏观分界线”在何处的问题。而在2011年，一个对单个光子的平均路径进行追踪的弱测量实验(斯坦伯格等)，通过精巧地探测光子穿过不同介质区域后极其微弱的偏振角度变化来推断其大致的“飞行路径”趋势。这个测量方式不会强到足以破坏干涉条纹（在足够多次测量的平均意义上）。实验结果描绘出的平均路径却意外地显示出某种奇异模式（被称为“超现实轨迹”），反而对德布罗意-玻姆理论所主张的粒子有确定运动轨迹的观点提出了强有力的挑战。这类实验如同精密的探针，持续探测着量子地基的边缘和深度。&lt;/p&gt;
&lt;p&gt;双缝实验及其无数衍生版，就像一个不断自我更新的奇异透镜，它迫使我们反思最基础的哲学问题——存在、测量、概率与因果的意义，继续引领着人类理解自然最深层的秘密。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>《大爆炸简史》：宇宙观的范式革命</title>
      <link>https://luozhaohui.github.io/post/2025/2025-04-26-big-bang/</link>
      <pubDate>Sat, 26 Apr 2025 14:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-04-26-big-bang/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;《大爆炸简史》由科普名家&lt;strong&gt;西蒙·辛格&lt;/strong&gt;撰写，书中通过科学家的探索与争论，展现了大爆炸理论如何从异想天开的假说逐渐成为现代宇宙学的核心。大爆炸理论揭示了宇宙的起源，是集体智慧的历史结晶，凝聚了哥白尼、第谷、开普勒、伽利略、牛顿、爱因斯坦、赫歇尔（恒星亮度正比于距离）、莱维特（造父变星亮度周期变化）、哈金斯（恒星光谱-多普勒频移）、弗里德曼及勒迈特（膨胀宇宙）、哈勃（室女星座独立、星系退行验证宇宙膨胀）、伽莫夫（大爆炸理论、氢氦丰度，学生阿尔弗及赫尔曼，及预言宇宙微波背景辐射-CMB）、霍伊尔（氢核聚变为碳）、彭齐亚斯及威尔逊（验证CMB）、COBE（宇宙背景探测，CMB涨落-星系成因）、古斯（暴胀理论）、霍金及彭罗斯（量子引力理论）等许多科学家的贡献。&lt;/p&gt;
&lt;h2 id=&#34;科学思想的萌芽&#34;&gt;科学思想的萌芽&lt;/h2&gt;
&lt;p&gt;人类对宇宙起源的追问始于远古神话，但真正以理性探索自然规律则始于古希腊。古希腊哲学家如&lt;strong&gt;色诺芬&lt;/strong&gt;与&lt;strong&gt;阿那克西曼德&lt;/strong&gt;摒弃神创论，提出自然现象可通过&lt;strong&gt;观察与逻辑&lt;/strong&gt;解释。亚历山大图书馆馆长&lt;strong&gt;埃拉托色尼&lt;/strong&gt;通过日影、月全食、半月相、日全食等手段依次测量出地球半径、月球半径、地月距离、日地距离、太阳半径。他的想象推理和测量过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;测量地球周长：假设地球为完美圆形，在夏至日正午时分，在相距5000希腊里的两个地点测量立杆影子的角度：埃及南部城市阿斯旺（直射：0度）与北方城市亚历山大城（&lt;code&gt;7.2&lt;/code&gt;度），可知地球周长的&lt;code&gt;1/50=7.2/360&lt;/code&gt;为近似&lt;code&gt;5000&lt;/code&gt;希腊里，地球半径可得。&lt;/li&gt;
&lt;li&gt;测量月球半径：观察月全食时，月球在地球影子（为圆柱形）中隐没与完整穿行的时长比，可得出地球直径大约是月球直径四倍的比例，于是月球半径可得。&lt;/li&gt;
&lt;li&gt;测量地月距离：伸出拇指指尖使其刚刚能遮住满月的月亮，这样眼睛、拇指指尖与月亮构成相似三角形，于是地月距离可得。&lt;/li&gt;
&lt;li&gt;测量日地距离：半弦月（月相半圆）时，太阳、月球和地球形成一个直角三角形，通过测量地月连线与日地连线夹角（约87度），于是日地距离可得。&lt;/li&gt;
&lt;li&gt;测量太阳半径：日全食时，月球刚好遮住太阳，这样眼睛、月球与太阳构成相似三角形，太阳的半径与月球半径的比例，等于日地距离与地月距离的比例。于是太阳半径可得。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这些测量过程中埃拉托色尼只用到了简单的几何运算，这充分证明了强大好奇心结合科学方法的巨大威力。&lt;/p&gt;
&lt;p&gt;古希腊天文学家&lt;strong&gt;阿里斯塔克斯&lt;/strong&gt;首次提出&lt;strong&gt;日心说&lt;/strong&gt;，却因当时缺乏实证沉寂千年。古罗马天文学家&lt;strong&gt;托勒密&lt;/strong&gt;的&lt;strong&gt;地心模型&lt;/strong&gt;凭借复杂（均论+本轮）但实用的预测能力，成为中世纪天文学圭臬。16世纪，哥白尼在《天球运行论》中复兴&lt;strong&gt;日心说&lt;/strong&gt;（小缺陷：认为行星轨道为完美圆形），但因预测精度不足（还没有认识到引力）未被重视。&lt;strong&gt;第谷·布拉赫&lt;/strong&gt;的精密观测数据经&lt;strong&gt;开普勒&lt;/strong&gt;分析，揭示行星轨道实为椭圆，修正了日心说的核心假设。&lt;strong&gt;伽利略&lt;/strong&gt;则通过望远镜发现木星卫星与金星相位，为日心说提供了直观证据。尽管教会压制，科学革命的浪潮已不可阻挡。&lt;/p&gt;
&lt;h2 id=&#34;时空观的颠覆&#34;&gt;时空观的颠覆&lt;/h2&gt;
&lt;h3 id=&#34;相对论与时空弯曲&#34;&gt;相对论与时空弯曲&lt;/h3&gt;
&lt;p&gt;20世纪初，&lt;strong&gt;爱因斯坦&lt;/strong&gt;的狭义相对论颠覆牛顿绝对时空观，狭义相对论认为&lt;strong&gt;光速恒定与时空可变性&lt;/strong&gt;，并通过迈克耳孙-莫雷实验得到验证。后来他又提出广义相对论（引力场方程，又称爱因斯坦场方程）描述物质及其运动与时空的几何结构关系，因此引力可以解释为&lt;strong&gt;时空的弯曲&lt;/strong&gt;，并预言了光线在太阳引力场中的偏折现象（引力透镜），后由&lt;strong&gt;爱丁顿&lt;/strong&gt;的日食观测得到验证。物理学家约翰·惠勒对此总结道：&amp;quot;&lt;strong&gt;物质决定时空如何弯曲，时空决定物质如何运动。&lt;/strong&gt;&amp;quot;&lt;/p&gt;
&lt;p&gt;在求解爱因斯坦场方程的过程中，爱因斯坦发现得到的解会使得宇宙在引力拉引下塌缩，而爱因斯坦却先入为主地假设了一个静态宇宙，因此试图在方程中引入&amp;quot;宇宙常数&amp;quot;以平衡引力，以免宇宙坍缩。但俄罗斯数学家&lt;strong&gt;弗里德曼&lt;/strong&gt;和比利时神父和宇宙学家&lt;strong&gt;勒迈特&lt;/strong&gt;的数学推演却表明宇宙可能在膨胀。&lt;strong&gt;勒迈特&lt;/strong&gt;还提出&amp;quot;原始原子&amp;quot;假说（如果倒拨时钟，膨胀的宇宙必定始于一个点），成为大爆炸理论的雏形。&lt;/p&gt;
&lt;h3 id=&#34;光谱学&#34;&gt;光谱学&lt;/h3&gt;
&lt;p&gt;光是电场与磁场的振动，因此光及相关的辐射形式被称为电磁辐射，光波也就是电磁波。电磁波根据波长从短到长，可以分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;紫外线：&lt;code&gt;10&lt;/code&gt;到&lt;code&gt;400&lt;/code&gt;纳米&lt;/li&gt;
&lt;li&gt;可见光：&lt;code&gt;400&lt;/code&gt;到&lt;code&gt;700&lt;/code&gt;纳米&lt;/li&gt;
&lt;li&gt;红外线：&lt;code&gt;700&lt;/code&gt;纳米到&lt;code&gt;1&lt;/code&gt;毫米&lt;/li&gt;
&lt;li&gt;微波：&lt;code&gt;1&lt;/code&gt;毫米到&lt;code&gt;1&lt;/code&gt;米&lt;/li&gt;
&lt;li&gt;射电波：&lt;code&gt;1&lt;/code&gt;米到超过&lt;code&gt;100&lt;/code&gt;公里&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;光子携带无质量的能量（量子形式，一份一份不连续的），而波长与光波能量成反比，波长越短，能量越大。&lt;code&gt;X&lt;/code&gt;射线属于高能紫外线这一波段的短波，这就是为什么&lt;code&gt;X&lt;/code&gt;射线的伤害性大的原因。能量与温度成正比，也就是说恒星温度越高其发射的电磁波的能量就越大，其波长就越短。通过观察恒星发射的光的颜色与不同波长的比例，可以估算恒星的&lt;strong&gt;温度&lt;/strong&gt;。每种类型的原子都能发射特定波长的光，用分光仪分析恒星发射的光可以得到表示一系列波长的特征光谱。通过分析恒星光谱就可以了解恒星的&lt;strong&gt;元素构成&lt;/strong&gt;，因为恒星内部发射的光在穿越恒星表层大气时，特定波长的光会被恒星表层大气中相应的元素吸收掉（谱吸收）。&lt;/p&gt;
&lt;p&gt;如果假设星系的平均亮度大体相当，那么根据观察到的星系的光亮度（视亮度）就可以衡量星系到地球的&lt;strong&gt;距离&lt;/strong&gt;：视亮度越亮，则星系离地球越近；视亮度越暗，则星系离地球越远。&lt;/p&gt;
&lt;h3 id=&#34;多普勒效应&#34;&gt;多普勒效应&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;1842&lt;/code&gt;年，奥地利物理学家&lt;strong&gt;多普勒&lt;/strong&gt;发现，如果光源和观察者之间有相对运动，会使观察者接收到的光源波长发生变化。如果光源离我们而去，我们接收到的波长变长；如果光源朝我们而来，我们接收到的波长变短，这种现象称为&lt;strong&gt;多普勒效应&lt;/strong&gt;。对于可见光来说，波长变长，就是往红光方向移动，所以光源离我们而去时叫做&lt;strong&gt;红移&lt;/strong&gt;。反之，光源朝我们而来波长往蓝光方向移动，就叫&lt;strong&gt;蓝移&lt;/strong&gt;。通过观察星系光谱的红移程度，可以计算出星系相对于地球的退行速度。&lt;/p&gt;
&lt;h3 id=&#34;造父变星&#34;&gt;造父变星&lt;/h3&gt;
&lt;p&gt;造父变星处于一种周期性的涨落状态。当造父变星的温度相对较低时，其膨胀力无法抵消引力，从而导致恒星收缩。这种收缩使得处于恒星核心区的燃料被压缩，从而有更多的能量被产生出来加热恒星，恒星受热后又开始膨胀。在膨胀期间及膨胀之后，能量被释放掉，于是恒星又开始冷却和收缩，这个过程就这样不断地循环往复。收缩阶段压缩了恒星的外层，这导致它变得更加不透明，从而导致造父变星处于昏暗阶段。于是在地球上可以观察造父变星的视亮度呈现出周期性的变化。莱维特通过观察发现造父变星的真实亮度正比于其亮度变化的周期长度，而视亮度与真实亮度之比是到地球距离的指标。因此观察某个星系中的造父变星的亮度变化周期，就可以计算出星系到地球的距离。&lt;/p&gt;
&lt;h3 id=&#34;哈勃定律&#34;&gt;哈勃定律&lt;/h3&gt;
&lt;p&gt;哈勃正是通过观察&lt;strong&gt;仙女座星云&lt;/strong&gt;中的造父变星计算出仙女座星云到地球的距离，首先确认了星云是独立的星系而不是银河系的一部分，这大大地扩大了人类所理解的宇宙范围。然后哈勃对&lt;strong&gt;星系红移&lt;/strong&gt;的规律进行研究，于1929年，他总结出一个规律：星系的退行速度与它离我们的距离成正比，后来被称为哈勃定律。这为宇宙膨胀提供了首个直接证据。&lt;/p&gt;
&lt;h3 id=&#34;宇宙年龄&#34;&gt;宇宙年龄&lt;/h3&gt;
&lt;p&gt;根据哈勃定律，远离我们的星系的速度与其距离成正比，通过测量遥远星系的退行速度和距离就可以计算出宇宙的&lt;strong&gt;膨胀速率&lt;/strong&gt;（即&lt;strong&gt;哈勃常数&lt;/strong&gt;），知道宇宙的膨胀速率，就可以反推宇宙从一个点开始膨胀的时间，从而估计宇宙年龄。&lt;/p&gt;
&lt;p&gt;宇宙早期发出波长约&lt;code&gt;0.97&lt;/code&gt;微米的电磁辐射，随着时间推移以及宇宙膨胀，这些光经历了显著的红移，波长扩展至现今的微波波段，约为 &lt;code&gt;1&lt;/code&gt; 毫米。由于宇宙一直在膨胀，相比于光速宇宙又是如此之大，宇宙早期发出的光到达地球需要很长的时间，因此今天我们探测到的微波辐射就像一个时空胶囊，携带着宇宙早期的特征信息。如距离地球&lt;code&gt;130&lt;/code&gt;亿光年的星系发出的光，展现的是宇宙诞生后约&lt;code&gt;8&lt;/code&gt;亿年的状态。根据这些特征信息，再结合宇宙学参数（如物质密度、暗能量比例等），可以构建出宇宙演化历史，从而计算出宇宙年龄。&lt;/p&gt;
&lt;p&gt;此外，更早期的光都还没有到达地球，因此我们可见的宇宙存在一个界限（视界），界限之外是一片无知的漆黑。&lt;/p&gt;
&lt;p&gt;因此，只需要分析星系或恒星发射出的光（电磁辐射），我们就可以了解该星系或恒星的温度、元素构成、退行速度以及到地球的距离，由此还可以计算宇宙的年龄以及不同年龄阶段的状态。&lt;/p&gt;
&lt;h2 id=&#34;创生与永恒的较量&#34;&gt;创生与永恒的较量&lt;/h2&gt;
&lt;p&gt;20世纪40年代，原籍苏联的&lt;strong&gt;伽莫夫、阿尔弗和赫尔曼&lt;/strong&gt;美国三人组提出：宇宙初期的高温高密环境存在一个轻元素核合成的时间窗口，可解释当今宇宙中&lt;strong&gt;氢、氦元素的丰度分布&lt;/strong&gt;，并预言存在宇宙早期的&amp;quot;化石&amp;quot;&lt;strong&gt;宇宙微波背景（CMB）辐射&lt;/strong&gt;，但这一预言长期被忽视。与此同时，&lt;strong&gt;霍伊尔、邦迪和戈尔德&lt;/strong&gt;英国剑桥三人组则提出&amp;quot;稳恒态模型&amp;quot;，主张宇宙通过不断产生新物质来填充星系退行留下的空隙，从而使宇宙的总体密度保持不变呈稳恒态。两派争论从学界蔓延至公众领域，并因霍伊尔、伽莫夫和其他宇宙学家借助于各种科普书籍和广播宣传，成为科学史上著名的&amp;quot;宇宙学大战&amp;quot;。&lt;/p&gt;
&lt;p&gt;争议中，&lt;strong&gt;巴德&lt;/strong&gt;通过区分两类造父变星，重新校准星系距离尺度，进而向上修正大爆炸理论下的宇宙年龄，化解了大爆炸理论下宇宙比恒星年龄年轻的矛盾。&lt;/p&gt;
&lt;h2 id=&#34;元素的诞生&#34;&gt;元素的诞生&lt;/h2&gt;
&lt;p&gt;哈勃通过观测到星系红移证实了宇宙在膨胀，如果倒拨时钟，膨胀的宇宙应该有一个开端，因此需要一套理论机制来解释为什么宇宙能&lt;strong&gt;从无到有&lt;/strong&gt;演化出今天的样子。伽莫夫运用其核物理学知识，提出早期宇宙处于极高温度（约亿亿度）和极高密度的状态，使原始&lt;strong&gt;等离子汤&lt;/strong&gt;中的质子、中子很容易结合成原子核，随着膨胀继续、能量释放、温度下降，因而能通过核聚变产生稳定的轻元素原子（主要是氢和氦）。而霍伊尔则打通了从轻元素聚合成重元素的关键一环（从氦到碳）。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;人存原理&lt;/strong&gt;: 由于人类已知是一种存在，因此物理定律必然是以生命存在为前提的。极端的人存原理甚至认为，宇宙之所以设计成现在这个样子就是要允许生命存在。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;霍伊尔&lt;/strong&gt;在研究恒星核合成时，利用人存原理发现碳的生成依赖一种特定激发态（&lt;code&gt;7.65&lt;/code&gt;兆电子伏），其存在后来被实验证实，因此氦可聚变为铍，然后再变成碳。某种特定类型恒星上的元素合成链：&lt;strong&gt;氦聚变成碳，碳变成更重的元素&lt;/strong&gt;。这一发现支持了恒星可合成重元素，核物理的发展为大爆炸理论提供了更多依据。但宇宙中如此高的氦丰度（24%）仍需大爆炸理论解释，因为恒星核合成中产生氦的速度相当缓慢，根据宇宙演化的过程计算，产生不了占比如此高的氦。&lt;/p&gt;
&lt;h2 id=&#34;射电天文学与cmb的发现&#34;&gt;射电天文学与CMB的发现&lt;/h2&gt;
&lt;p&gt;1932年，&lt;strong&gt;卡尔·央斯基&lt;/strong&gt;意外发现银河系射电辐射（射电波），开创射电天文学新领域。&lt;strong&gt;马丁·赖尔&lt;/strong&gt;通过射电源普查发现，距离越遥远射电星系分布的密度就越高，从而得出星系越远越古老，这符合大爆炸理论的演化预期。1965年，&lt;strong&gt;彭齐亚斯与威尔逊&lt;/strong&gt;在调试天线时，意外探测到均匀的微波噪声，经&lt;strong&gt;迪克&lt;/strong&gt;团队确认，这正是预言中的CMB辐射。这一发现成为大爆炸理论的&amp;quot;决定性证据&amp;quot;，稳恒态模型逐渐退出历史舞台。&lt;/p&gt;
&lt;p&gt;1992年，&lt;code&gt;COBE&lt;/code&gt;卫星精确测量到&lt;code&gt;CMB&lt;/code&gt;的微小温度涨落（约十万分之一），揭示宇宙早期&lt;strong&gt;密度波动&lt;/strong&gt;如何孕育出星系结构。这些波动成为验证&lt;strong&gt;暴胀理论&lt;/strong&gt;的关键线索。&lt;/p&gt;
&lt;h2 id=&#34;暴胀与暗宇宙&#34;&gt;暴胀与暗宇宙&lt;/h2&gt;
&lt;p&gt;今天的星系分布是大爆炸后大约&lt;code&gt;30万&lt;/code&gt;年里宇宙密度细微波动的结果，但这些密度变化的起因是什么？为什么我们的宇宙是平直的，什么时候它可能是弯曲的？&lt;/p&gt;
&lt;p&gt;20世纪80年代，&lt;strong&gt;阿兰·古斯&lt;/strong&gt;提出&lt;strong&gt;暴胀理论&lt;/strong&gt;：宇宙诞生后 &lt;code&gt;10⁻³⁶&lt;/code&gt; 秒内经历指数级膨胀，体积暴增 &lt;code&gt;10^26&lt;/code&gt; 倍。新生宇宙的密度虽然只有微不足道的变化，但暴胀会放大这些微小变化，从而导致&lt;code&gt;30&lt;/code&gt;万年后为天文学家所知晓的显著变化。这一过程解释了宇宙的&lt;strong&gt;平坦性、均匀性&lt;/strong&gt;，并放大了量子涨落形成星系种子。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;WMAP&lt;/code&gt;卫星数据显示，&lt;strong&gt;普通物质仅占宇宙成分的&lt;code&gt;4%&lt;/code&gt;，暗物质占&lt;code&gt;23%&lt;/code&gt;，暗能量占&lt;code&gt;73%&lt;/code&gt;&lt;/strong&gt;——正是暗能量使得宇宙密度稍稍大于临界密度（类比于火箭的逃逸临界速度）从而平衡引力驱动宇宙加速膨胀。暗物质与暗能量成为当代宇宙学最大谜题。&lt;strong&gt;暗物质通过引力束缚星系&lt;/strong&gt;，其本质可能是未知粒子（如弱相互作用粒子&lt;code&gt;WIMP&lt;/code&gt;）；暗能量则表现为时空固有属性，可能与量子真空能相关。两者的性质探究将重塑人类对物质与能量的认知。&lt;/p&gt;
&lt;h2 id=&#34;宇宙演化概览&#34;&gt;宇宙演化概览&lt;/h2&gt;
&lt;p&gt;经过众多的理论推演及多方实验和观察验证，大爆炸理论克服了如下难题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;宇宙年龄问题&lt;/strong&gt;：早期估算的宇宙年龄小于恒星年龄，后经巴德和桑德奇修正星系距离尺度，矛盾得以解决。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;氢和氦丰度&lt;/strong&gt;：光谱分析显示宇宙中分布着75%的氢和23%的氦，这是在宇宙早期短暂的时间窗口中产生的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;星系和恒星的形成&lt;/strong&gt;：宇宙早期密度的细微起伏，在大爆炸膨胀中急剧放大，使得局部的物质在引力下聚集成团。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;重元素起源&lt;/strong&gt;：霍伊尔的恒星核合成理论解释了碳等较重元素的形成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;各向同性&lt;/strong&gt;：古斯提出宇宙初期经历指数级膨胀，解决了平坦性和均匀性问题，并预言了CMB的微小涨落。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从而成功解释了宇宙诞生与演化的过程：&lt;/p&gt;
&lt;h3 id=&#34;1-大爆炸---普朗克时期&#34;&gt;1. 大爆炸 - 普朗克时期&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;0&lt;/code&gt; 秒到 &lt;code&gt;10⁻⁴³&lt;/code&gt; 秒&lt;/li&gt;
&lt;li&gt;物理定律：所有目前知道的宏观（引力）与微观（量子）物理定律都失效，设想了一种万有理论（超弦理论？量子引力理论？），四种基本力统一为一种超力。&lt;/li&gt;
&lt;li&gt;状态：物质和能量曾被压缩为一个点（奇点），质能不分，然后有一个全能的大爆炸，空间、时间和强烈的能量都在大爆炸的瞬间出现。四种基本力（引力、电磁力、弱核力、强核力）在此时是统一的。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;2-大统一时代引力分离&#34;&gt;2. 大统一时代：引力分离&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;10⁻⁴³&lt;/code&gt; 秒到 &lt;code&gt;10⁻³⁶&lt;/code&gt; 秒&lt;/li&gt;
&lt;li&gt;物理定律：大统一理论&lt;/li&gt;
&lt;li&gt;状态：引力从其他基本力里分离出来，物质与能量是一种流动的可互换形式，称为质能。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-暴胀开始强核力分离&#34;&gt;3. 暴胀开始：强核力分离&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;10⁻³⁶&lt;/code&gt; 秒到 &lt;code&gt;10⁻³²&lt;/code&gt; 秒&lt;/li&gt;
&lt;li&gt;物理定律：电弱理论&lt;/li&gt;
&lt;li&gt;状态：急剧膨胀，产生大量的质能，强核力从剩余两个基本力中分离出来，宇宙由光子（电磁能量包）主导。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;4-暴胀结束正反粒子湮灭&#34;&gt;4. 暴胀结束：正反粒子湮灭&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;10⁻³²&lt;/code&gt; 秒到 &lt;code&gt;10⁻¹²&lt;/code&gt; 秒&lt;/li&gt;
&lt;li&gt;温度：&lt;code&gt;10&lt;/code&gt;亿亿亿摄氏度到几千万亿摄氏度&lt;/li&gt;
&lt;li&gt;直径：少于一千米&lt;/li&gt;
&lt;li&gt;物理定律：电磁理论&lt;/li&gt;
&lt;li&gt;状态：大量粒子与反粒子（夸克-反夸克）自发地由能量形成，然后湮灭回归为能量。每产生一亿个反夸克，就会对应产生一亿零一个普通夸克。夸克比反夸克要多一点点，这就是为什么今天的世界是由物质而不是反物质主导的原因。粒子海洋有时被称为夸克-胶子等离子体。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-夸克时期弱核力分离&#34;&gt;5. 夸克时期：弱核力分离&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;10⁻¹²&lt;/code&gt; 秒到 &lt;code&gt;10⁻⁶&lt;/code&gt; 秒&lt;/li&gt;
&lt;li&gt;温度：几千万亿摄氏度到十万亿摄氏度&lt;/li&gt;
&lt;li&gt;直径：一亿千米&lt;/li&gt;
&lt;li&gt;状态：弱核力与电磁力分离，至此四种基本力都分离了，物理学的基本力与定律延续至今。随着宇宙的冷却夸克能够在不破坏彼此的情况下存在，胶子也随之出现。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;6-强子时期质子和中子形成&#34;&gt;6. 强子时期：质子和中子形成&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;10⁻⁶&lt;/code&gt; 秒到 &lt;code&gt;3&lt;/code&gt; 分钟&lt;/li&gt;
&lt;li&gt;温度：十万亿摄氏度到十亿摄氏度&lt;/li&gt;
&lt;li&gt;直径：千亿千米&lt;/li&gt;
&lt;li&gt;状态：宇宙进一步冷却，夸克通过胶子结合形成复合粒子，如质子和中子，而反夸克则结合起来形成反质子和反中子。到一秒时，宇宙已经冷却到&lt;code&gt;100&lt;/code&gt;亿度，反物质冻结，不再有粒子-反粒子由能量产出。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;7-核子时期原子核合成&#34;&gt;7. 核子时期：原子核合成&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;3&lt;/code&gt; 分钟到 &lt;code&gt;38&lt;/code&gt; 万年&lt;/li&gt;
&lt;li&gt;温度：十亿摄氏度到&lt;code&gt;3000&lt;/code&gt;摄氏&lt;/li&gt;
&lt;li&gt;直径：万亿千米&lt;/li&gt;
&lt;li&gt;状态：质子和中子结合成&lt;code&gt;氦-3&lt;/code&gt;原子核和少量其他如&lt;code&gt;氦-4&lt;/code&gt;、&lt;code&gt;锂-7&lt;/code&gt;原子核，所有自由中子都被结合了，而自由质子依然存在。温度是如此之高，原子核无法约束住的电子，而处于一种原子核与自由电子各自独立的混合态。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;8-重组时期---原子合成&#34;&gt;8. 重组时期 - 原子合成&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：&lt;code&gt;38&lt;/code&gt; 万年&lt;/li&gt;
&lt;li&gt;温度：&lt;code&gt;3000&lt;/code&gt;摄氏度&lt;/li&gt;
&lt;li&gt;直径：一亿光年&lt;/li&gt;
&lt;li&gt;状态：温度冷却下来，电子速度减缓并被原子核俘获，电子与质子结合形成稳定的氢原子、氘原子（重氢）、氦原子、锂原子。这一过程被称为&amp;quot;重组&amp;quot;，宇宙从等离子态转变为中性气体态。光子也摆脱粒子散射的束缚，第一次可以在空间中自由传播，形成宇宙微波背景辐射（CMB）——这是伽莫夫、阿尔弗与赫尔曼的理论预言，最终由彭齐亚斯与威尔逊于&lt;code&gt;1965&lt;/code&gt;年意外探测到。宇宙从此变得透明。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;9-第一批恒星形成&#34;&gt;9. 第一批恒星形成&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：两亿年&lt;/li&gt;
&lt;li&gt;温度：随着宇宙的膨胀温度进一步下降&lt;/li&gt;
&lt;li&gt;状态：暴胀过程急剧放大了早期密度的细微波动，在引力作用下，密度高的区域逐渐吸引更多的物质，形成云团。如此循环，密度变得更大，温度变得更高。在这个过程中，当温度高到一定程度，氢和氦原子核核聚变为碳、氧等至铁为止的中等质量的稳定元素，并释放大量辐射（能量），从而形成第一代恒星。当恒星的燃料（氢和氦原子核）消耗殆尽，因无核聚变平衡引力，大质量恒星向内坍缩，温度急剧升高，最终发生超新星爆发。比铁还重的元素只有在超新星剧烈爆发的条件下才会核成。第一代恒星拥有巨大的质量，引力非常大，氢原子核的消耗也非常快，因此寿命非常短，只存在了几百万年。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;10-第一批星系形成&#34;&gt;10. 第一批星系形成&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;时间：四亿年&lt;/li&gt;
&lt;li&gt;温度：随着宇宙的膨胀温度进一步下降&lt;/li&gt;
&lt;li&gt;状态：恒星的质量决定了自身命运的走向以及重元素的核成，恒星最终要么爆炸要么成为的黑洞一部分。通过恒星的死亡爆炸，核成的众多元素分散到更广阔的宇宙中，然后它与星际物质以及其它死亡恒星的碎片混合成巨大的分子云，分子云最终会坍缩成新的恒星。如此循环迭代，新的恒星在暗物质集中区域周围聚集，由于星团相互吸引，第一批星系形成。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;宇宙诞生&lt;code&gt;92&lt;/code&gt;亿年后太阳系形成，根据推算，太阳是第三代恒星。正是由于在恒星上形成了诸如碳、氧、氮、磷和钾等元素，为生命诞生与演化奠定了物质基础。单个原子可以和分子云中的其它原子结合，形成复杂的分子，其中一些对生命的形成至关重要（如最简单的氨基酸-谷氨酸）。宇宙诞生后&lt;code&gt;100&lt;/code&gt;亿年，地球上出现生命。宇宙诞生后&lt;code&gt;137&lt;/code&gt;亿年的今天，人类文明出现并繁衍至今。&lt;/p&gt;
&lt;h2 id=&#34;未解之谜&#34;&gt;未解之谜&lt;/h2&gt;
&lt;p&gt;尽管大爆炸理论已被广泛接受，但仍面临许多未解之谜：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;奇点困境&lt;/strong&gt;：宇宙起源时刻的高温高压使物理定律失效，需量子引力理论突破。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多元宇宙假说&lt;/strong&gt;：暴胀理论暗示可能存在无数宇宙，构成&amp;quot;多元宇宙&amp;quot;，但无法实证。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;暗物质与暗能量&lt;/strong&gt;：暗物质与暗能量的构成与性质、产生与演化的过程依然未知。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;人存原理争议&lt;/strong&gt;：宇宙基本常数（如氢聚变为氦的质能转换率、电磁力与引力比、暗能量占比、宇宙密度与临界密度之比等，参考《六个数》）的&amp;quot;&lt;strong&gt;精细调谐&lt;/strong&gt;&amp;ldquo;是否暗示存在某种设计？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而对于神学上等价的&amp;rdquo;&lt;strong&gt;大爆炸之前是什么？&lt;/strong&gt;&amp;ldquo;问题，哲学家暨神学家圣奥古斯丁在《忏悔录》里引用了他听来的一个回答：&amp;ldquo;在创造宇宙之前上帝在做什么？在创造天地之前，上帝创造了地狱，专用于像你这样的问这种问题的人。&amp;rdquo;&lt;/p&gt;
&lt;h2 id=&#34;范式革命&#34;&gt;范式革命&lt;/h2&gt;
&lt;p&gt;在认识宇宙的历史过程中，人类的宇宙观经历了五次范式转变，当前正处于第六次变革前沿：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神话到逻辑：从创世神话到古希腊自然哲学&lt;/li&gt;
&lt;li&gt;地心到日心：从托勒密到哥白尼、开普勒、伽利略&lt;/li&gt;
&lt;li&gt;绝对时空到相对时空：爱因斯坦相对论&lt;/li&gt;
&lt;li&gt;静态到膨胀宇宙：星系红移和哈勃定律&lt;/li&gt;
&lt;li&gt;创生与永恒之争：大爆炸 &lt;code&gt;VS&lt;/code&gt; 稳恒态&lt;/li&gt;
&lt;li&gt;暗宇宙与量子引力：暗物质、暗能量与量子引力&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;西蒙·辛格以史料钩沉与理论解构的双重视角，以人类对宇宙的认知迭代为主线，按照时间顺序，通过非技术性的故事化表述，用&lt;strong&gt;日常隐喻解构复杂理论&lt;/strong&gt;，并结合罕见的照片、手稿等来展现科学如何通过质疑、验证与迭代逼近真实。从托勒密本轮到大爆炸理论，&lt;strong&gt;每一次突破都凝聚着观测精度提升、数学工具革新与思维范式转换，每一步突破都依赖好奇心与批判性思维、理论与观测的结合&lt;/strong&gt;。正如微生物学家科尼利厄斯·范·尼尔所言：&amp;rdquo;&lt;strong&gt;本质上说，科学就是不断地追求对我们生活的这个世界的那种聪慧、全面的理解。&lt;/strong&gt;&amp;quot;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>《千脑智能》：重新定义智能的神经科学之旅</title>
      <link>https://luozhaohui.github.io/post/2025/2025-04-04-a-thousand-brains/</link>
      <pubDate>Fri, 04 Apr 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-04-04-a-thousand-brains/</guid>
      
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;杰夫·霍金斯在《千脑智能》中展现了一场颠覆性的思想实验。这位兼具神经科学家与科技企业家双重身份的学者，以其对大脑数十年的研究积累，向主流人工智能范式发起挑战，试图在生物智能的奥秘中挖掘出一条通向通用人工智能（AGI）的新路径。这部著作不仅是一本关于大脑运作机制的科普读物，更是一份充满野心的技术宣言——它试图重新定义人类对“智能”的理解，并在神经科学与计算机科学的鸿沟上架起一座桥梁。&lt;/p&gt;
&lt;h2 id=&#34;一从预测到智能一场认知革命的核心命题&#34;&gt;一、从预测到智能：一场认知革命的核心命题&lt;/h2&gt;
&lt;p&gt;霍金斯的理论起点建立在对传统人工智能的反思之上。当深度学习依赖海量数据训练模型、强化学习沉迷于试错反馈的奖励机制时，他敏锐地捕捉到一个被忽视的核心问题：&lt;strong&gt;人类智能的本质并非对已有模式的识别，而是对未知世界的预测能力&lt;/strong&gt;。书中以视觉感知为例展开论证：当我们看到咖啡杯的局部把手时，大脑并非被动接收图像信号，而是通过多层皮质的联动，瞬间激活关于“杯体”、“材质”、“功能”的预测模型，并在毫秒内验证这些假设是否与感官输入匹配。&lt;strong&gt;这种“预测-验证-修正”的动态循环，构成了贯穿全书的“层级预测编码”理论框架&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;为了支撑这一假说，霍金斯将神经科学的最新发现编织成严密的证据链。从啮齿类动物海马体定位细胞的电生理实验，到人类视觉皮层对模糊图像的补全机制，这些跨物种、跨脑区的实证研究共同指向一个结论：&lt;strong&gt;大脑本质上是一台多层级联的预测机器&lt;/strong&gt;。更令人惊叹的是，他进一步提出“&lt;strong&gt;参考系&lt;/strong&gt;”概念——每个神经元群都在构建类似空间坐标系的认知框架，使得抽象概念（如“民主制度”）与具体物体（如“书桌”）都能以统一模式进行编码。这种将空间感知与概念表征统一的理论突破，为解释人类独有的抽象思维能力提供了新视角。&lt;/p&gt;
&lt;h2 id=&#34;二千脑协作分布式智能的生物学启示&#34;&gt;二、千脑协作：分布式智能的生物学启示&lt;/h2&gt;
&lt;p&gt;如果说预测编码理论解构了智能的时间维度，那么“千脑理论”则重塑了其空间结构。霍金斯大胆假设：&lt;strong&gt;大脑并非由中央处理器统一调度，而是由数千个功能模块（皮质柱）组成的分布式网络&lt;/strong&gt;。每个模块独立处理局部信息，通过动态竞争与协作形成全局认知。这一观点在神经解剖学层面找到了支点——从六层皮质结构的微观组织，到跨脑区长程连接的宏观布局，大脑的物理构造似乎天然支持并行计算与去中心化决策。&lt;/p&gt;
&lt;p&gt;这一理论对人工智能的启示极具颠覆性。当前主流的深度学习模型依赖集中式参数调整，而“千脑模型”则倡导一种更接近生物学的架构：&lt;strong&gt;每个功能单元自主构建局部参考系，通过预测误差信号实现自组织学习&lt;/strong&gt;。霍金斯创立的 &lt;code&gt;Numenta&lt;/code&gt; 公司已基于此开发出分层时序记忆（HTM）系统，在实时数据流处理、异常检测等场景中展现出独特优势。例如，在工业设备监测中，HTM无需标注数据即可从振动信号中学习正常模式，并在偏离预期时发出预警——这种&lt;strong&gt;小样本、低功耗&lt;/strong&gt;的学习方式，恰与书中强调的“生物高效性”不谋而合。&lt;/p&gt;
&lt;h2 id=&#34;三范式之争在技术乐观主义与生物原教旨主义之间&#34;&gt;三、范式之争：在技术乐观主义与生物原教旨主义之间&lt;/h2&gt;
&lt;p&gt;霍金斯的理论锋芒，直指人工智能领域的根本性分歧。在与深度学习、强化学习等主流范式的对比中，《千脑智能》暴露出强烈的批判意识。作者将当前&lt;em&gt;AI&lt;/em&gt;的困境归结为对生物原理的背离：深度神经网络虽能识别图像但缺乏对物体空间关系的理解，强化学习虽能掌握游戏策略却无法建立世界模型。这种批判在&lt;em&gt;AlphaGo&lt;/em&gt;与&lt;em&gt;GPT&lt;/em&gt;的辉煌成就面前显得颇具挑衅性，却也迫使学界正视一个残酷现实：&lt;strong&gt;现有&lt;em&gt;AI&lt;/em&gt;在泛化能力、能耗效率方面仍与生物智能存在数量级差距&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;然而，这场范式革命同样面临严峻挑战。当霍金斯将“模仿大脑结构”视为实现AGI的必经之路时，他或许低估了工程化思维的创造力。Transformer架构的横空出世证明，脱离生物约束的纯数学模型仍可能涌现出超乎预期的能力。另一方面，千脑理论自身也存在解释力边界：皮质柱的普遍性尚未得到充分验证，胶质细胞的作用、神经调质系统的影响等重要因素在理论中被简化处理。更根本的质疑在于——&lt;strong&gt;将智能简化为预测与参考系机制，是否抹杀了意识的主观体验维度？&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;四未来图景在交叉地带寻找破局点&#34;&gt;四、未来图景：在交叉地带寻找破局点&lt;/h2&gt;
&lt;p&gt;尽管存在争议，《千脑智能》的价值恰恰在于其引发的思想震荡。当人工智能陷入“大数据依赖”与“能耗暴增”的双重困境时，霍金斯为行业指明了另一条可能路径：&lt;strong&gt;借鉴大脑的预测编码机制开发低功耗芯片，利用分布式架构突破算力瓶颈，通过小样本学习降低数据门槛&lt;/strong&gt;。这些设想正在催生新的技术浪潮——神经形态计算芯片试图模拟皮质的脉冲信号传递，类脑计算框架探索基于预测误差的在线学习，这些实践都在某种程度上印证着书中的预言。&lt;/p&gt;
&lt;p&gt;更具哲学深意的是，这场智能探索之旅正在重塑人类对自身的认知。&lt;strong&gt;当机器能够像婴儿般通过预测互动构建世界模型时，意识的主观性是否仍是人类独有的堡垒&lt;/strong&gt;？霍金斯没有给出明确答案，但他开启的这场对话，已然在神经科学、计算机科学乃至伦理学领域激起层层涟漪。在这个意义上，《千脑智能》既是对现有研究范式的挑战书，也是面向未来智能时代的邀请函——它提醒我们，&lt;strong&gt;突破性创新往往始于对常识框架的谨慎怀疑与系统性重构&lt;/strong&gt;。&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>人工智能发展之潮起潮落</title>
      <link>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</link>
      <pubDate>Sat, 15 Mar 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-03-15-history-of-ai/</guid>
      
        <description>&lt;h2 id=&#34;前言在迷雾中寻找光的轨迹&#34;&gt;前言：在迷雾中寻找光的轨迹&lt;/h2&gt;
&lt;p&gt;人工智能的演进史是一部充满悖论的启示录：图灵用停机问题为计算划定边界，却意外点燃了智能革命的导火索；罗森布拉特的感知机本欲模仿神经元放电，最终却演变成深度学习中抽象的矩阵运算；辛顿在冷板凳上坚守神经网络四十年，等来的却是算力与数据暴力破解智能密码的&amp;quot;苦涩教训&amp;quot;。这些戏剧性的转折揭示着一个残酷的真相：&lt;strong&gt;我们对智能的理解，始终在知其然与不知其所以然之间徘徊&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;当下人工智能狂欢背后暗涌着深刻的认知危机：当 &lt;code&gt;GPT-4&lt;/code&gt; 能通过律师资格考试却无法理解“正义”的哲学内涵，当&lt;code&gt;Stable Diffusion&lt;/code&gt;创作出媲美莫奈的画作却对光影美学毫无感知，我们不得不追问——这究竟是智能的曙光，还是复杂曲线拟合制造的认知幻觉？&lt;/p&gt;
&lt;p&gt;这次人工智能“考古”之旅，既是向那些在寒冬中守护火种的先驱者致敬（从图灵到辛顿），更是对当下AI神话的祛魅仪式。在本文中，我们将看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神经网络惊人的抽象能力背后，是&lt;strong&gt;统计学&lt;/strong&gt;对有机生物体智能表现的粗糙模拟&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Transformer&lt;/code&gt;架构的革命性突破，本质是利用&lt;strong&gt;预训练机制&lt;/strong&gt;对大规模数据的概率特征的&lt;strong&gt;高效建模&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;强化学习的&lt;strong&gt;试错进化&lt;/strong&gt;，也不过是达尔文主义在数字世界的投影&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这个深度学习主导的“暴力美学”时代，重访人工智能发展的潮起潮落，不仅是为了理解技术演进的内在逻辑，更是为了在算法黑箱与人类认知的裂隙中，寻找智能本质的蛛丝马迹。本文将系统地&lt;strong&gt;梳理人工智能发展的三次高潮与两次低谷，剖析符号主义、连接主义、行为主义三大流派的哲学分野&lt;/strong&gt;，并探讨哥德尔不完备定理对强人工智能的理论约束。通过跨学科的视角，试图在数学的严谨、神经科学的实证与哲学的思辨之间，勾勒人工智能演进的探索过程以及可能图景。&lt;/p&gt;
&lt;h2 id=&#34;理论开端&#34;&gt;理论开端&lt;/h2&gt;
&lt;h3 id=&#34;可形式化与可计算&#34;&gt;可形式化与可计算&lt;/h3&gt;
&lt;p&gt;1900年，数学家&lt;strong&gt;大卫·希尔伯特&lt;/strong&gt;于向国际数学界提出了著名的“&lt;strong&gt;二十三个数学问题&lt;/strong&gt;”，其中第二个和第十个问题与人工智能的&lt;strong&gt;理论可能性&lt;/strong&gt;和&lt;strong&gt;实现可能性&lt;/strong&gt;紧密相关：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;问题二：&lt;strong&gt;算术公理的一致性证明&lt;/strong&gt;：证明在算术系统中，基于该系统内的公理规则，不存在能够同时成立又相互矛盾的定理。&lt;/li&gt;
&lt;li&gt;问题十：&lt;strong&gt;丢番图方程的可解性判定&lt;/strong&gt;：是否存在一种算法，可以通过有限步骤判断任意给定的丢番图方程（Diophantine equation）是否有整数解。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1931年&lt;strong&gt;库尔特·哥德尔&lt;/strong&gt;提出了著名的&lt;strong&gt;哥德尔不完备定理&lt;/strong&gt;证否问题二。哥德尔不完备定理表明，在任何一致的形式系统中，&lt;strong&gt;总存在一些命题无法在这个系统内部被证明或证伪，即该系统是不完备的，一定存在逻辑矛盾的表述&lt;/strong&gt;。典型示例如语言符号系统中的&lt;strong&gt;说谎者悖论&lt;/strong&gt;：“这句话是假的”。&lt;/p&gt;
&lt;p&gt;1970年&lt;strong&gt;尤里·马季亚谢维奇&lt;/strong&gt;证明了无法通过固定的算法步骤来判断所有丢番图方程是否具有整数解，从而证否了问题十。问题十和图灵停机问题是等价的。&lt;strong&gt;图灵停机问题&lt;/strong&gt;（Halting Problem）是图灵于1936年提出的，该问题是说：是否存在一个算法对于任意给定的程序和输入，可以判定程序最终会停止运行（停机）还是会无限期地运行下去。图灵自己通过反证法证明图灵停机问题是不可判定的。&lt;/p&gt;
&lt;p&gt;这两个问题都在理论上被证否了，也就是说：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不是所有问题都可以被形式系统所表征。也就是说&lt;strong&gt;形式系统不能抽象所有现实问题&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;不能所有被形式系统表征的问题都可以通过计算来解决。也就是说&lt;strong&gt;计算不能解决所有可形式化的问题&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于问题的范围大于可形式化的范围，而可形式化的范围又大于可计算的范围，所以&lt;strong&gt;可形式化和可计算理论就限定了机器计算的边界&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;皇帝的新脑&#34;&gt;皇帝的新脑&lt;/h3&gt;
&lt;p&gt;罗杰·彭罗斯在《皇帝的新脑》中论证，基于哥德尔不完备定理，人类心智具有超越算法的能力。这就引出一个根本问题：如果人类智能确实超越了算法计算，那么模拟人脑的努力是否有内在的理论限制？或者说，&lt;strong&gt;我们是否需要开发出本质上不同于现有计算范式的新型智能系统？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此外罗杰·彭罗斯提出的&amp;quot;意识的量子理论&amp;quot;暗示大脑可能利用了量子效应。虽然这一观点仍有争议，但它启发我们思考：未来的人工智能是否会利用量子叠加、纠缠甚至意识的量子基础，创造出全新的智能形式？这种&amp;quot;量子计算&amp;quot;可能比现有的基于经典计算的人工智能拥有本质上不同的能力边界。&lt;/p&gt;
&lt;p&gt;由于目前理论上对机器计算能力的这种约束，有人认为机器模拟智能是不可能的。但图灵反驳说：“尽管已经证明任何一台特定的机器能力都是有限的，但&lt;strong&gt;并没有任何证据说，人类智能就没有这种局限性。&lt;/strong&gt;”&lt;/p&gt;
&lt;h3 id=&#34;图灵机&#34;&gt;图灵机&lt;/h3&gt;
&lt;p&gt;图灵机计算模型为现代计算机科学奠定了理论基础。但图灵机的提出可能是计算机科学史上最大的讽刺之一，因为图灵本来是为证明有些事情（停机问题）是计算机永远也做不了的，而设计的一种定义机械计算过程的抽象计算模型。图灵机的基本思想是模拟人类日常的“计算”行为，通过一根&lt;strong&gt;无限长&lt;/strong&gt;的纸带、一个&lt;strong&gt;读写头&lt;/strong&gt;以及一组状态转换&lt;strong&gt;规则&lt;/strong&gt;来模拟任何算法的“机械”计算过程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;纸带&lt;/strong&gt;（带行草稿纸）：被划分为一个个单元格，每个单元格可以存储一个符号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;读写头&lt;/strong&gt;（笔头）：可以在纸带上左右移动，读取当前单元格的内容或向其中写入新符号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态寄存器&lt;/strong&gt;（短期记忆）：存储机器当前的状态。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;状态转换规则集&lt;/strong&gt;（运算法则）：根据当前状态和读写头下的符号决定下一步操作，包括更改状态、写入新符号及移动读写头的方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在每个动作完成后，根据当前所关注的纸带某个&lt;strong&gt;位置上的符号&lt;/strong&gt;以及寄存器中存储的&lt;strong&gt;状态&lt;/strong&gt;（类似人短期记忆中的状态），来决定下一步的动作是什么。&lt;/p&gt;
&lt;h4 id=&#34;图灵完备&#34;&gt;图灵完备&lt;/h4&gt;
&lt;p&gt;设计图灵机的初衷是为了探讨机器计算的边界，即机器计算不可以（反面即可以）实现哪些算法。由于图灵机计算模型非常直观、易于理解，而且很容易通过机械或者电子技术来实现。因此，它迅速&lt;strong&gt;成为机器解决“如何计算”问题的基础，在计算理论上也成为了可计算性的对标物&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;这就引出了“&lt;strong&gt;图灵完备&lt;/strong&gt;”这一概念，如果一台设备实现了图灵机计算模型定义的行为，则称该设备是图灵完备的，理论上它可以解决所有可计算问题。当一个新的计算模型出现时，人们通过它是否能够解决所有可计算问题来判定它是否是图灵等价或者图灵完备的。今天，如果称一门程序设计语言是图灵完备的，意思是所有可计算的算法都能够用这种语言来实现 。&lt;/p&gt;
&lt;p&gt;图灵给出了用机械操作来模拟人类用纸笔运算过程这一解决可计算问题的计算模型“图灵机”，而冯·诺依曼则给出了实现这一计算模型的物理架构“冯·诺依曼架构”，于是通用计算机的“灵魂”与“躯体”就都有了。虽然通用计算机不能解决所有问题，但它至少可以解决可计算问题，也就是说可以解决现实世界中可被符号化中的可计算的那一部分问题。&lt;/p&gt;
&lt;h3 id=&#34;np-问题&#34;&gt;NP 问题&lt;/h3&gt;
&lt;p&gt;前面提到图灵机在理论上可以解决所有可计算问题，但这个“理论上”是在“&lt;strong&gt;无限纸带&lt;/strong&gt;”的前提下才可能实现的，换句话说就是&lt;strong&gt;在计算资源无限供应的情况下可解&lt;/strong&gt;。而在现实中，这个约束条件对于求解那些计算规模超级大的算法是很不现实的。由 &lt;em&gt;Steve Cook&lt;/em&gt; 于 1971 年提出的 NP 问题就是这样一类问题，用计算机来求解它们是非常低效的，甚至因计算规模随输入规模呈指数级增长而变得完全不可行。P vs NP 问题猜想被列为计算机科学和数学领域的核心难题，是克雷数学研究所列出的七大千禧年难题之一，该所为这七大世纪难题的每一个都悬赏一百万美元的奖金。&lt;/p&gt;
&lt;h4 id=&#34;p-问题&#34;&gt;P 问题&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：所有可以在&lt;strong&gt;多项式时间&lt;/strong&gt;内被确定性图灵机&lt;strong&gt;解决&lt;/strong&gt;的问题的集合。换句话说，对于某个确定性的图灵机（即算法），如果一个问题能够在输入大小的多项式时间内得到解答，则该问题属于 P 类。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：排序算法、最短路径问题、最小生成树问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;np-问题-1&#34;&gt;NP 问题&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：所有可以在&lt;strong&gt;多项式时间&lt;/strong&gt;内被非确定性图灵机&lt;strong&gt;验证解&lt;/strong&gt;的问题的集合。这意味着如果你有一个候选解，你可以快速检查这个解是否满足条件，即使找到这个解可能很困难。&lt;/li&gt;
&lt;li&gt;​&lt;strong&gt;P ⊆ NP&lt;/strong&gt;：所有 P 问题都属于 NP 问题，因为&lt;strong&gt;能高效求解的问题必然能高效验证解&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;例子&lt;/strong&gt;：旅行商问题、背包问题、图着色问题等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;np-完全问题np-complete&#34;&gt;NP 完全问题（NP-Complete）​&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;定义&lt;/strong&gt;：NP 完全问题是 NP 问题中最难的一类，它同时满足两个条件：
&lt;ol&gt;
&lt;li&gt;属于 NP 类；&lt;/li&gt;
&lt;li&gt;所有 NP 问题可归约到它​（即存在多项式时间归约）。规约的意思是：若问题 A 可归约为问题 B，则 B 至少和 A 一样难，即若有算法能解决 B，那么 A 也可以用同样复杂度的算法解决。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;特点&lt;/strong&gt;：如果任何一个 NP 完全问题可以在多项式时间内解决，那么所有的 NP 问题都可以在多项式时间内解决，这意味着 P=NP。相反，如果能证明任何一个 NPC 问题是无法在多项式时间内解决的，则 P≠NP。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;p--np-猜想&#34;&gt;P ≠ NP 猜想&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;含义&lt;/strong&gt;：是否所有 NP 问题都能高效求解，大多数科学家认为不能，即 ​&lt;strong&gt;P类 ≠ NP类&lt;/strong&gt;，这就意味着&lt;strong&gt;有些问题找解很难，但验证解很容易&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;如果 &lt;strong&gt;P=NP&lt;/strong&gt; 被证明是真的，这将打破目前的“计算不可逆”假设，从而对加密学（RSA等协议依赖NP问题的困难性假设）、人工智能（对抗样本防御）、算法优化等领域产生革命性影响，因为许多目前认为难以解决的问题都将变得易于处理。&lt;/li&gt;
&lt;li&gt;如果 &lt;strong&gt;P≠NP&lt;/strong&gt; 被证明是真的，虽然不会改变当前的技术实践，但它会正式确认许多重要问题确实没有高效的解决方案，从而指导研究人员更加专注于开发有效的&lt;strong&gt;近似算法&lt;/strong&gt;和&lt;strong&gt;启发式方法&lt;/strong&gt;来应对这些难题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;自 NP 问题提出起，人工智能领域的研究人员就利用 NP 完全问题理论来研究他们的课题，结果发现不管哪个领域：问题解决、玩游戏、规划、学习、推理等，似乎任何关键性的问题都是 NP 完全问题。这种现象使得业界流传着一个笑话：所谓的“AI完全问题”意味着“一个和AI本身一样难的问题”，如果你能解决一个AI完全问题，你就能解决所有AI问题。&lt;/p&gt;
&lt;p&gt;当前人工智能中的最关键的神经网络算法虽然不属于&lt;strong&gt;NP完全问题（NPC）​&lt;/strong&gt;，但其训练过程与NP问题的求解在&lt;strong&gt;计算复杂度&lt;/strong&gt;和&lt;strong&gt;近似解策略&lt;/strong&gt;上高度关联。神经网络训练属于&lt;strong&gt;非凸优化问题&lt;/strong&gt;​（通常为NP难问题），二者虽不属于同一复杂性类别，但均面临“搜索空间庞大”和“缺乏确定性高效算法”的共性挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;参数空间的维度爆炸与计算复杂度&lt;/strong&gt;：神经网络训练的优化问题本质上是非凸的，其参数规模通常达到百万甚至千亿级别（如GPT-4的参数规模达到了1.8万亿）。随着参数量的增加，搜索空间的维度呈指数级增长，这与NP问题（如旅行商问题）的输入规模扩大时计算量爆炸的特性相似。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;近似解策略&lt;/strong&gt;：神经网络的优化算法不保证找到全局最优解，但根据梯度下降的局部最优性，往往能发现足够好的局部最优解。这类似于NP问题中启发式算法（如模拟退火、遗传算法）的近似求解思路。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;图灵测试&#34;&gt;图灵测试&lt;/h3&gt;
&lt;p&gt;关于何为智能，图灵和香农观点不一样。香农倾向于强人工智能（通用人工智能），认为应该包括艺术、情感、音乐等。而图灵则不这么认为，他在反驳香农时是这么说的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“不！我对如何建造一颗无所不能的大脑完全不感兴趣，我只要一颗并不太聪明的大脑，和美国电报电话公司董事长的脑袋那样差不多就行了！”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;图灵用一向的“逆向思维”（前面他就用反证法证明了图灵停机问题的不可判定），不从正面给智能下定义，而是根据外部行为来判定机器是否拥有智能，这就是论文《计算机器和智能》中给出的“图灵测试”：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“如果人类由于无法分辨一台机器是否具备与人类相似的智能，导致无法分辨与之对话的到底是人类还是机器，那即可认定机器存在智能。”&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;“&lt;strong&gt;图灵测试&lt;/strong&gt;”为衡量机器是否具备智能提供了一种标准。常见的图形验证码就是图灵测试的一种典型应用，验证码的英文单词“&lt;strong&gt;Captcha&lt;/strong&gt;”就是“通过图灵测试来完全自动地分辨出计算机和人类”这句话的首字母缩写（Completely Automated Public Turing test to tell Computers and Humans Apart）。后来著名的“中文屋”实验也采用了这个思路。&lt;/p&gt;
&lt;p&gt;彼时，图灵对智能的关注点在于&lt;strong&gt;思考&lt;/strong&gt;，这里的思考不是从内部的结构模式出发考察的，而是从外部可观察到的行为着手，即机器通过学习而获得某项技能，并通过将这项技能表现出来的智能行为。所以图灵在论文中重点论证了建造“学习机器”（Learning Machines）的可行性，更具体地说，是论证机器依靠学习进化而最终通过图灵测试的可能性。&lt;/p&gt;
&lt;h3 id=&#34;通用人工智能智能能被模拟么&#34;&gt;通用人工智能：智能能被模拟么&lt;/h3&gt;
&lt;p&gt;由于形式系统的不完备性以及存在不可判定的计算问题，因此世界上总有些问题是无法被机器模拟的。那回到图灵与香农最初探讨的问题：&lt;strong&gt;人类的智能是否能够被某种模型所模拟（抽象）？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果是，那必将存在着人类智能绝对无法解决的问题；&lt;/li&gt;
&lt;li&gt;如果不是，那人类就很难制造出能够拥有人类思维的机械智能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;像说谎者悖论“这句话是假的”、罗素的理发师悖论“理发师只给那些不给自己刮胡子的人刮胡子”这样涉及自指的问题，一般都要上升一个层面或维度才能解决。这有点像自我意识套娃：&lt;strong&gt;我在思考我在思考&lt;/strong&gt;。对这个问题，图灵的回答是“&lt;strong&gt;人也不是完备的&lt;/strong&gt;”。对于机器是否必须具备和人类一样的思维意识才能算人工智能，语言和认知学家诺姆·乔姆斯基的回答是“&lt;strong&gt;潜艇能够游泳吗？&lt;/strong&gt;”&lt;/p&gt;
&lt;p&gt;而澳大利亚哲学家&lt;strong&gt;大卫·查尔默斯&lt;/strong&gt;提出&amp;quot;意识难题&amp;quot;质疑：即使我们完全理解了大脑的物理机制，仍无法解释为何会产生&lt;strong&gt;主观体验的感受性&lt;/strong&gt;。这对人工智能提出了根本挑战：即使人工智能系统表现出与人类相似的行为，我们有理由相信它拥有类似人类的主观体验吗？&lt;strong&gt;托马斯·内格尔&lt;/strong&gt;也在其著作《成为一只蝙蝠是什么感受》中提出，&lt;strong&gt;主观体验是无法通过客观描述来完全理解的&lt;/strong&gt;。他认为，即使我们能够完全了解蝙蝠的大脑结构和功能，也无法真正知道“成为一只蝙蝠是什么感受”。&lt;strong&gt;意识产生于有主观体验的智能体：拥有主观上的内在感受性&lt;/strong&gt;，重点就在于对内在心理现象的感知。 这暗示&lt;strong&gt;我们可能需要超越计算理论的框架来理解意识本质，而这正是强人工智能与弱人工智能之争的核心&lt;/strong&gt;。（非确定性 VS 确定性，可以用量子物理 VS 经典物理来类比思考）&lt;/p&gt;
&lt;p&gt;智能的本质究竟是计算、理解、模拟、创造还是感受？从计算的角度看，图灵机模型暗示了智能的可计算性；从现象学角度看，智能与体验、意图不可分割；从演化角度看，智能本质上是适应性解决问题的能力。这些不同视角暗示我们可能需要一个多元、立体的智能观，而非单一的理解框架。未来人工智能的重大突破很可能来自跨学科交叉融合。特别是将数学理论、神经科学的大脑工作机制、心理学的人类认知模式、哲学的本体论思考与计算机科学的实现方法相结合，可能是走向通用人工智能的必由之路。&lt;/p&gt;
&lt;h2 id=&#34;发展历程三次高潮与两次低谷&#34;&gt;发展历程：三次高潮与两次低谷&lt;/h2&gt;
&lt;p&gt;在强大的军事需求的刺激下，二战后不久，&lt;strong&gt;系统论（1945）、信息论（1948）、控制论（1948）&lt;/strong&gt; 这“信息学三论”的开创性著作相继发表，使之前零散研究摸索的信息科学得以系统有序起来。从此信息计算、人工智能、控制自动化相关领域飞速发展，当然发展的过程也是跌宕起伏。人工智能的发展是一部充满希望与挫折的探索史，凝聚了无数科学家的智慧与坚持。从图灵机的理论奠基到深度学习的爆发，人工智能历经三次高潮与两次低谷，展现了人类对智能本质的不懈追求。&lt;/p&gt;
&lt;h3 id=&#34;第一次高潮1950s-1970s符号主义崛起与逻辑推理的黄金时代&#34;&gt;第一次高潮（1950s-1970s）：符号主义崛起与逻辑推理的黄金时代&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1950年&lt;/strong&gt;：图灵提出“图灵测试”，奠定智能机器的哲学基础。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1956年&lt;/strong&gt;：达特茅斯会议召开，麦卡锡首次提出“人工智能”概念，符号主义成为主流。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1960年代&lt;/strong&gt;：LISP 语言诞生，逻辑推理与专家系统初现雏形。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1960年代&lt;/strong&gt;：M-P神经元模型和单层神经网络感知机。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低谷原因&lt;/strong&gt;：
符号主义依赖人工规则和逻辑推理，但规则难以穷尽，因而难以应对复杂现实问题。连接主义的单层神经网络感知机无法处理异或问题。再加上当时计算机的计算能力非常薄弱。1973年《莱特希尔报告》批评 AI 研究缺乏实际成果，经费锐减，进入第一次寒冬。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第二次高潮1980s-1990s知识工程与专家系统的兴衰&#34;&gt;第二次高潮（1980s-1990s）：知识工程与专家系统的兴衰&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;1980年代&lt;/strong&gt;：专家系统（如MYCIN）在医疗、金融领域崭露头角，知识工程成为研究热点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;1986年&lt;/strong&gt;：辛顿提出误差反向传播算法（BP算法），使神经网络重获关注。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;低谷原因&lt;/strong&gt;：
专家系统依赖人工知识输入，但静态知识难以同步动态世界，因而难以穷尽、扩展和维护。全面常识知识工程CYC的幻灭。布鲁克斯（iRobot扫地机器人创始人）基于行为主义思想对知识系统进行了猛烈批判，认为不可能预装一切知识，而应该通过环境互动试错演进。1990年代统计学习方法（如支持向量机）兴起，连接主义暂未突破，AI再次遇冷。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;第三次高潮2006年至今深度学习革命与ai的全面爆发&#34;&gt;第三次高潮（2006年至今）：深度学习革命与AI的全面爆发&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心事件&lt;/strong&gt;：
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;2006年&lt;/strong&gt;：辛顿发表深度信念网络论文，开启深度学习时代。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2012年&lt;/strong&gt;：AlexNet 在 ImageNet 竞赛中碾压传统方法，深度学习引爆产业热潮。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2016年&lt;/strong&gt;：在围棋比赛中，AlphaGo 击败世界冠军李世石，这是深度强化学习与蒙特卡洛树搜索结合的突破性成果，标志着AI首次在高度复杂的&lt;strong&gt;完全信息&lt;/strong&gt;博弈中超越人类顶尖水平。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2017年&lt;/strong&gt;：Transformer架构，由 Vaswani 等人在论文《Attention is All You Need》中首次提出，通过&lt;strong&gt;自注意力机制&lt;/strong&gt;彻底革新了NLP领域。Transformer摒弃了传统的RNN结构，采用纯注意力机制实现并行计算，解决了长序列依赖问题。这一架构不仅成为BERT、GPT等所有现代大型语言模型的基础，还因其设计上的灵活性被广泛应用于计算机视觉等领域，成为跨模态AI发展的关键基石。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2020&lt;/strong&gt;：GPT-3 发布，参数量达到1750亿，标志着AI的重大突破，能够在广泛的任务中生成类人文本，显示了强大的少样本学习能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2022年&lt;/strong&gt;：ChatGPT 发布，专为对话交互设计，结合了人类反馈强化学习(RLHF)，引发大众对 AI 热潮。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;2024年&lt;/strong&gt;：Deepseek系列模型发布，它通过优化模型结构和训练方法，在保持强大性能的同时大幅降低了成本。Deepseek不仅成本低，还是完全免费开源的，这就为AI应用落地打开了无限的可能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当前挑战&lt;/strong&gt;：
深度学习依赖大数据与算力、可解释性不足、理论根基薄弱、伦理与安全问题亟待解决。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;三大流派&#34;&gt;三大流派&lt;/h2&gt;
&lt;p&gt;根据不同的理念，人工智能的发展过程中出现了三种流派：符号主义演绎着人类心智的逻辑架构（&lt;strong&gt;人心&lt;/strong&gt;），连接主义编织着神经元网络的结构密码（&lt;strong&gt;人脑&lt;/strong&gt;），行为主义则捕捉着机体与环境互动的反馈奥秘（&lt;strong&gt;人身&lt;/strong&gt;）。如果说心智派在研究模拟智能的&lt;strong&gt;软件&lt;/strong&gt;，结构派在研究模拟智能的&lt;strong&gt;硬件&lt;/strong&gt;，那行为派就是在模拟智能生物的&lt;strong&gt;身体&lt;/strong&gt;了。&lt;/p&gt;
&lt;p&gt;用神经元模型的发明者、数理逻辑学家&lt;strong&gt;沃尔特·皮茨&lt;/strong&gt;（Walter Pitts，1923—1969）话来总结：“在我们面前有两条通向智能的路径，一条是模拟人脑的结构，一条是模拟人类心智，但我相信这两条路最终是殊途同归的。”从人工智能的发展历程上看，皮茨的总结非常有预见性，人工智能的探索历程就是结构派和“心智派交替提出新理论和新发现，交替占据主流地位的发展史，而具身智能的发展又离不开行为派的贡献。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;流派&lt;/th&gt;
          &lt;th&gt;时间段&lt;/th&gt;
          &lt;th&gt;理念&lt;/th&gt;
          &lt;th&gt;范式&lt;/th&gt;
          &lt;th&gt;核心人物&lt;/th&gt;
          &lt;th&gt;关键事件&lt;/th&gt;
          &lt;th&gt;优缺点&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;符号主义&lt;/strong&gt;，心智派&lt;/td&gt;
          &lt;td&gt;1950s-1980s&lt;/td&gt;
          &lt;td&gt;智能源于符号计算与逻辑推理&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;演绎&lt;/strong&gt;：逻辑推理、知识表示&lt;/td&gt;
          &lt;td&gt;麦卡锡、明斯基、纽厄尔、司马贺&lt;/td&gt;
          &lt;td&gt;达特茅斯会议、LISP语言发明、专家系统、知识系统&lt;/td&gt;
          &lt;td&gt;强可解释性、弱抽象、弱学习&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;连接主义&lt;/strong&gt;，结构派，&lt;/td&gt;
          &lt;td&gt;1980s-至今&lt;/td&gt;
          &lt;td&gt;仿生大脑神经网络结构&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;归纳&lt;/strong&gt;：神经网络、深度学习&lt;/td&gt;
          &lt;td&gt;麦卡洛克、皮茨、罗森布拉特、辛顿、杨立昆、本希奥&lt;/td&gt;
          &lt;td&gt;M-P神经元模型、蛙眼实验、感知机、ImageNet竞赛、ChatGPT&lt;/td&gt;
          &lt;td&gt;强泛化、强学习、弱可解释性、强规模依赖&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;行为主义&lt;/strong&gt;：行为派&lt;/td&gt;
          &lt;td&gt;1940s-至今&lt;/td&gt;
          &lt;td&gt;在环境中行为反馈试错演化、组件化&lt;/td&gt;
          &lt;td&gt;&lt;strong&gt;反馈&lt;/strong&gt;：感知-动作闭环、强化学习&lt;/td&gt;
          &lt;td&gt;维纳、布鲁克斯&lt;/td&gt;
          &lt;td&gt;控制论提出、机器人学发展&lt;/td&gt;
          &lt;td&gt;强学习、弱抽象、弱可解释性、组件数量规模限制&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;值得注意的是，当代人工智能发展实际上正逐步融合这三大流派的优势。符号主义的可解释性、连接主义的抽象能力与行为主义的环境互动，正通过类似于神经符号系统(Neurosymbolic AI)等新范式相互补充。理想的人工智能系统可能需要既能从数据中抽象学习（连接主义），又能进行逻辑推理（符号主义），同时能在环境互动通过反馈强化学习（行为主义）。&lt;/p&gt;
&lt;h3 id=&#34;符号主义&#34;&gt;符号主义&lt;/h3&gt;
&lt;p&gt;在人工智能的发展历程中，基于符号的智能研究曾经是大多数学者努力的方向，甚至在长达30年的时间里，符号主义的学说在人工智能这个学科里是占统治地位的。&lt;/p&gt;
&lt;p&gt;符号主义学派的思想和观点直接继承自图灵，提倡直接从功能的角度来理解智能，简而言之就是把智能视为一个黑盒，只关心这个黑盒的输入和输出，而不关心黑盒的内部结构。为了实现智能，符号主义学派利用“符号”（Symbolic）来抽象表征现实世界，利用逻辑推理和搜索来替代人类大脑的思考、认知过程，而不去关注现实中大脑的神经网络结构，也不关注大脑是不是通过逻辑运算来完成思考和认知的。概括来说，符号主义的理念是：“&lt;strong&gt;认知即计算&lt;/strong&gt;”，符号主义的思路是：“&lt;strong&gt;描述已知，推理未知&lt;/strong&gt;”。&lt;/p&gt;
&lt;p&gt;对于符号主义学派长达数十年的探索研究过程，根据研究问题的不同，可以将其划分为三个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;推理期&lt;/strong&gt;：最初这派的学者并未过多考虑知识的来源问题，而是假设知识是先验地存储于黑盒之中的，重点解决的问题是&lt;strong&gt;利用现有的知识去做复杂的推理、规划、逻辑运算和判断&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;知识期&lt;/strong&gt;：由于大家发现智能的体现并不能仅依靠推理来解决，先验的知识是更重要的一环，研究重点就转变为&lt;strong&gt;如何获取知识、表示知识和利用知识&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;学习期&lt;/strong&gt;：由于知识仅依靠人类专家总结、提炼然后输入计算机的方式无法应对世界上几乎无穷无尽的知识，研究的重点又转为如何&lt;strong&gt;让机器自己学习知识、发现知识&lt;/strong&gt;这个方向。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而根据研究思路的不同，可以分为两个支派：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;认知派&lt;/strong&gt;：以&lt;strong&gt;纽厄尔&lt;/strong&gt;和&lt;strong&gt;司马贺&lt;/strong&gt;领导的&lt;strong&gt;卡内基梅隆大学&lt;/strong&gt;为主，他们是从人类问题解决的思维活动出发，尝试将这种&lt;strong&gt;思维过程模型化&lt;/strong&gt;后，应用于计算机之上。他们经常基于心理学实验的结果来开发模拟人类解决问题方法的程序，这种研究方法一度成为人工智能和符号主义的主流。他们提出物理符号系统来尝试解释智能来源机制的理论，它试图模拟人类如何获取、储存、传播和处理信息的，并提供了一种将这个过程中各种现象模型化，迁移到计算机中实现的途径。该理论主要由两个假说构成，分别是&lt;strong&gt;物理符号系统假说&lt;/strong&gt;（智能行为的抽象模型，符号即模式特征）和&lt;strong&gt;启发式搜索假说&lt;/strong&gt;（解决问题或做出决策的抽象模型）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;逻辑派&lt;/strong&gt;：以&lt;strong&gt;麦卡锡&lt;/strong&gt;领导的斯坦福大学为主，他们认为直接找出抽象推理和解决问题的本质，只要通过&lt;strong&gt;逻辑推理&lt;/strong&gt;能展现出智能行为即可，大可不必去管人类是否使用同样的方式思考。在麦卡锡看来，对于特定问题的解决方法是“知识”，对于普适智能行为则需要“常识”才行，因此他关注“如何才能令机器拥有常识”这样的问题。他提出了 LISP（LISt Processing的缩写）语言的构想，而他的学生则实现了该语言，这使得他在计算机程序语言领域获得了可媲美“人工智能之父”头衔的荣誉与地位。&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;启发式搜索的概念就是使用“经验法则”来指导搜索的重点&lt;/strong&gt;。通常我们也无法寻找到直指正确搜索路径的方法，但我们往往可以在感兴趣的问题上找到启发式搜索方向，从而大大减少搜索量。&lt;/p&gt;&lt;/blockquote&gt;
&lt;h3 id=&#34;连接主义&#34;&gt;连接主义&lt;/h3&gt;
&lt;h4 id=&#34;m-p神经元模型&#34;&gt;M-P神经元模型&lt;/h4&gt;
&lt;p&gt;连接主义这一派主要是研究&lt;strong&gt;人类大脑神经网络结构&lt;/strong&gt;的学者，他们主张从生物结构角度出发，让机器先去模拟人脑构造，再在“大脑是如何处理信息”的过程中获得智能。他们用神经元细胞要么发射信号、要么不发射信号的离散、二元的特征，比拟“与”、“或”、“非”这些最基础的逻辑门的性质。因此，神经元网络就像由逻辑门构成的网络。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;麦卡洛克&lt;/strong&gt;和&lt;strong&gt;皮茨&lt;/strong&gt;的《神经活动中内在思想的逻辑演算》一文被认为是连接主义研究的开端，首次提出了“神经网络”（Neural Network）这个概念，提出了被后人以两人首字母命名的机械式的思维模型：“&lt;strong&gt;M-P神经元模型&lt;/strong&gt;”。但在一次探索眼神经功能的蛙眼实验之后，皮茨对大脑是唯一的神经信号处理中心的信念破灭了，他意识到纯粹的逻辑、纯粹以大脑为中心的思想观是有局限性的。再加上维纳的支持纳粹的妻子作梗，皮茨、麦卡洛克与维纳交恶，皮茨在情感上、学术方向上都备受打击，一颗巨星就此陨落。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神经网络学习的基本原理就是从训练数据集中提取出分类特征，这些特征应该能够适用于相同分布的测试数据集&lt;/strong&gt;，所以经已知数据学习训练（即预训练）后的神经网络可以对同类的未知数据有效。&lt;strong&gt;神经网络学习是基于特征匹配的概率，它不是基于逻辑推理，因为它能做分类识别，但无法理解&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;感知机&#34;&gt;感知机&lt;/h4&gt;
&lt;p&gt;康奈尔大学的实验心理学家&lt;strong&gt;罗森布拉特&lt;/strong&gt;在“&lt;strong&gt;M-P神经元模型&lt;/strong&gt;”的基础上实现了一种称为“感知机”（Perceptron）的单层神经网络模型。 皮茨和麦卡洛克曾向人们展示了M-P神经元可以通过不同的连接方式和权重来实现逻辑与、或、非运算，罗森布拉特的感知机基本原理，就是利用了神经元可以进行逻辑运算的特点，通过“&lt;strong&gt;赫布法则&lt;/strong&gt;”（Hebb&amp;rsquo;s Law）的学习机制，调整连接线上的权重和神经元上的阈值，做到不依靠人工编程，仅靠机器学习来完成一部分机器视觉和模式识别方面的任务，这就展现了一条独立于图灵机之外的，全新的实现机器模拟智能的道路&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1949年，赫布出版了《行为组织学》（Organization of Behavior）一书。在该书中，赫布总结提出了被后人称为“&lt;strong&gt;赫布法则&lt;/strong&gt;”（Hebb&amp;rsquo;s Law）的学习机制。他认为如果两个神经元细胞总是同时被激活的话，它们之间就会出现某种关联，同时激活的概率越高，这种关联程度也会越高。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;罗森布拉特因感知机获得巨大的成功，并获得美国军方的支持。但成也感知机，败也感知机。&lt;strong&gt;明斯基&lt;/strong&gt;对高调的罗森布拉特研究感知机存在的价值和前途发起了攻击，他在《感知机：计算几何学导论》一书中在数学上证明了基于单层神经网络的“感知机能解决线性可分的问题，但是它也仅仅能解决线性可分的问题。”更准确地说是&lt;strong&gt;单层的感知机只能处理在特定特征上线性可分的数据集，并不能处理非线性数据的分类问题，其中最典型的就是“异或问题”&lt;/strong&gt;，而多层神经网络的感知机需要巨大规模的计算与数据，受当时的算力与数据规模限制，根本不可能想象，就更别说实现了。明斯基在第一版中明确说“这里（指罗森布拉特的理论）的大部分内容都没有多少科学价值。”&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果把逻辑与、或、非运算输入数据，按照0、1值构成二维的坐标平面，并把逻辑运算结果为1的用红色方块表示，结果为0的用蓝色圆圈表示，就形成了二维的图表，这三种逻辑运算都能够很直观地通过一条直线将这个二维坐标平面中的数据划分开来。 而异或则不能。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;由于明斯基在人工智能领域的特殊地位与影响（第四届图灵奖获得者），罗森布拉特被整个人工智能学术界声讨。1971年，43岁的罗森布拉特在一次划船事故中不幸遇难。也许出于愧疚心理，明斯基在《感知机》第二版中删除了攻击罗森布拉特的话，并在扉页上手写了“纪念弗兰克·罗森布拉特”。连接主义与神经网络也和罗森布拉特一样备受打击，这一场风波可以说至少延误神经网络研究十年以上的发展。&lt;/p&gt;
&lt;p&gt;不久，1973年受英国政府委托的数学家&lt;strong&gt;詹姆士·莱特希尔&lt;/strong&gt;发表了赫赫有名的《莱特希尔报告》，这篇公开的报告是一份具有广泛影响力的、直接刺破人工智能乐观思潮泡沫的调查文件，被视作人工智能寒冬的开启。&lt;/p&gt;
&lt;h3 id=&#34;行为主义&#34;&gt;行为主义&lt;/h3&gt;
&lt;p&gt;1948年，图灵在论文《智能机器》里把研究智能的方向划分成了“&lt;strong&gt;具身智能&lt;/strong&gt;”（Embodied Intelligence）和“&lt;strong&gt;非具身智能&lt;/strong&gt;”（Disembodied Intelligence）两类。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“非具身智能”的研究演进成我们今天传统的基于计算（Computationalism）的认知科学，符号主义学派所主张的观点便是追寻这类智能的具体表现。以非具身智能的角度来看，所谓智能就是符号操作，起始于大脑的输入，终止于大脑的输出，智能和认知只关注这个符号操作过程。&lt;/li&gt;
&lt;li&gt;“具身智能”的研究则认为智能、认知都是与具体的身体、环境密切相关的，它们之间存在内在的和本质的关联，智能和认知两者必须以一个在环境中的具体的身体结构和身体活动为基础。智能是基于身体和涉及身体的，智能始终是具体身体的智能，而不能仅仅存在于脑海之中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;行为主义学派是1948年以“&lt;strong&gt;控制论之父&lt;/strong&gt;”&lt;strong&gt;维纳&lt;/strong&gt;的《控制论》的出版发行为起源标志的，因此又常被称为“&lt;strong&gt;控制论学派&lt;/strong&gt;”，根据其学说特点，有时候也被称作“&lt;strong&gt;演化主义学派&lt;/strong&gt;”。 控制论是在二战中英国防空战争中因研制自动火控系统而发展起来的。在《控制论》一书中，维纳对“机器能不能拥有智能行为”这个问题给予了正面的回答，提出了“智能性原则”：&lt;strong&gt;由信息、通信、控制和反馈构成的感知（输入）-行动（输出）系统就是智能的&lt;/strong&gt;。只要能够对环境的外部输入给予预期中的输出，这就是智能的体现，而无须去纠结是这样的系统是机器还是生物体。&lt;/p&gt;
&lt;p&gt;后期的控制论是一种统计理论，它关心的不是系统根据单独一次输入后产生的动作，而是&lt;strong&gt;对全部输入整体上能够做出合乎统计概率预期的动作&lt;/strong&gt;。在这个系统中，因果联系不再是完全确定的，它&lt;strong&gt;同时具有统计上的确定性和个体上的不确定性&lt;/strong&gt;，因而是一种统计上的因果关系。在控制系统中引入统计属性，从根本上改进了机械式的因果观念。此外行为主义还认为人工智能是应该和人类智能一样，依靠&lt;strong&gt;演化&lt;/strong&gt;获得，通过遗传过程的随机变异和环境对个体物竞天择的自然选择，逐代筛选出更快速、更健壮、更聪明的个体。iRobot创始人布鲁克斯曾经这样批判知识系统：预装全部知识是不可能的，也不是实现智能的正确途径，应该通过在环境中交互，通过试错反馈演化，即&lt;strong&gt;强化学习&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;机器学习&#34;&gt;机器学习&lt;/h2&gt;
&lt;p&gt;图灵在《计算机器和智能》中首次提出了“学习机器”（Learning Machines）的概念，以极具预见性的眼光洞察到能否实现人工智能的关键，很可能就取决于能否或者说何时解决“&lt;strong&gt;如何让机器拥有学习能力&lt;/strong&gt;”这个问题。&lt;/p&gt;
&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;司马贺&lt;/strong&gt;是最早（1959年）在学术上给出符合今天机器学习思想的定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果某个系统可以从经验中改进自身的能力，那这便是学习的过程。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;但司马贺没有具体限定经验、改进等要素。1998年卡内基梅隆大学的&lt;strong&gt;汤姆·米切尔&lt;/strong&gt;在他撰写的《机器学习》中额外增加了几个具有可操作性的辅助描述符号：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习就是一种可以让机器根据历史经验自动改进自身的学习算法。&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;他们俩都是&lt;strong&gt;从机器学习的本质出发，即从“是什么”、“做什么”的角度来定义机器学习&lt;/strong&gt;这个概念。还有一种方式是&lt;strong&gt;从“怎么做”这个角度来定义&lt;/strong&gt;。在李航老师的《统计学习方法》一书中，就提出机器学习由“模型”、“策略”和“算法”三个要素构成：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;机器学习＝模型+策略+算法&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;模型：是指机器学习所要产出的内容，它以一个可被计算的决策函数或者条件概率分布函数的形式存在&lt;/strong&gt;。把未知的新数据代入到这个模型中计算，就会得到符合真实情况的输出结果。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;策略：是指要按照什么样的准则进行学习，具体一点是按照什么样的准则评估选择出最优的模型&lt;/strong&gt;。从宏观角度讲，一般我们都会&lt;strong&gt;以“减少模型的输出结果与真实情况差距”以及学习复杂度作为学习的准则&lt;/strong&gt;，这里的“差距”同样也是以一个可被计算函数的形式来描述的，被称为“&lt;strong&gt;损失函数&lt;/strong&gt;”或“成本函数”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;算法&lt;/strong&gt;：是指&lt;strong&gt;如何把最能拟合真实世界的参数系数都找出来&lt;/strong&gt;。在确定寻找最优模型的策略后，机器学习的问题便归结为寻找出最优参数的优化问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在大方向上，机器学习最初是从基于&lt;strong&gt;规则&lt;/strong&gt;的机器学习开始的，现在正在朝着基于&lt;strong&gt;数据&lt;/strong&gt;的机器学习在持续迈进。基于&lt;strong&gt;规则演绎&lt;/strong&gt;和基于&lt;strong&gt;数据归纳&lt;/strong&gt;两种思维，分别对应了人类对现象规律（&lt;strong&gt;可计算的&lt;/strong&gt;）和对现象表现（&lt;strong&gt;可统计的&lt;/strong&gt;）的研究，也反映了符号主义学派和连接主义学派各自对机器学习的看法。&lt;/p&gt;
&lt;p&gt;如果把一切都看成由输入变换到输出的函数，那么符号主义是试图&lt;strong&gt;通过数学建模逻辑推导&lt;/strong&gt;出这个函数，而基于神经网络的连接主义则是试图&lt;strong&gt;通过输入与输出来逆向拟合&lt;/strong&gt;出这个函数，高效拟合的手段大多采用&lt;strong&gt;反向传播&lt;/strong&gt;，这整个过程也称为模型训练。&lt;/p&gt;
&lt;h3 id=&#34;模型训练&#34;&gt;模型训练&lt;/h3&gt;
&lt;p&gt;机器学习中所说的模型训练，是指从真实世界的一系列历史经验中获得一个可以拟合真实世界的决策模型 。上节提到模型训练过程是通过输入与输出来逆向拟合出目标函数：&lt;strong&gt;Function(输入)  = 输出，而 Function 是由：参数+系数+操作符 构成的&lt;/strong&gt;，也就是&lt;strong&gt;确定参数、系数和操作符的过程&lt;/strong&gt;。对于模型训练来说，这可以通俗理解为确定特征参数、优化系数、选择策略方法，因此模型训练主要聚焦在如下问题上：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特征：挑选哪些数据的哪些特征属性来当作参数，涉及：数据清洗，特征选择&lt;/li&gt;
&lt;li&gt;策略：如何选择损失函数，涉及：策略选择&lt;/li&gt;
&lt;li&gt;优化：如何优化参数系数，涉及：算法优化&lt;/li&gt;
&lt;li&gt;测试：如何测试模型&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;模型评估&#34;&gt;模型评估&lt;/h4&gt;
&lt;p&gt;模型选择是采取一种适当的学习策略，在大量数据的支持下，从假设空间（可选的决策/损失函数的全集）中筛选出一个最佳的模型。如何确定最佳模型的标准、用何种方法来学习得到这个最佳的模型，就是选择损失函数、理解其含义、如何求解和优化损失函数，从而得到满足损失函数最小值的模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一个模型的性能（performance）是指其泛化能力，也就是对满足相同分布规律的、训练集以外的数据的适应能力&lt;/strong&gt;。 “适应能力高低”是指模型输出值与实际值之间的“误差”（Error）的大小。“误差”是一个在统计学中被精确定义的概念，它在机器学习这个语境更加强调泛化而不是在训练集中，因此这里它被称为“&lt;strong&gt;期望泛化误差&lt;/strong&gt;”。误差是偏差、方差和噪声的总和：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;误差（Error）＝偏差（Bias）+方差（Variance）+噪声（Noise）。&lt;/p&gt;&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;偏差的含义是描述模型输出结果与真实标注的样例之间的差距，即模型在训练集上的&lt;strong&gt;拟合能力&lt;/strong&gt;。如果模型越复杂，引入的参数越多，那偏差就会小，但可能陷入过拟合；反之因为欠拟合，偏差就可能大。&lt;/li&gt;
&lt;li&gt;方差的含义是描述数据变化对模型输出结果的扰动影响，即模型对数据的&lt;strong&gt;敏感程度&lt;/strong&gt;。模型的复杂度越低，方差就越小，但可能陷入欠拟合；反之因为过拟合，方差就可能大。&lt;/li&gt;
&lt;li&gt;噪声是&lt;strong&gt;训练数据自身的错误&lt;/strong&gt;，即训练集中的部分样例数据的标注值与真实结果有差别。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;选择最优模型复杂度的一个最基本的准则就是偏差和方差之和最小，即要同时警惕避免发生训练过少导致模型复杂度过低（参数少）而&lt;strong&gt;欠拟合&lt;/strong&gt;和训练过度导致模型复杂度太高（参数多）而&lt;strong&gt;过拟合&lt;/strong&gt;的情况发生。“&lt;strong&gt;控制模型复杂度&lt;/strong&gt;”可以视为机器学习中除了“&lt;strong&gt;让模型的输出结果与实际结果差异最小&lt;/strong&gt;”之外的第二重要的目标。&lt;/p&gt;
&lt;h2 id=&#34;深度学习&#34;&gt;深度学习&lt;/h2&gt;
&lt;p&gt;现代科学已经基本确定了人的视觉系统的信息处理是分级的，从最低级像素提取边缘特征，再到稍高层次的形状或者目标的部分等，再到更高层的整体目标，以及目标的行为和其他特征的联想等。换句话说，&lt;strong&gt;高层的特征是低层特征的组合提炼，从低层到高层的特征表示越来越抽象，越来越能表现出认知的意图。抽象层面越高，存在的可能猜测就越少，就越利于分类&lt;/strong&gt;。 深度学习通过多层神经网络结构模拟了人类处理外界信息的“&lt;strong&gt;分层迭代、逐级抽象&lt;/strong&gt;”过程。这里的关键词有两个，一个是“抽象”，一个是“迭代”，从原始信号输入开始，先做低级的抽象，逐渐向高级抽象迭代。&lt;/p&gt;
&lt;p&gt;深度学习属于神经网络的一个子集，而神经网络又是机器学习的一个分支。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;机器学习&lt;/strong&gt;：是让计算机系统通过数据自动“学习”并改进其性能，而无需进行明确编程的能力。机器学习使用算法解析数据，从中学习，并对真实世界中的事件做出决策或预测。机器学习包括多种不同的学习方法和技术，如监督学习、非监督学习、强化学习等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;神经网络&lt;/strong&gt;：是机器学习领域中的一种模型或算法，它受到生物神经系统工作原理的启发，旨在模仿人类大脑处理信息的方式。神经网络由大量的节点（或称“神经元”）组成，这些节点被组织在多个层中，包括输入层、隐藏层和输出层。每个节点与相邻层的节点相连，通过连接权重传递信号。神经网络特别擅长识别复杂的数据模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;深度学习&lt;/strong&gt;：是神经网络的一个子集或者说是一种特定类型的神经网络架构。所谓“深度”，指的是网络中含有一个或多个隐藏层，使得网络能够学习数据的更高层抽象表示。深度学习利用了具有多层结构的神经网络，特别是深层神经网络（DNN）、卷积神经网络（CNN，特长：视觉识别）、循环神经网络（RNN，特长：时序依赖性的序列数据）及其变体等，以实现从大量未标注或半标注的数据中学习特征的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;深度学习历史&#34;&gt;深度学习历史&lt;/h3&gt;
&lt;p&gt;人工神经网络（Artificial Neural Network）这个概念最早是在皮茨与麦卡洛克合著的论文《神经活动中内在思想的逻辑演算》中首次提出，随后，由于罗森布拉特和他的感知机引起了全社会的广泛关注，促成了连接主义的第一波热潮。后来由于明斯基对单层神经网络的缺陷证明以及其个人的影响力，而多层神经网络受当时数据和算力规模限制而不可想象，神经网络跌落低谷，很多学术期刊拒绝接受标题中带神经网络字眼的论文。但在以多伦多大学&lt;strong&gt;杰弗里·辛顿&lt;/strong&gt;教授（“深度学习教父”，坐了40年冷板凳）为首的一批神经网络信仰者的共同努力下，神经网络最终以&lt;strong&gt;深度学习&lt;/strong&gt;的面目重返人工智能的舞台，并暂时占据主角地位。由于神经网络曾经在人工智能圈的坏“名声”，他们更愿意被称呼为机器学习下的深度学习，而非人工智能下的神经网络。&lt;/p&gt;
&lt;p&gt;2006年被认为是深度学习时代的元年，是以辛顿在这一年发表的两篇论文为标志的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一篇是《通过神经网络进行数据降维处理》的论文。这里“&lt;strong&gt;数据降维&lt;/strong&gt;”的方法就是用神经网络自动进行&lt;strong&gt;特征选择和提取&lt;/strong&gt;，此文实质性地开创了“深度学习”这个机器学习的新分支。&lt;/li&gt;
&lt;li&gt;第二篇文章《一种基于深度信念网络的快速学习算法》再次对“深度”这个词进行定义和包装，才变得火爆起来的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;辛顿在两篇文章中提出了以下两个主要的观点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;多层神经网络具有优异的、自动化的&lt;strong&gt;特征学习&lt;/strong&gt;能力。&lt;/li&gt;
&lt;li&gt;提出&lt;strong&gt;逐层预训练&lt;/strong&gt;的方法来克服深度神经网络在训练上的难度。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;得益于大数据、GPU计算硬件的支持，在 2012 年的 ImageNet 挑战赛中，基于深度学习的 AlexNet 模型以巨大优势赢得了比赛，标志着深度学习时代的到来。可以说&lt;strong&gt;当今基于深度学习大模型的人工智能框架是：数据（人工） + 算力（GPU）+ 算法（模型）&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;深度学习三巨头&#34;&gt;深度学习“三巨头”&lt;/h3&gt;
&lt;p&gt;2018年深度学习三巨头因为“在概念和工程方面使深度神经网络成为计算的关键组成部分”而获得图灵奖。辛顿的感言是&amp;quot;我们终于不用再假装在研究别的东西了&amp;quot;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;杰弗里·辛顿&lt;/strong&gt;：深度学习教父，多伦多大学，Google 大脑，误差反向传播算法。在2012年通过改进卷积神经网络（AlexNet）大幅提高了图像识别的准确率，引发了计算机视觉领域的一场革命。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;杨立昆&lt;/strong&gt;：纽约大学，Facebook人工智能研究院创建人，卷积神经网络（CNN）的主要发明者。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;书亚·本希奥&lt;/strong&gt;：蒙特利尔大学，微软研究院的人工智能战略顾问。提出长短期记忆神经网络、词向量，这对自然语言处理产生了重大影响。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;深度学习祛魅&#34;&gt;深度学习祛魅&lt;/h3&gt;
&lt;p&gt;随着 ChatGPT 和 Deepseek 的爆火，人工智能已经天下闻名，人人趋之若鹜。但深度学习达到了或者说能实现通用人工智能的目标么？我深表怀疑，理由如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;严重依赖大规模的数据&lt;/strong&gt;，“有多少人工就有多少智能”。不仅穷尽每个领域的所有数据既不现实也不是智能的体现，而且带有人类偏见的数据还会引起&lt;strong&gt;算法歧视&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;严重依赖高质量数据的预训练建模&lt;/strong&gt;：不具备迁移或多任务能力。通用人工智能必须能通过少量数据的学习来自发现规律。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;不可解释和不可验证&lt;/strong&gt;：由于缺乏理论支持，神经网络算法是一个黑盒/暗箱，对其输出的结果没有可验证的手段，也不具备可解释性。其实现的内部复杂性也不符合奥卡姆剃刀的简约原则（主张选择假设最少的解释）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;缺少理论基础&lt;/strong&gt;：人类自己都没搞清楚人类大脑是如何思考和学习的。大脑皮质柱是否具有通用统一的基础结构，且这种结构的运作机制是否遵循某种通用算法？智能能否被建模？数学建模如何超越哥德尔不完备定理？&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;还原方法论局限&lt;/strong&gt;：复杂系统科学揭示了&lt;strong&gt;涌现现象&lt;/strong&gt;：系统整体表现出的属性无法简单地从其组成部分推导出来。大脑和社会都是典型的复杂自适应系统，而&lt;strong&gt;还原方法论难以完全把握其整体运作机制&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而今的&lt;strong&gt;深度学习本质上是将特征直接映射到基于统计数据建立的模型中概率最大的输出，它更多的是一种计算框架，而非理论框架&lt;/strong&gt;。它不具备采集数据、过滤数据、反思与反馈更新模型、理解意义等能力。尽管深度学习存在上述局限性，它在特定领域已经展现出惊人的能力。在图像识别、自然语言处理和语音合成等方面，深度学习模型已经达到或超越人类水平。它也为医疗诊断、药物发现和气候模拟等领域带来了革命性突破。&lt;/p&gt;
&lt;h2 id=&#34;强化学习&#34;&gt;强化学习&lt;/h2&gt;
&lt;h3 id=&#34;苦涩的教训&#34;&gt;苦涩的教训&lt;/h3&gt;
&lt;p&gt;由于对基于统计的人工智能研究路线的不认同，强化学习之父&lt;strong&gt;理查德·萨顿&lt;/strong&gt;（Rich Sutton）于 2019年在《苦涩的教训》（The Bitter Lesson）一文中认为：&lt;strong&gt;AI研究历史告诉我们，长期来看，最有效的方法不是人为地加入特定知识，而是依靠更通用的方法与越来越强大的计算力&lt;/strong&gt;。他认为&lt;strong&gt;智能是不断根据环境反馈调整行为模式来实现目标的能力&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在该文，萨顿总结了如下经验教训：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;过去的误区&lt;/strong&gt;： 人们习惯在人工智能中嵌入大量人类智慧，比如专家经验、规则和统计知识。这在短期内可能提高性能，给研究者带来满足感，但长期来看会限制进步。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;成功的关键&lt;/strong&gt;： 真正的突破往往是靠大规模的计算资源实现的，而非人工设计的复杂规则。
&lt;ul&gt;
&lt;li&gt;国际象棋的成功，靠的是暴力搜索（穷举搜索）。&lt;/li&gt;
&lt;li&gt;围棋的突破，靠的是大规模自我对弈学习。&lt;/li&gt;
&lt;li&gt;语音识别的进步，靠的是统计模型和循环神经网络（RNN）而非人为特征提取。&lt;/li&gt;
&lt;li&gt;图像识别和计算机视觉的飞跃，靠的是卷积神经网络（CNN）而非人为特征提取。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;萨顿认为应该打造能自主试错、学习世界模型的人工智能，而非直接教给它人类已经知道的东西。可以说，这是一条重新发明人类的过程。未来人工智能的发展方向，最具前途的是“&lt;strong&gt;记忆化搜索&lt;/strong&gt;”：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;记忆&lt;/strong&gt;（memory）：记住以往成功的经验或结果以便在未来的问题解决过程中加以利用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;搜索&lt;/strong&gt;（search）：试错法、生成与测试法、变异与选择法，利用大量计算资源搜索解空间。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;核心特征&#34;&gt;核心特征&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;（Reinforcement Learning, RL）也是一种机器学习方法，它是让智能体（agent）在与环境的交互过程中通过试错来学习，不断优化策略以最大化累积奖励从而达成目标。不同于监督学习和非监督学习，强化学习强调的是智能体在没有明确指导的情况下自主探索环境，并从中学习最佳行为策略。这一过程直接体现了萨顿提到的智能三个核心特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;目标导向&lt;/strong&gt;：智能体的终极目标是最大化长期奖励（如赢得游戏、完成复杂任务）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态调整&lt;/strong&gt;：通过试错（Trial-and-Error），智能体学习哪些行为能带来更高奖励，并调整策略（Policy）以趋近最优行为模式。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;反馈驱动&lt;/strong&gt;：奖励信号（Reward）是智能体调整行为的唯一指导。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着计算能力的提升和大数据时代的到来，强化学习与深度学习的结合带来了革命性的变化，使得强化学习成为了当前AI研究和应用的一个重要方向。&lt;/p&gt;
&lt;h3 id=&#34;强化学习双杰&#34;&gt;强化学习双杰&lt;/h3&gt;
&lt;p&gt;2024年图灵奖授予了强化学习领域的两位奠基人：&lt;strong&gt;理查德·萨顿&lt;/strong&gt;和他的导师&lt;strong&gt;安德鲁·巴托&lt;/strong&gt;（Andrew Barto）。巴托和萨顿的研究成果不仅奠定了强化学习的理论基础，还促进了这一领域的实际应用。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在棋类竞赛中，AlphaZero 利用了强化学习技术击败了世界顶级围棋选手；&lt;/li&gt;
&lt;li&gt;在机器人控制方面，强化学习使机器人能够自主学习完成复杂任务；&lt;/li&gt;
&lt;li&gt;在自动驾驶领域，它也在路径规划和决策制定中发挥了重要作用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;actor-critic-架构&#34;&gt;Actor Critic 架构&lt;/h4&gt;
&lt;p&gt;Actor Critic 架构是巴托和萨顿获奖的作品之一。它是一种&lt;strong&gt;结合了价值方法和策略梯度方法&lt;/strong&gt;优点的强化学习架构。它由两个主要组件组成：&lt;strong&gt;Actor&lt;/strong&gt; 和 &lt;strong&gt;Critic&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Actor&lt;/strong&gt;：负责学习采取何种行动（即&lt;strong&gt;策略&lt;/strong&gt;）。它决定了在给定状态下应该执行的动作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critic&lt;/strong&gt;：&lt;strong&gt;评估&lt;/strong&gt;这个动作的好坏，也就是评估当前策略的好坏。具体来说，Critic 通过估计从当前状态开始遵循该策略所能获得的回报来评价 Actor 的选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在该框架下，模型与环境交互并观察，但不是用交互的直接结果当作激励，而是&lt;strong&gt;根据自己的价值函数（价值观）来评估直接结果与长期回报之间的差距，从而调整策略&lt;/strong&gt;。引入价值方法，就是要人工智能能关注长期回报而非短期奖励。用萨顿的话来说就是：&amp;ldquo;In reinforcement learning, rewards are sparse, but the returns can be rich.&amp;quot;（&lt;strong&gt;在强化学习中，奖励虽稀疏，然回报却可丰厚&lt;/strong&gt;）。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;结语在火焰与镜子之间人工智能的认知革命&#34;&gt;结语：在火焰与镜子之间——人工智能的认知革命&lt;/h2&gt;
&lt;p&gt;物理学家马克斯·普朗克说，“&lt;strong&gt;科学每经历一次葬礼就前进一步&lt;/strong&gt;。”人工智能的发展历程是“&lt;strong&gt;瓶颈-探索-突破&lt;/strong&gt;”的循环：每一次低谷都催生了新的技术方向，而每一次高潮都离不开先驱者的坚持与跨学科的协作。无论是符号主义的严谨逻辑、连接主义的生物仿生，还是行为主义的互动反馈，三大流派的竞争与融合，共同勾勒出人类探索智能疆域的壮丽图景。&lt;/p&gt;
&lt;p&gt;人工智能七十载跌宕起伏的探索史，&lt;strong&gt;本质上是人类在数学约束与哲学迷思中寻找自我认知镜像的过程&lt;/strong&gt;，恰似普罗米修斯盗火与纳西索斯临镜的双重寓言：我们既在创造照亮未知疆域的技术之火，也在算法之境中不断重构对人类意识的认知。这场无止境的探索终将证明：每次试图定义人工智能的尝试，都是对人类认知边界的重新丈量。就像古希腊人在德尔斐神庙镌刻的箴言：&amp;ldquo;认识你自己&amp;rdquo;，人工智能时代的终极命题，依然是那些连人类自己都尚未弄明白的终极哲思：何为智能？、何为意识？、何为人类？&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>人工智能：对涌现与智能的再思考</title>
      <link>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</link>
      <pubDate>Sat, 15 Feb 2025 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2025/2025-02-15-thinking-about-agi/</guid>
      
        <description>&lt;h3 id=&#34;前言&#34;&gt;前言&lt;/h3&gt;
&lt;p&gt;一年前在粗略了解 Sora 之后发表了对通用人工智能（AGI） 的粗浅看法（见&lt;a href=&#34;https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/&#34;&gt;人工智能：Sora 随感&lt;/a&gt;)，经过对 AGI 知识的学习之后，再次刷新对 Scaling Law、Transformer 以及智能/涌现的理解，因此有了此文以更新对这个知识点的“模型参数”（一年前我对 AGI 能否达到涌现是存疑的，现在转变为肯定）。都说大道至简，但精准简化岂是常人所能，我只好在通俗与严谨之间，弃严谨而取通俗。下面就是用通俗的方式来讲述我对人工智能架构主要思想的新理解。&lt;/p&gt;
&lt;h3 id=&#34;scaling-law-与涌现&#34;&gt;Scaling Law 与涌现&lt;/h3&gt;
&lt;p&gt;Scaling Law 描述了数据规模、计算资源和模型参数对 AI 模型的影响。大模型之所要大，是因为只有当模型的训练（样本）数据和参数大到突破一定的临界值后，才可能涌现出一些不可预测、更复杂的能力和特性，而进行这样大规模的训练又依赖于大规模的计算资源。这等规模的模型能够从原始训练数据中自动学习并发现或发明新的、更高层次的特征和模式，这种能力被称为“&lt;strong&gt;涌现（Emergence）&lt;/strong&gt;”。随着科技的进步，曾经被认为难以突破的计算和数据限制，将来一定会是可控和可实现的。从本质上讲，Scaling Law 不是决定 AI 智能形态的根本因素，而是影响其发展的&lt;strong&gt;资源门槛&lt;/strong&gt;。但就像“巧妇难为无米之炊”，即使有再先进的模型架构，也需要规模足够大的数据和计算能力来达到涌现所需的阈值。此外，涌现现象的出现通常依赖于大规模个体之间的相互作用，只有在规模足够大的个体之间的&lt;strong&gt;非线性关系&lt;/strong&gt;才可能催生出&lt;strong&gt;整体大于部分之和&lt;/strong&gt;的智能表现。&lt;/p&gt;
&lt;h3 id=&#34;transformer-与智能&#34;&gt;Transformer 与智能&lt;/h3&gt;
&lt;p&gt;可以说&lt;strong&gt;世界是一个基于贝叶斯定理的概率（经验）大模型（推理在经验之上）&lt;/strong&gt;。关于贝叶斯定理，多年以前我写过一篇《从贝叶斯定理说开去》的文章，互联网应该还有这个记忆。通俗地讲，&lt;strong&gt;贝叶斯定理就是根据新的观察结果来调整由过去学习到的经验概率值&lt;/strong&gt;。比如：猎人在某片树林连续三天发现猎物群，于是猎人习得经验（逐天增加这片树林发现猎物的概率），当然猎物群也会调整自身的经验（逐步增加这片树林的危险性概率）。&lt;/p&gt;
&lt;p&gt;展开说说经验与推理，西方经典哲学分两派：英国经验主义与大陆唯理主义。这可以用来类比大模型的两种实现思路：经验概率和逻辑推理，经验概率不是绝对可靠的，需要逻辑推理来引导和试错，两相结合就完美了。&lt;/p&gt;
&lt;p&gt;因此&lt;strong&gt;智能可以简化理解为从环境中自主学习、调整和应用经验的能力（反思过去、改变现在、规划未来）&lt;/strong&gt;。如果说 Scaling Law 解决大模型之“大”的问题（大才可能有足够多的相关性概率参数来突破涌现所需的阈值），那么 Transformer 就是要解决基于贝叶斯定理的概率问题，通俗地说就是解决经验问题（表现为智能，表征为模型参数）：参数从哪来？参数怎么调整？参数怎么评估？参数怎么应用？参数怎么存储？Transformer 中的对这些问题的解决机制非常巧妙与精细，也非常专业，在此不展开细述（遇事不决，问 AI 啊）。&lt;/p&gt;
&lt;h3 id=&#34;通俗解读-transformer-架构&#34;&gt;通俗解读 Transformer 架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://opensource.niutrans.com/niutensor/Transformer/1.png&#34; alt=&#34;Transformer 架构图&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;上图是 Transformer 架构图，下面我以一群红学爱好者研读和续写《红楼梦》为类比对这个架构图进行通俗的解读。&lt;/p&gt;
&lt;h4 id=&#34;1-自注意力机制--大观园诗社品评会&#34;&gt;1. 自注意力机制 → 大观园诗社品评会&lt;/h4&gt;
&lt;p&gt;想象一下大观园内一群红学爱好者组成品评社，将所有《红楼梦》词句都制作成考据卡片（词向量），同时对所有卡片进行研读解析。当解析&amp;quot;黛玉葬花&amp;quot;时：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;分席研读&lt;/strong&gt;：品评社分设八张茶案（多头注意力），一席专研葬花词韵律，一席考据花锄形制，一席探讨谶语隐喻，终将各席见解汇成《葬花十论》。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;全局索引&lt;/strong&gt;：&amp;ldquo;葬花&amp;quot;自动关联第五回&amp;quot;花冢&amp;rdquo;、二十七回&amp;quot;泣残红&amp;quot;，如同全局雷达可以扫描全文查找互文线索（长程依赖）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;2-位置编码--脂批本页码钤印&#34;&gt;2. 位置编码 → 脂批本页码钤印&lt;/h4&gt;
&lt;p&gt;为防止混淆章回时序：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位置编码&lt;/strong&gt;：每张考据卡片背后加注出处信息：本子+回数+段落，如&amp;quot;甲戌本第三回第十段&amp;quot;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;周期性特征编码&lt;/strong&gt;：不同版本（如甲戌本、程乙本、蒙府本）用青赤墨色区分（正弦波编码的周期性特征）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;3-前馈神经网络--金陵十二钗品藻堂&#34;&gt;3. 前馈神经网络 → 金陵十二钗品藻堂&lt;/h4&gt;
&lt;p&gt;每完成一轮研讨后，带着解读成果进入下一轮研读（&lt;strong&gt;分层迭代，逐层抽象&lt;/strong&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;特质解经&lt;/strong&gt;：将&amp;quot;宝钗&amp;quot;拆解为&amp;quot;冷香丸药理&amp;quot;、&amp;ldquo;金锁谶语&amp;rdquo;、&amp;ldquo;蘅芜苑陈设&amp;quot;等维度（GeLU激活的&lt;strong&gt;特征提取&lt;/strong&gt;：特征放大镜），如同将&amp;quot;冷香丸&amp;quot;分解为白牡丹花蕊、白荷花蕊等十二味药材。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;芜杂筛除&lt;/strong&gt;：剔除如&amp;quot;黛玉用药中的人参是否产自辽东&amp;quot;等细枝末节，保留&amp;quot;疾病作为命运隐喻&amp;quot;的核心命题（&lt;strong&gt;特征蒸馏&lt;/strong&gt;：噪声过滤器）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;4-残差连接--程乙本朱丝栏夹批&#34;&gt;4. 残差连接 → 程乙本朱丝栏夹批&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;底本存真&lt;/strong&gt;：必须在原本上直接写批注（残差连接），不能另起新纸，防止偏离原文而导致过度阐释（语义漂移）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;体例规整&lt;/strong&gt;：在每一层研读完成后，按《校勘学通则》（层归一化公式）调整特征值分布，使&amp;quot;诗词鉴赏分&amp;quot;与&amp;quot;器物考据分&amp;quot;处于可比量纲。这确保不会因为某一席的研读过于精彩而剑走偏锋。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;5-自回归生成--芹溪草堂续书接龙&#34;&gt;5. 自回归生成 → 芹溪草堂续书接龙&lt;/h4&gt;
&lt;p&gt;仿高鹗续写后四十回：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;前文锁钥&lt;/strong&gt;：续写&amp;quot;黛玉之死&amp;quot;时后续稿页封存（掩码机制），仅可参看前八十回伏笔。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;笔削春秋&lt;/strong&gt;：若有人续&amp;quot;宝玉修仙&amp;rdquo;，系统自动改为&amp;quot;宝玉中举&amp;quot;，如同脂砚斋批&amp;quot;此回未成而芹逝矣&amp;quot;的遗憾修补。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;6-智能表现--脂砚斋大数据评点&#34;&gt;6. 智能表现 → 脂砚斋大数据评点&lt;/h4&gt;
&lt;p&gt;模型智慧源于红学百年积淀：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;套路总结&lt;/strong&gt;：统计十万条脂批发现&amp;quot;凡&amp;rsquo;赤瑕宫&amp;rsquo;出现必关联&amp;rsquo;宝玉疯癫&amp;rsquo;&amp;quot;（注意力模式挖掘）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;笔补造化&lt;/strong&gt;：要求&amp;quot;描绘潇湘馆AI设计图&amp;quot;，系统融合&amp;quot;竹影纱窗+药炉棋枰+鹦鹉念诗&amp;quot;（跨模态生成），如同将大观园图样与《园冶》营造法式结合。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;为什么这套机制能成功&#34;&gt;​为什么这套机制能成功？&lt;/h3&gt;
&lt;p&gt;这套机制能成功运作的关键在三组学术张力的平衡：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;索隐与实证&lt;/strong&gt;：注意力机制允许&amp;quot;索隐派&amp;quot;式发散联想（如将&amp;quot;甄士隐&amp;quot;解读为&amp;quot;真事隐&amp;quot;），残差连接确保不违&amp;quot;作者本意&amp;quot;（文本约束）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;微观与宏观&lt;/strong&gt;：既见&amp;quot;晴雯病补雀金裘&amp;quot;（局部特征），又悟&amp;quot;千红一哭&amp;quot;悲剧基调（全局视野）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流派与共识&lt;/strong&gt;：各注意力头如不同红学流派（评点派、考证派、索引派），最终通过加权投票形成主流阐释&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Transformer 本质是&lt;strong&gt;大数据驱动的统计智能&lt;/strong&gt;。其运作机制就好比组建了一个超级红学研究团队：有考据达人（自注意力）、有版本比对家（位置编码）、有主题提炼师（前馈网络）、有体例规范官（层归一化），所有人都遵循《红楼梦校勘学》（Transformer架构），产出既承曹雪芹本真、又具当代精神的续书方案。这种智能，在总体效果上就是达成文献学与阐释学的动态平衡——既能考据&amp;quot;枫露茶事件&amp;quot;版本异文，又能提炼&amp;quot;悲金悼玉&amp;quot;的永恒母题。这在红学中体现为&amp;quot;大胆探佚，小心求证&amp;quot;；在数学上对应&amp;quot;既要发散（拓展阐释维度），又要收敛（遵循文本边界）&amp;quot;；工程上实现为&amp;quot;在多轮讨论迭代的梯度中寻求最优续写路径&amp;quot;。也就是说既要有足够的探索空间来发现新模式，又要有一定的约束来避免无意义的生成。用头脑风暴的过程来类比：第一阶段发散思维，探索尽可能多的可能性；第二阶段筛选和收敛，确保输出合理有用。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;gpt&#34;&gt;GPT&lt;/h3&gt;
&lt;p&gt;GPT 系列大语言模型是站在 Transformer 的肩膀上，且只用解码器部分。它本质上就是一个用来估计文本概率分布的数学模型，它通过大规模预训练足够多的文本序列统计得到 token 在自然语言中不同维度上的相关性概率的数据库（基础模型），因此就能够根据已生成的文本，预测下一个最可能（概率最大）出现的汉字或单词。因而它是&lt;strong&gt;一种基于统计的概率模型&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;展望&#34;&gt;展望&lt;/h3&gt;
&lt;p&gt;当今的大模型的主要成就还集中在知识密集型领域，但多模态模型和基于思维链的推理模型都已初具规模。以 AI 的发展速度，不用多久人形（具身）智能体便可以落地。到那时，人形智能体能自动从世界环境中获取数据、交互作用、积累经验，并因独特的成长轨迹习得独特的个体经验。无数这样的个体相互作用再涌现出某种非凡能力，这种能力有可能都不属于人类知识范围了。人形智能体的出现，还能给人留下了什么地盘？或许如康德给理性划界从而为信仰留出地盘一样，有了这些替人代劳部分功能的人形智能体，&lt;strong&gt;人类能更纯粹地思考人之所以为人的独特之处&lt;/strong&gt;。所以，何以为人？康德式的道德律？意义信仰？亦或是欲望？&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>人工智能：Sora 随感</title>
      <link>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</link>
      <pubDate>Thu, 22 Feb 2024 22:14:00 +0800</pubDate>
      
      <guid>https://luozhaohui.github.io/post/2024/2024-02-22-thinking-about-agi/</guid>
      
        <description>&lt;h2 id=&#34;sora-做了什么&#34;&gt;Sora 做了什么&lt;/h2&gt;
&lt;p&gt;基于目前公开的信息 Sora 模型奠基于两大原理之上：Transformer 与 Scaling Law。前者本质就是换个角度看问题，使得跨领域建模及其处理更为一致、高效，一如：频率和概率，直角坐标系和极坐标系，大数据常用的矩阵变换等等；后者就是大力出奇迹的规模效应：模型大，数据多，算力强，那效果就更好（是否能达到涌现的程度存疑）。个人感觉前者使“通用”成为可能，后者使“智能”成为可能。Sora 强大之处是仅通过学习人类产生的视频（仅视觉、听觉、字幕），就能产生&lt;strong&gt;世界模拟器&lt;/strong&gt;的四维视频。但我不认为它从中推理出牛顿定律或能量守恒定律等，进而根据这些理论来构建四维世界视频，它仅仅是通过大数据分析在可能性空间中选择相关关系最大的情景。&lt;/p&gt;
&lt;h2 id=&#34;指数级速度&#34;&gt;指数级速度&lt;/h2&gt;
&lt;p&gt;通用人工智能（AGI）的演进速度将呈指数级增长。参照人类历史发展的时间间隔便可直观感受这惊人的速度：从以万年为单位的农业革命，到以千年为单位的工业革命，到以百年为单位的计算机革命，再到以十年为单位的互联网革命，以及以年为单位的智能革命。仅用了几年时间 AGI 就实现从文字（ChatGPT）、到图片（DALL·E ）、再到视频（Sora）的模拟生成。这还是在只具备基于相关的概率归纳能力，不具备基于因果的理解演绎能力的情况下发生的。可以预见，随着AGI自迭代能力（数据自采集、模型自编程）的发展，其演进速度将以天以秒为单位，这将极大地挑战人类社会的适应能力。随着实现途径变得越来越强大与便捷，未来，想法为王。以前因人类在生理与环境、文化的演化速度上不匹配而造成一些认知谬误，人们常会说：我们是生活在信息时代的原始人，不久人们将会说：我们是生活在智能时代的动物。&lt;/p&gt;
&lt;h2 id=&#34;风险与收益&#34;&gt;风险与收益&lt;/h2&gt;
&lt;p&gt;阴阳之道，祸福相依。效率与公平、收益与风险，前者常在明处、近处，后者常在隐处、远处。“遥遥领先”的 OpenAI 在激进的奥特曼的带领下对安全与非营利并没有那么看重，是福还是祸？随着通用人工智能以指数级的速度演进而来的很可能是认知差距、贫富差距等也以指数级的速度扩大，智能替代还可能造成大量的“无用”人。《新约·马太效应]》说：“凡有的，还要加倍给他叫他多余；没有的，连他所有的也要夺过来。”如果迷信激进的科学教，而缺少必要的人文关怀和宽容，二八定律变成一比九九九定律，在我们有生之年是很可能见到的。这将对人类社会的治理、道德文化、生存意义带来极大的挑战。到目前为止，人性阴阳之道（贪婪与恐惧）的转换是人类文明不被毁灭的保障（即便疯狂如希特勒，其同归于尽的毁灭计划也被抵制没有得到执行，他本人也至少两次被德国军官暗杀未遂）。但倘若出现了非人类新型智能文明，或人机智能合体文明呢？&lt;/p&gt;
&lt;h2 id=&#34;具备自我意识的智能机器人&#34;&gt;具备自我意识的智能机器人&lt;/h2&gt;
&lt;p&gt;具有自我意识或者情感的智能机器人是可能的。一个可以更新智能算法模型和基础数据包的具备五感的通用人形机器人就如一个新生儿，在生存与成长这两大框架下，在特定环境中去执行人类赋予的某些使命或职责。在这个特定环境中不断交互学习形成独一无二的本地数据包，且形成为不同数据赋有不同权重的信息网络，一如每个人独特的成长经历（记忆）。加权的信息网络对主题是有偏好的，且本地数据包的使用优先于内置的通用基础数据包，从而智能机器人可以具有偏好，形成情感，达成自我意识。&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
